{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.7.5\n"
     ]
    }
   ],
   "source": [
    "from platform import python_version\n",
    "\n",
    "print(python_version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "from PIL import Image\n",
    "import time\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers,models,optimizers\n",
    "from keras import backend as K\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "path=\"datasets/ofg_family/\"\n",
    "randomiser = np.random.RandomState(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_image(family_dir):\n",
    "    dic={}\n",
    "    sub=[a for a in listdir(path+\"/\"+family_dir)]\n",
    "    \n",
    "    for ele in sub:\n",
    "        mypath = path+\"/\"+family_dir+\"/\"+ele+\"/\"\n",
    "        onlyfiles = [mypath+f for f in listdir(mypath)]\n",
    "        \n",
    "        addr = randomiser.choice(onlyfiles)\n",
    "        original_img = np.array(Image.open(addr).resize((32,32),Image.ANTIALIAS))\n",
    "        if ele[0].lower()=='f':\n",
    "            dic['father'] = original_img\n",
    "        elif ele[0].lower()=='m':\n",
    "            dic['mother'] = original_img\n",
    "        elif ele.lower()=='child_male':\n",
    "            dic['child'] = original_img    \n",
    "            dic['gender']=np.zeros((original_img.shape))\n",
    "        elif ele.lower()=='child_female':\n",
    "            dic['child'] = original_img    \n",
    "            dic['gender'] = np.ones((original_img.shape))\n",
    "    return [dic['father'],dic['mother'],dic['gender'],dic['child']]\n",
    "\n",
    "def generate_batch(families_batch):\n",
    "    np_images=[]\n",
    "    \n",
    "    for family in families_batch:\n",
    "        res = generate_image(family)\n",
    "        if( res != None):\n",
    "            np_images.append(res)\n",
    "    \n",
    "    return np_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "#full_data = load_npdata(path)\n",
    "#print(len(full_data))\n",
    "\n",
    "for r, d, f in os.walk(path):\n",
    "        all_families=d\n",
    "        break\n",
    "\n",
    "randomiser.shuffle(all_families)\n",
    "\n",
    "train_families = all_families[:-500]\n",
    "test_families = all_families[-500:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create encoder decoder supervised pipeling operation\n",
    "input: stacked images of father and mother (32,32,6)\n",
    "encoder -> decoder -> image reconstruction\n",
    "reconstruction loss w/ target image as child"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat = tf.keras.layers.Concatenate()\n",
    "\n",
    "family_data = generate_image(all_families[0])\n",
    "inp = concat([family_data[0],family_data[1]])\n",
    "child = family_data[3]\n",
    "child = tf.convert_to_tensor(child, dtype=tf.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_CHANNELS = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downsample(filters, size, apply_batchnorm=True):\n",
    "  initializer = tf.random_normal_initializer(0., 0.02)\n",
    "\n",
    "  result = tf.keras.Sequential()\n",
    "  result.add(\n",
    "      tf.keras.layers.Conv2D(filters, size, strides=2, padding='same',\n",
    "                             kernel_initializer=initializer, use_bias=False))\n",
    "\n",
    "  if apply_batchnorm:\n",
    "    result.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "  result.add(tf.keras.layers.LeakyReLU())\n",
    "\n",
    "  return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upsample(filters, size, apply_dropout=False):\n",
    "  initializer = tf.random_normal_initializer(0., 0.02)\n",
    "\n",
    "  result = tf.keras.Sequential()\n",
    "  result.add(\n",
    "    tf.keras.layers.Conv2DTranspose(filters, size, strides=2,\n",
    "                                    padding='same',\n",
    "                                    kernel_initializer=initializer,\n",
    "                                    use_bias=False))\n",
    "\n",
    "  result.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "  if apply_dropout:\n",
    "      result.add(tf.keras.layers.Dropout(0.5))\n",
    "\n",
    "  result.add(tf.keras.layers.ReLU())\n",
    "\n",
    "  return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "def EncoderNN():\n",
    "  down_stack = [\n",
    "    downsample(32, 4, apply_batchnorm=True),\n",
    "    downsample(64, 4, apply_batchnorm=False),\n",
    "    downsample(128, 4, apply_batchnorm=False) \n",
    "  ]\n",
    "\n",
    "  up_stack = [\n",
    "    upsample(64, 4, apply_dropout=False),\n",
    "    upsample(32, 4, apply_dropout=False),\n",
    "    upsample(3, 4, apply_dropout=False)\n",
    "  ]\n",
    "\n",
    "  initializer = tf.random_normal_initializer(0., 0.02)\n",
    "  last = tf.keras.layers.Conv2DTranspose(OUTPUT_CHANNELS, 4,\n",
    "                                         strides=2,\n",
    "                                         padding='same',\n",
    "                                         kernel_initializer=initializer,\n",
    "                                         activation='tanh') # (bs, 256, 256, 3)\n",
    "\n",
    "  concat = tf.keras.layers.Concatenate()\n",
    "\n",
    "  inputs = tf.keras.layers.Input(shape=[32,32,6])\n",
    "  x = inputs\n",
    "\n",
    "  # Downsampling through the model\n",
    "  skips = []\n",
    "  for down in down_stack:\n",
    "    x = down(x)\n",
    "    skips.append(x)\n",
    "\n",
    "  skips = reversed(skips[:-1])\n",
    "\n",
    "  # Upsampling and establishing the skip connections\n",
    "  for up, skip in zip(up_stack, skips):\n",
    "    x = up(x)\n",
    "    x = concat([x, skip])\n",
    "    \n",
    "  x = last(x)\n",
    "\n",
    "  return tf.keras.Model(inputs=inputs, outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = EncoderNN()\n",
    "\n",
    "# gen_output = encoder(inp[tf.newaxis,...], training=False)\n",
    "# loss= tf.reduce_mean(tf.image.total_variation(tf.concat([child,tf.squeeze(gen_output)],axis=0)))\n",
    "# loss = tf.reduce_mean(tf.nn.l2_loss(child-gen_output))\n",
    "# print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_loss():\n",
    "    def loss(y_true,y_pred):\n",
    "        print(y_true.shape)\n",
    "        print(y_pred.shape)\n",
    "        return tf.reduce_mean(tf.abs(y_true - y_pred))\n",
    "        #return tf.reduce_mean(tf.image.total_variation(tf.concat([y_true,y_pred],axis=0)))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "inp = concat([full_data[0][0],full_data[0][1]])\n",
    "inp = tf.convert_to_tensor(inp, dtype=tf.float32)\n",
    "X_train = tf.reshape(inp,([1,32,32,6]))\n",
    "Y_train = tf.reshape(full_data[0][3],(1,32,32,3))\n",
    "\n",
    "encoder.compile(loss=custom_loss(),\n",
    "              optimizer=tf.keras.optimizers.RMSprop())\n",
    "history = encoder.fit(X_train, Y_train,\n",
    "                    batch_size=1,\n",
    "                    epochs=1)\n",
    "\n",
    "gen_output = encoder(inp[tf.newaxis,...], training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat = tf.keras.layers.Concatenate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, None, None, None)\n",
      "(None, 32, 32, 3)\n",
      "Epoch  0  .....\n",
      "Generated batch (20, 4, 32, 32, 3)\n",
      "WARNING:tensorflow:Layer concatenate_48 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "Batch converted to tensor\n",
      "Train on 20 samples\n",
      "(20, 32, 32, 3)\n",
      "(20, 32, 32, 3)\n",
      "(20, 32, 32, 3)\n",
      "(20, 32, 32, 3)\n",
      "20/20 [==============================] - 1s 45ms/sample - loss: 132.9951\n",
      "Generated batch (20, 4, 32, 32, 3)\n",
      "Batch converted to tensor\n",
      "Train on 20 samples\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 125.2195\n",
      "Generated batch (20, 4, 32, 32, 3)\n",
      "Batch converted to tensor\n",
      "Train on 20 samples\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 131.8188\n",
      "Generated batch (20, 4, 32, 32, 3)\n",
      "Batch converted to tensor\n",
      "Train on 20 samples\n",
      "20/20 [==============================] - 0s 3ms/sample - loss: 125.5421\n",
      "Generated batch (20, 4, 32, 32, 3)\n",
      "Batch converted to tensor\n",
      "Train on 20 samples\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 129.9285\n",
      "Generated batch (20, 4, 32, 32, 3)\n",
      "Batch converted to tensor\n",
      "Train on 20 samples\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 126.8264\n",
      "Generated batch (20, 4, 32, 32, 3)\n",
      "Batch converted to tensor\n",
      "Train on 20 samples\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 127.3414\n",
      "Generated batch (20, 4, 32, 32, 3)\n",
      "Batch converted to tensor\n",
      "Train on 20 samples\n",
      "20/20 [==============================] - 0s 3ms/sample - loss: 126.8531\n",
      "Generated batch (20, 4, 32, 32, 3)\n",
      "Batch converted to tensor\n",
      "Train on 20 samples\n",
      "20/20 [==============================] - 0s 3ms/sample - loss: 134.3731\n",
      "Generated batch (20, 4, 32, 32, 3)\n",
      "Batch converted to tensor\n",
      "Train on 20 samples\n",
      "20/20 [==============================] - 0s 3ms/sample - loss: 129.0502\n",
      "Generated batch (20, 4, 32, 32, 3)\n",
      "Batch converted to tensor\n",
      "Train on 20 samples\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 133.7057\n",
      "Generated batch (20, 4, 32, 32, 3)\n",
      "Batch converted to tensor\n",
      "Train on 20 samples\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 129.9513\n",
      "Generated batch (20, 4, 32, 32, 3)\n",
      "Batch converted to tensor\n",
      "Train on 20 samples\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 116.6339\n",
      "Generated batch (20, 4, 32, 32, 3)\n",
      "Batch converted to tensor\n",
      "Train on 20 samples\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 129.7670\n",
      "Generated batch (20, 4, 32, 32, 3)\n",
      "Batch converted to tensor\n",
      "Train on 20 samples\n",
      "20/20 [==============================] - 0s 3ms/sample - loss: 121.0623\n",
      "Generated batch (20, 4, 32, 32, 3)\n",
      "Batch converted to tensor\n",
      "Train on 20 samples\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 130.3813\n",
      "Generated batch (20, 4, 32, 32, 3)\n",
      "Batch converted to tensor\n",
      "Train on 20 samples\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 124.1153\n",
      "Generated batch (20, 4, 32, 32, 3)\n",
      "Batch converted to tensor\n",
      "Train on 20 samples\n",
      "20/20 [==============================] - 0s 3ms/sample - loss: 123.2316\n",
      "Generated batch (20, 4, 32, 32, 3)\n",
      "Batch converted to tensor\n",
      "Train on 20 samples\n",
      "20/20 [==============================] - 0s 3ms/sample - loss: 121.8350\n",
      "Generated batch (20, 4, 32, 32, 3)\n",
      "Batch converted to tensor\n",
      "Train on 20 samples\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 126.3763\n",
      "Generated batch (20, 4, 32, 32, 3)\n",
      "Batch converted to tensor\n",
      "Train on 20 samples\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 122.2308\n",
      "Generated batch (20, 4, 32, 32, 3)\n",
      "Batch converted to tensor\n",
      "Train on 20 samples\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 123.8039\n",
      "Generated batch (20, 4, 32, 32, 3)\n",
      "Batch converted to tensor\n",
      "Train on 20 samples\n",
      "20/20 [==============================] - 0s 3ms/sample - loss: 124.6622\n",
      "Generated batch (20, 4, 32, 32, 3)\n",
      "Batch converted to tensor\n",
      "Train on 20 samples\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 125.0264\n",
      "Generated batch (20, 4, 32, 32, 3)\n",
      "Batch converted to tensor\n",
      "Train on 20 samples\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 126.7520\n",
      "Generated batch (20, 4, 32, 32, 3)\n",
      "Batch converted to tensor\n",
      "Train on 20 samples\n",
      "20/20 [==============================] - 0s 3ms/sample - loss: 133.4212\n",
      "Generated batch (20, 4, 32, 32, 3)\n",
      "Batch converted to tensor\n",
      "Train on 20 samples\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 129.4779\n",
      "Generated batch (20, 4, 32, 32, 3)\n",
      "Batch converted to tensor\n",
      "Train on 20 samples\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 115.6493\n",
      "Generated batch (20, 4, 32, 32, 3)\n",
      "Batch converted to tensor\n",
      "Train on 20 samples\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 117.6746\n",
      "Generated batch (20, 4, 32, 32, 3)\n",
      "Batch converted to tensor\n",
      "Train on 20 samples\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 113.3902\n",
      "Generated batch (20, 4, 32, 32, 3)\n",
      "Batch converted to tensor\n",
      "Train on 20 samples\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 130.3421\n",
      "Generated batch (20, 4, 32, 32, 3)\n",
      "Batch converted to tensor\n",
      "Train on 20 samples\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 119.7254\n",
      "Generated batch (20, 4, 32, 32, 3)\n",
      "Batch converted to tensor\n",
      "Train on 20 samples\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 136.8331\n",
      "Generated batch (20, 4, 32, 32, 3)\n",
      "Batch converted to tensor\n",
      "Train on 20 samples\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 120.5487\n",
      "Generated batch (20, 4, 32, 32, 3)\n",
      "Batch converted to tensor\n",
      "Train on 20 samples\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 118.1667\n",
      "Generated batch (20, 4, 32, 32, 3)\n",
      "Batch converted to tensor\n",
      "Train on 20 samples\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 136.8294\n",
      "Generated batch (20, 4, 32, 32, 3)\n",
      "Batch converted to tensor\n",
      "Train on 20 samples\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 124.4827\n",
      "Generated batch (20, 4, 32, 32, 3)\n",
      "Batch converted to tensor\n",
      "Train on 20 samples\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 126.4549\n",
      "Generated batch (20, 4, 32, 32, 3)\n",
      "Batch converted to tensor\n",
      "Train on 20 samples\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 125.4798\n",
      "Generated batch (20, 4, 32, 32, 3)\n",
      "Batch converted to tensor\n",
      "Train on 20 samples\n",
      "20/20 [==============================] - 0s 3ms/sample - loss: 128.6183\n",
      "Generated batch (20, 4, 32, 32, 3)\n",
      "Batch converted to tensor\n",
      "Train on 20 samples\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 131.3508\n",
      "Generated batch (20, 4, 32, 32, 3)\n",
      "Batch converted to tensor\n",
      "Train on 20 samples\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 135.0109\n",
      "Generated batch (20, 4, 32, 32, 3)\n",
      "Batch converted to tensor\n",
      "Train on 20 samples\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 122.5865\n",
      "Generated batch (20, 4, 32, 32, 3)\n",
      "Batch converted to tensor\n",
      "Train on 20 samples\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 134.4487\n",
      "Generated batch (20, 4, 32, 32, 3)\n",
      "Batch converted to tensor\n",
      "Train on 20 samples\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 126.5583\n",
      "Generated batch (20, 4, 32, 32, 3)\n",
      "Batch converted to tensor\n",
      "Train on 20 samples\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 123.9510\n",
      "Generated batch (20, 4, 32, 32, 3)\n",
      "Batch converted to tensor\n",
      "Train on 20 samples\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 137.3742\n",
      "Generated batch (20, 4, 32, 32, 3)\n",
      "Batch converted to tensor\n",
      "Train on 20 samples\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 135.9156\n",
      "Generated batch (20, 4, 32, 32, 3)\n",
      "Batch converted to tensor\n",
      "Train on 20 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 0s 2ms/sample - loss: 119.4473\n",
      "Generated batch (20, 4, 32, 32, 3)\n",
      "Batch converted to tensor\n",
      "Train on 20 samples\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 131.3354\n",
      "Generated batch (20, 4, 32, 32, 3)\n",
      "Batch converted to tensor\n",
      "Train on 20 samples\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 130.7571\n",
      "Generated batch (20, 4, 32, 32, 3)\n",
      "Batch converted to tensor\n",
      "Train on 20 samples\n",
      "20/20 [==============================] - 0s 3ms/sample - loss: 118.9928\n",
      "Generated batch (20, 4, 32, 32, 3)\n",
      "Batch converted to tensor\n",
      "Train on 20 samples\n",
      "20/20 [==============================] - 0s 3ms/sample - loss: 116.0126\n",
      "Generated batch (20, 4, 32, 32, 3)\n",
      "Batch converted to tensor\n",
      "Train on 20 samples\n",
      "20/20 [==============================] - 0s 3ms/sample - loss: 124.1404\n",
      "Generated batch (20, 4, 32, 32, 3)\n",
      "Batch converted to tensor\n",
      "Train on 20 samples\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 128.8515\n",
      "Generated batch (20, 4, 32, 32, 3)\n",
      "Batch converted to tensor\n",
      "Train on 20 samples\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 120.4032\n",
      "Generated batch (20, 4, 32, 32, 3)\n",
      "Batch converted to tensor\n",
      "Train on 20 samples\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 132.0217\n",
      "Generated batch (20, 4, 32, 32, 3)\n",
      "Batch converted to tensor\n",
      "Train on 20 samples\n",
      "20/20 [==============================] - 0s 3ms/sample - loss: 127.9885\n",
      "Generated batch (20, 4, 32, 32, 3)\n",
      "Batch converted to tensor\n",
      "Train on 20 samples\n",
      "20/20 [==============================] - 0s 2ms/sample - loss: 126.9142\n",
      "Generated batch (20, 4, 32, 32, 3)\n",
      "Batch converted to tensor\n",
      "Train on 20 samples\n",
      "20/20 [==============================] - 0s 3ms/sample - loss: 129.9781\n"
     ]
    },
    {
     "ename": "NotADirectoryError",
     "evalue": "[Errno 20] Not a directory: 'datasets/ofg_family//F0001_1/.DS_Store/'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotADirectoryError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-189-ea8c384436c0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Epoch \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;34m\" .....\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_families\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mbatch_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerate_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_families\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Generated batch\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-179-70a241499191>\u001b[0m in \u001b[0;36mgenerate_batch\u001b[0;34m(families_batch)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mfamily\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfamilies_batch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfamily\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mres\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0mnp_images\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-179-70a241499191>\u001b[0m in \u001b[0;36mgenerate_image\u001b[0;34m(family_dir)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mele\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msub\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mmypath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mfamily_dir\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mele\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0monlyfiles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mmypath\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mf\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmypath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0maddr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandomiser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0monlyfiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotADirectoryError\u001b[0m: [Errno 20] Not a directory: 'datasets/ofg_family//F0001_1/.DS_Store/'"
     ]
    }
   ],
   "source": [
    "encoder.compile(loss=custom_loss(),optimizer=tf.keras.optimizers.RMSprop())\n",
    "\n",
    "divide = 100\n",
    "epochs = 5\n",
    "batch = 20\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(\"Epoch \", epoch , \" .....\")\n",
    "    for i in range(len(train_families)//batch):\n",
    "        batch_data = np.asarray(generate_batch(train_families[i*batch:(i+1)*batch]))\n",
    "        \n",
    "        print(\"Generated batch\", batch_data.shape)\n",
    "        \n",
    "        X_train = tf.convert_to_tensor(concat([batch_data[:,0],batch_data[:,1]]),dtype =tf.float32)\n",
    "        print(\"Batch converted to tensor\")\n",
    "        \n",
    "        Y_train = batch_data[:,3]\n",
    "        history = encoder.fit(X_train, Y_train, batch_size=batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x14d011dd0>"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "inp = tf.cast(inp, tf.float32)\n",
    "\n",
    "gen_output = encoder(inp[tf.newaxis,...], training=False)\n",
    "plt.imshow(gen_output[0,...])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "csci566Assg3",
   "language": "python",
   "name": "csci566asg3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
