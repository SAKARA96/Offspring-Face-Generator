{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from platform import python_version\n",
    "import tensorflow as tf\n",
    "\n",
    "print(tf.test.is_gpu_available())\n",
    "print(python_version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "from PIL import Image\n",
    "import time\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers,models,optimizers\n",
    "from keras import backend as K\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path=\"datasets/TSKinFace_Data/TSKinFace_cropped/\"\n",
    "randomiser = np.random.RandomState(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = 0.\n",
    "std_dev = 0.02\n",
    "lr = 0.0005\n",
    "b1 = 0.9\n",
    "b2 = 0.99\n",
    "sd_random_normal_init = 0.02\n",
    "img_size = 64\n",
    "EPOCHS = 20\n",
    "batch = 125"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_image(family_dir, family_number, gender):\n",
    "    dic={}\n",
    "    sub = [\"F\" , \"M\", gender]\n",
    "    family_pth = path+\"/\"+family_dir+\"/\" + family_dir + \"-\" + str(family_number) + \"-\"\n",
    "    for ele in sub:\n",
    "        addr = family_pth+ele+\".jpg\"\n",
    "        original_img = np.array(Image.open(addr))\n",
    "        if ele =='F':\n",
    "            dic['father'] = original_img\n",
    "        elif ele == 'M':\n",
    "            dic['mother'] = original_img\n",
    "        elif ele == 'S':\n",
    "            dic['child'] = original_img    \n",
    "            dic['gender']=np.zeros((original_img.shape))\n",
    "        elif ele == 'D':\n",
    "            dic['child'] = original_img    \n",
    "            dic['gender'] = np.ones((original_img.shape))\n",
    "    return [dic['father'],dic['mother'],dic['gender'],dic['child']]\n",
    "\n",
    "def generate_batch(families_batch):\n",
    "    np_images=[]\n",
    "    for family in families_batch:\n",
    "        res = generate_image(family[0], family[1], family[2])\n",
    "        if( res != None):\n",
    "            np_images.append(res)\n",
    "    return np_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_families = []\n",
    "for i in range(285):\n",
    "    all_families.append(['FMS', i+1, 'S'])\n",
    "for i in range(274):\n",
    "    all_families.append(['FMD', i+1, 'D'])\n",
    "for i in range(228):\n",
    "    all_families.append(['FMSD', i+1, 'D'])  \n",
    "    all_families.append(['FMSD', i+1, 'S'])  \n",
    "randomiser.shuffle(all_families)\n",
    "train_families = all_families[:-500]\n",
    "test_families = all_families[-500:]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "path=\"datasets/ofg_family/\"\n",
    "randomiser = np.random.RandomState(123)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def generate_image(family_dir):\n",
    "    dic={}\n",
    "    sub=[a for a in listdir(path+\"/\"+family_dir)]\n",
    "    \n",
    "    for ele in sub:\n",
    "        mypath = path+\"/\"+family_dir+\"/\"+ele+\"/\"\n",
    "        onlyfiles = [mypath+f for f in listdir(mypath)]\n",
    "        \n",
    "        addr = randomiser.choice(onlyfiles)\n",
    "        original_img = np.array(Image.open(addr).resize((img_size,img_size),Image.ANTIALIAS))\n",
    "        if ele[0].lower()=='f':\n",
    "            dic['father'] = original_img\n",
    "        elif ele[0].lower()=='m':\n",
    "            dic['mother'] = original_img\n",
    "        elif ele.lower()=='child_male':\n",
    "            dic['child'] = original_img    \n",
    "            dic['gender']=np.zeros((original_img.shape))\n",
    "        elif ele.lower()=='child_female':\n",
    "            dic['child'] = original_img    \n",
    "            dic['gender'] = np.ones((original_img.shape))\n",
    "    return [dic['father'],dic['mother'],dic['gender'],dic['child']]\n",
    "\n",
    "def generate_batch(families_batch):\n",
    "    np_images=[]\n",
    "    \n",
    "    for family in families_batch:\n",
    "        res = generate_image(family)\n",
    "        if( res != None):\n",
    "            np_images.append(res)\n",
    "    \n",
    "    return np_images"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for r, d, f in os.walk(path):\n",
    "        all_families=d\n",
    "        break\n",
    "\n",
    "randomiser.shuffle(all_families)\n",
    "\n",
    "train_families = all_families[:-500]\n",
    "test_families = all_families[-500:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_CHANNELS = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_downsample_parent(filters, size, apply_batchnorm=True, apply_dropout=False):\n",
    "    initializer = tf.random_normal_initializer(mean, std_dev) \n",
    "  \n",
    "\n",
    "    result = tf.keras.Sequential()\n",
    "    result.add(\n",
    "      tf.keras.layers.Conv2D(filters, size, strides=2, padding='same',\n",
    "                             kernel_initializer=initializer,\n",
    "                             use_bias=False))\n",
    "\n",
    "    if apply_batchnorm:\n",
    "        result.add(tf.keras.layers.BatchNormalization())\n",
    "        \n",
    "    result.add(tf.keras.layers.ELU())\n",
    "        \n",
    "    if apply_dropout:\n",
    "        result.add(tf.keras.layers.Dropout(rate = 0.5))\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def gen_downsample_noise(filters, size, apply_batchnorm=True):\n",
    "    initializer = tf.random_normal_initializer(mean, std_dev) \n",
    "  \n",
    "\n",
    "    result = tf.keras.Sequential()\n",
    "    result.add(\n",
    "      tf.keras.layers.Conv2DTranspose(filters, size, strides=2, padding='same',\n",
    "                             kernel_initializer=initializer,\n",
    "                             use_bias=False))\n",
    "\n",
    "    if apply_batchnorm:\n",
    "        result.add(tf.keras.layers.BatchNormalization())\n",
    "        \n",
    "    result.add(tf.keras.layers.ELU())\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_upsample(filters, size,apply_batchnorm = False):\n",
    "    initializer = tf.random_normal_initializer(mean, std_dev)\n",
    "\n",
    "    result = tf.keras.Sequential()\n",
    "    result.add(\n",
    "    tf.keras.layers.Conv2DTranspose(filters, size, strides=2,\n",
    "                                    padding='same',\n",
    "                                    kernel_initializer=initializer,\n",
    "                                   use_bias=False))\n",
    "    if apply_batchnorm:\n",
    "        result.add(tf.keras.layers.BatchNormalization())\n",
    "        result.add(tf.keras.layers.ELU())\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def EncoderNN():\n",
    "    down_stack_parent = [\n",
    "    gen_downsample_parent(32,4,apply_batchnorm=True, apply_dropout=False),\n",
    "    gen_downsample_parent(64,4,apply_batchnorm=True, apply_dropout=False)\n",
    "    ]\n",
    "    \n",
    "#     down_stack_noise =[\n",
    "# #   z = 4x4x64\n",
    "#     gen_downsample_noise(64,4,apply_batchnorm=True), #8x8x64\n",
    "#     gen_downsample_noise(32,4,apply_batchnorm=True) #16x16x32      \n",
    "#     ]\n",
    "    \n",
    "    final_conv =[\n",
    "        gen_upsample(32,4 ,apply_batchnorm = True)\n",
    "    ]\n",
    "    \n",
    "    initializer = tf.random_normal_initializer(mean, sd_random_normal_init)\n",
    "    last = tf.keras.layers.Conv2DTranspose(OUTPUT_CHANNELS, 4,\n",
    "                                         strides=2,\n",
    "                                         padding='same',\n",
    "                                         kernel_initializer=initializer,\n",
    "                                         activation='tanh')\n",
    "\n",
    "    concat = tf.keras.layers.Concatenate()\n",
    "\n",
    "    father = tf.keras.layers.Input(shape=(img_size,img_size,3))\n",
    "    mother = tf.keras.layers.Input(shape=(img_size,img_size,3))\n",
    "\n",
    "    \n",
    "    \n",
    "    x1 = father\n",
    "    for down in down_stack_parent:\n",
    "        x1 = down(x1)\n",
    "    \n",
    "#     print(x1.shape)\n",
    "    \n",
    "    x2 = mother\n",
    "    for down in down_stack_parent:\n",
    "        x2 = down(x2) \n",
    "    \n",
    "#     print(x2.shape)\n",
    "    \n",
    "    final = concat([x1,x2])\n",
    "#     print(final.shape)\n",
    "    final = final_conv[0](final)\n",
    "    \n",
    "    final = last(final)\n",
    "#     print(final.shape)\n",
    "    return tf.keras.Model(inputs=[father, mother], outputs=final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = EncoderNN()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "family_data = generate_image(all_families[700])\n",
    "noise = tf.random.normal((4,4,64),mean=0.0,stddev=1.0,dtype=tf.dtypes.float32)\n",
    "inp = np.array([family_data[0],family_data[1]])\n",
    "inp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_optimizer = tf.keras.optimizers.Adam(learning_rate = lr, beta_1=b1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tensor_to_array(tensor1):\n",
    "    return tensor1.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_encoder(father_batch, mother_batch, target_batch, b_size):\n",
    "    with tf.GradientTape() as enc_tape:\n",
    "        gen_outputs = encoder([father_batch, mother_batch], training=True)\n",
    "        \n",
    "        diff = tf.abs(target_batch - gen_outputs)\n",
    "        flatten_diff = tf.reshape(diff, (b_size, img_size*img_size*3))\n",
    "        \n",
    "        encoder_loss_batch = tf.reduce_mean(flatten_diff, axis=1)\n",
    "        encoder_loss = tf.reduce_mean(encoder_loss_batch)\n",
    "    \n",
    "    print(\"ENCODER_LOSS: \",tensor_to_array(encoder_loss))\n",
    "    #calculate gradients\n",
    "    encoder_gradients = enc_tape.gradient(encoder_loss,encoder.trainable_variables)\n",
    "\n",
    "    #apply gradients on optimizer\n",
    "    encoder_optimizer.apply_gradients(zip(encoder_gradients,encoder.trainable_variables))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_encoder(train_ds, epochs, test_ds, batch):\n",
    "    losses=np.array([])\n",
    "    for epoch in range(epochs):\n",
    "        print(\"______________________________EPOCH %d_______________________________\"%(epoch+1))\n",
    "        start = time.time()\n",
    "        for i in range(len(train_ds)//batch):\n",
    "            batch_data = np.asarray(generate_batch(train_ds[i*batch:(i+1)*batch]))\n",
    "            batch_data = batch_data / 255 * 2 -1\n",
    "            \n",
    "            \n",
    "            print(\"Generated batch\", batch_data.shape)\n",
    "\n",
    "            X_Father_train = tf.convert_to_tensor(batch_data[:,0],dtype =tf.float32)\n",
    "            X_Mother_train = tf.convert_to_tensor(batch_data[:,1],dtype =tf.float32)\n",
    "            Y_train = tf.convert_to_tensor(batch_data[:,3],dtype =tf.float32)\n",
    "            \n",
    "            train_encoder(X_Father_train, X_Mother_train, Y_train,batch)\n",
    "            \n",
    "            print(\"Trained for batch %d/%d\"%(i+1,(len(train_ds)//batch)))\n",
    "    print(\"______________________________TRAINING COMPLETED_______________________________\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_dataset = all_families[:-100]\n",
    "test_dataset = all_families[-100:]\n",
    "encoder = EncoderNN()\n",
    "\n",
    "with tf.device('/gpu:0'):\n",
    "    fit_encoder(train_dataset, EPOCHS, test_dataset,batch)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "family_no = 400\n",
    "family_data = generate_image(all_families[family_no][0], all_families[family_no][1], all_families[family_no][2])\n",
    "inp = [family_data[0],family_data[1]]\n",
    "inp = tf.cast(inp, tf.float32)\n",
    "father_inp = inp[0][tf.newaxis,...]\n",
    "mother_inp = inp[1][tf.newaxis,...]\n",
    "with tf.device('/gpu:0'):\n",
    "    gen_output = encoder([father_inp, mother_inp], training=True)\n",
    "temp = gen_output.numpy()\n",
    "plt.imshow(np.squeeze(temp))\n",
    "# print(temp)\n",
    "print(np.amin(temp))\n",
    "print(np.amax(temp))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "family_data = generate_image(all_families[126])\n",
    "inp = [family_data[0],family_data[1]]\n",
    "inp = tf.cast(inp, tf.float32)\n",
    "father_inp = inp[0][tf.newaxis,...]\n",
    "mother_inp = inp[1][tf.newaxis,...]\n",
    "with tf.device('/gpu:0'):\n",
    "    gen_output = encoder([father_inp, mother_inp], training=True)\n",
    "temp = gen_output.numpy()\n",
    "temp = np.squeeze(temp)\n",
    "plt.imshow(temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###############################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def disc_downsample_parent_target(filters, size, apply_batchnorm=True):\n",
    "    initializer = tf.random_normal_initializer(mean, std_dev) \n",
    "  \n",
    "\n",
    "    result = tf.keras.Sequential()\n",
    "    result.add(\n",
    "      tf.keras.layers.Conv2D(filters, size, strides=2, padding='same',\n",
    "                             kernel_initializer=initializer,\n",
    "                             use_bias=False))\n",
    "\n",
    "    if apply_batchnorm:\n",
    "        result.add(tf.keras.layers.BatchNormalization())\n",
    "        \n",
    "    result.add(tf.keras.layers.LeakyReLU(alpha = 0.2))\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def disc_loss(filters, size,apply_batchnorm = False):\n",
    "    initializer = tf.random_normal_initializer(mean, std_dev)\n",
    "\n",
    "    result = tf.keras.Sequential()\n",
    "    result.add(\n",
    "    tf.keras.layers.Conv2D(filters, size, strides=2,\n",
    "                                    padding='same',\n",
    "                                    kernel_initializer=initializer,\n",
    "                                   use_bias=False))\n",
    "    if apply_batchnorm:\n",
    "        result.add(tf.keras.layers.BatchNormalization())\n",
    "        \n",
    "    result.add(tf.keras.layers.LeakyReLU(alpha = 0.2))\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Discriminator():\n",
    "\n",
    "    father = tf.keras.layers.Input(shape=(img_size,img_size,3))\n",
    "    mother = tf.keras.layers.Input(shape=(img_size,img_size,3))\n",
    "    target = tf.keras.layers.Input(shape=(img_size,img_size,3))\n",
    "    \n",
    "    down_stack_parent_target = [\n",
    "    disc_downsample_parent_target(32,4,apply_batchnorm=False), #32x32x32\n",
    "    disc_downsample_parent_target(64,4,apply_batchnorm=True)   #16x16x64\n",
    "    ]\n",
    "    \n",
    "    down_stack_combined =[\n",
    "    disc_loss(192,4,apply_batchnorm=True),\n",
    "    disc_loss(256,4,apply_batchnorm=False)\n",
    "    ]\n",
    "    \n",
    "    initializer = tf.random_normal_initializer(mean, sd_random_normal_init)\n",
    "    last = tf.keras.layers.Conv2D(1, 4, strides=1,padding='same',\n",
    "                                  kernel_initializer=initializer) # linear layer\n",
    "    \n",
    "    \n",
    "    concat = tf.keras.layers.Concatenate()\n",
    "    x1 = father\n",
    "    for down in down_stack_parent_target:\n",
    "        x1 = down(x1)\n",
    "    \n",
    "    x2 = mother\n",
    "    for down in down_stack_parent_target:\n",
    "        x2 = down(x2)\n",
    "        \n",
    "    x3 = target\n",
    "    for down in down_stack_parent_target:\n",
    "        x3 = down(x3)\n",
    "    \n",
    "    combined = concat([x1,x2,x3])\n",
    "    # combined is Batchx16x16x192\n",
    "    \n",
    "    x4 = combined\n",
    "    for down in down_stack_combined:\n",
    "        x4 = down(x4)\n",
    "#     print(x4.shape)\n",
    "    \n",
    "    output = last(x4) #4X4 \n",
    "#     print(output.shape)\n",
    "\n",
    "    return tf.keras.Model(inputs=[father,mother,target], outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator = Discriminator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# family_data = generate_image(all_families[126])\n",
    "# p1 = tf.cast(family_data[0], tf.float32)\n",
    "# p2 = tf.cast(family_data[1], tf.float32)\n",
    "# c = tf.cast(family_data[2], tf.float32)\n",
    "\n",
    "# discriminator = Discriminator()\n",
    "# with tf.device('/cpu:0'):\n",
    "#     disc_out = discriminator(inputs = [p1,p2,c], training=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LAMBDA = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tensor_to_array(tensor1):\n",
    "    return tensor1.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator_loss(disc_real_output, disc_generated_output,b_size):\n",
    "    real_loss_diff = tf.abs(tf.ones_like(disc_real_output) - disc_real_output)\n",
    "    real_flatten_diff = tf.reshape(real_loss_diff, (b_size, 4*4*1))\n",
    "    real_loss_batch = tf.reduce_mean(real_flatten_diff, axis=1)\n",
    "    real_loss = tf.reduce_mean(real_loss_batch)\n",
    "    \n",
    "    gen_loss_diff = tf.abs(tf.zeros_like(disc_generated_output) - disc_generated_output)\n",
    "    gen_flatten_diff = tf.reshape(gen_loss_diff, (b_size, 4*4*1))\n",
    "    gen_loss_batch = tf.reduce_mean(gen_flatten_diff, axis=1)\n",
    "    gen_loss = tf.reduce_mean(gen_loss_batch)\n",
    "\n",
    "    total_disc_loss = real_loss + gen_loss\n",
    "    return total_disc_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_loss(disc_generated_output, gen_output, target,b_size):\n",
    "    gen_loss_diff = tf.abs(tf.ones_like(disc_generated_output) - disc_generated_output)\n",
    "    gen_flatten_diff = tf.reshape(gen_loss_diff, (b_size, 4*4*1))\n",
    "    gen_loss_batch = tf.reduce_mean(gen_flatten_diff, axis=1)\n",
    "    gen_loss = tf.reduce_mean(gen_loss_batch)\n",
    "    \n",
    "    l1_loss_diff = tf.abs(target - gen_output)\n",
    "    l1_flatten_diff = tf.reshape(l1_loss_diff, (b_size, img_size*img_size*3))\n",
    "    l1_loss_batch = tf.reduce_mean(l1_flatten_diff, axis=1)\n",
    "    l1_loss = tf.reduce_mean(l1_loss_batch)\n",
    " \n",
    "    total_gen_loss = l1_loss + LAMBDA * gen_loss  \n",
    "#     print(\"Reconstruction loss: {}, GAN loss: {}\".format(l1_loss, gen_loss))\n",
    "    return total_gen_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_optimizer = tf.keras.optimizers.Adam(lr, beta_1=b1 ,beta_2 = b2)\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(lr, beta_1=b1, beta_2 = b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(father_batch, mother_batch, target_batch,b_size):\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "        \n",
    "        gen_outputs = encoder([father_batch, mother_batch], training=True)\n",
    "#         print(\"Generated outputs\",gen_outputs.shape)\n",
    "        \n",
    "        disc_real_output = discriminator([father_batch, mother_batch, target_batch], training=True)\n",
    "#         print(\"disc_real_output \", disc_real_output.shape)\n",
    "        \n",
    "        disc_generated_output = discriminator([father_batch, mother_batch, gen_outputs], training=True)\n",
    "#         print(\"disc_generated_output \", disc_generated_output.shape)\n",
    "        \n",
    "        gen_loss = generator_loss(disc_generated_output, gen_outputs, target_batch,b_size)\n",
    "        disc_loss = discriminator_loss(disc_real_output, disc_generated_output,b_size)\n",
    "    \n",
    "        \n",
    "    print(\"GEN_LOSS\",tensor_to_array(gen_loss))\n",
    "    print(\"DISC_LOSS\",tensor_to_array(disc_loss))\n",
    "\n",
    "    generator_gradients = gen_tape.gradient(gen_loss,encoder.trainable_variables)\n",
    "    discriminator_gradients = disc_tape.gradient(disc_loss,discriminator.trainable_variables)\n",
    "\n",
    "    generator_optimizer.apply_gradients(zip(generator_gradients,encoder.trainable_variables))\n",
    "    discriminator_optimizer.apply_gradients(zip(discriminator_gradients,discriminator.trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(train_ds, epochs, test_ds,batch):\n",
    "    for epoch in range(epochs):\n",
    "        print(\"______________________________EPOCH %d_______________________________\"%(epoch))\n",
    "        start = time.time()\n",
    "        for i in range(len(train_ds)//batch):\n",
    "            batch_data = np.asarray(generate_batch(train_ds[i*batch:(i+1)*batch]))\n",
    "            batch_data = batch_data / 255 * 2 -1\n",
    "            \n",
    "            print(\"Generated batch\", batch_data.shape)\n",
    "\n",
    "            X_father_train = tf.convert_to_tensor(batch_data[:,0],dtype =tf.float32)\n",
    "            X_mother_train = tf.convert_to_tensor(batch_data[:,1],dtype =tf.float32)\n",
    "#             print(\"Xtrain\",X_train.shape)\n",
    "#             print(\"Batch converted to tensor\")\n",
    "\n",
    "            Y_train = tf.convert_to_tensor(batch_data[:,3],dtype =tf.float32)\n",
    "            train_step(X_father_train, X_mother_train, Y_train, batch)\n",
    "            print(\"Trained for batch %d/%d\"%(i+1,(len(train_ds)//batch)))\n",
    "            \n",
    "        family_no = 400\n",
    "        family_data = generate_image(all_families[family_no][0], all_families[family_no][1], all_families[family_no][2])\n",
    "        inp = [family_data[0],family_data[1]]\n",
    "        inp = tf.cast(inp, tf.float32)\n",
    "        father_inp = inp[0][tf.newaxis,...]\n",
    "        mother_inp = inp[1][tf.newaxis,...]\n",
    "        with tf.device('/gpu:0'):\n",
    "            gen_output = encoder([father_inp, mother_inp], training=True)\n",
    "        temp = gen_output.numpy()\n",
    "        plt.imshow(np.squeeze(temp))\n",
    "        print(np.amin(temp))\n",
    "        print(np.amax(temp))\n",
    "    \n",
    "    print(\"______________________________TRAINING COMPLETED_______________________________\")\n",
    "    checkpoint.save(file_prefix = checkpoint_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat = tf.keras.layers.Concatenate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = all_families[:-500]\n",
    "test_dataset = all_families[-500:]\n",
    "encoder = EncoderNN()\n",
    "discriminator = Discriminator()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "mean = 0.001\n",
    "std_dev = 0.0135\n",
    "lr = 0.0005\n",
    "b1 = 0.75\n",
    "b2 = 0.80\n",
    "sd_random_normal_init = 0.0135\n",
    "\n",
    "EPOCHS = 20\n",
    "batch = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = './checkpoint'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n",
    "                                 discriminator_optimizer=discriminator_optimizer,\n",
    "                                 generator=encoder,\n",
    "                                 discriminator=discriminator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "with tf.device('/gpu:0'):\n",
    "    fit(train_dataset, EPOCHS, test_dataset,batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "family_no = 400\n",
    "family_data = generate_image(all_families[family_no][0], all_families[family_no][1], all_families[family_no][2])\n",
    "inp = [family_data[0],family_data[1]]\n",
    "inp = tf.cast(inp, tf.float32)\n",
    "father_inp = inp[0][tf.newaxis,...]\n",
    "mother_inp = inp[1][tf.newaxis,...]\n",
    "with tf.device('/gpu:0'):\n",
    "    gen_output = encoder([father_inp, mother_inp], training=True)\n",
    "temp = gen_output.numpy()\n",
    "plt.imshow(np.squeeze(temp))\n",
    "print(np.amin(temp))\n",
    "print(np.amax(temp))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu-3.7",
   "language": "python",
   "name": "gpu-3.7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
