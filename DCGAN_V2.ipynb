{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "3.7.5\n"
     ]
    }
   ],
   "source": [
    "from platform import python_version\n",
    "import tensorflow as tf\n",
    "\n",
    "print(tf.test.is_gpu_available())\n",
    "print(python_version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "from PIL import Image\n",
    "import time\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers,models,optimizers\n",
    "from keras import backend as K\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "path1=\"datasets/ofg_family/\"\n",
    "path2=\"datasets/TSKinFace_Data/TSKinFace_cropped/\"\n",
    "\n",
    "randomiser = np.random.RandomState(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = 64\n",
    "mean = 0.0009\n",
    "std_dev = 0.009\n",
    "lr = 0.0005\n",
    "b1 = 0.875\n",
    "b2 = 0.975\n",
    "sd_random_normal_init = 0.02\n",
    "\n",
    "EPOCHS = 10\n",
    "batch = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_image_1(family_dir):\n",
    "    dic={}\n",
    "    sub=[a for a in listdir(path1+\"/\"+family_dir)]\n",
    "    \n",
    "    for ele in sub:\n",
    "        if ele == '.DS_Store':\n",
    "            continue;\n",
    "        mypath = path1+\"/\"+family_dir+\"/\"+ele+\"/\"\n",
    "        onlyfiles = [mypath+f for f in listdir(mypath)]\n",
    "        \n",
    "        addr = randomiser.choice(onlyfiles)\n",
    "        original_img = np.array(Image.open(addr).resize((64,64),Image.ANTIALIAS))\n",
    "        if ele[0].lower()=='f':\n",
    "            dic['father'] = original_img\n",
    "        elif ele[0].lower()=='m':\n",
    "            dic['mother'] = original_img\n",
    "        elif ele.lower()=='child_male':\n",
    "            dic['child'] = original_img    \n",
    "            dic['gender']=np.zeros((original_img.shape))\n",
    "        elif ele.lower()=='child_female':\n",
    "            dic['child'] = original_img    \n",
    "            dic['gender'] = np.ones((original_img.shape))\n",
    "    return [dic['father'],dic['mother'],dic['gender'],dic['child']]\n",
    "\n",
    "def generate_image_2(family_dir, family_number, gender):\n",
    "    dic={}\n",
    "    sub = [\"F\" , \"M\", gender]\n",
    "    family_pth = path2+\"/\"+family_dir+\"/\" + family_dir + \"-\" + str(family_number) + \"-\"\n",
    "    for ele in sub:\n",
    "        addr = family_pth+ele+\".jpg\"\n",
    "        original_img = np.array(Image.open(addr).resize((64,64),Image.ANTIALIAS))\n",
    "        if ele =='F':\n",
    "            dic['father'] = original_img\n",
    "        elif ele == 'M':\n",
    "            dic['mother'] = original_img\n",
    "        elif ele == 'S':\n",
    "            dic['child'] = original_img    \n",
    "            dic['gender']=np.zeros((original_img.shape))\n",
    "        elif ele == 'D':\n",
    "            dic['child'] = original_img    \n",
    "            dic['gender'] = np.ones((original_img.shape))\n",
    "    return [dic['father'],dic['mother'],dic['gender'],dic['child']]\n",
    "\n",
    "def generate_batch(families_batch):\n",
    "    np_images=[]\n",
    "    for family in families_batch:\n",
    "        if(len(family) == 3):\n",
    "            res = generate_image_2(family[0], family[1], family[2])\n",
    "        elif(len(family) == 1):\n",
    "            res = generate_image_1(family[0])\n",
    "        if( res != None):\n",
    "            np_images.append(res)\n",
    "    \n",
    "    return np_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "for r, d, f in os.walk(path1):\n",
    "        all_families = d\n",
    "        break      \n",
    "all_families = [[family] for family in all_families] \n",
    "\n",
    "for i in range(285):\n",
    "    all_families.append(['FMS', i+1, 'S'])\n",
    "for i in range(274):\n",
    "    all_families.append(['FMD', i+1, 'D'])\n",
    "    \n",
    "for i in range(228):\n",
    "    all_families.append(['FMSD', i+1, 'D'])  \n",
    "    all_families.append(['FMSD', i+1, 'S'])  \n",
    "\n",
    "\n",
    "randomiser.shuffle(all_families)\n",
    "\n",
    "train_families = all_families[:-100]\n",
    "test_families = all_families[-100:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_CHANNELS = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_downsample_parent(filters, size, apply_batchnorm=True, apply_dropout=False):\n",
    "    initializer = tf.random_normal_initializer(mean, std_dev) \n",
    "  \n",
    "\n",
    "    result = tf.keras.Sequential()\n",
    "    result.add(\n",
    "      tf.keras.layers.Conv2D(filters, size, strides=2, padding='same',\n",
    "                             kernel_initializer=initializer,\n",
    "                             use_bias=False))\n",
    "\n",
    "    if apply_batchnorm:\n",
    "        result.add(tf.keras.layers.BatchNormalization())\n",
    "        \n",
    "    result.add(tf.keras.layers.ELU())\n",
    "        \n",
    "    if apply_dropout:\n",
    "        result.add(tf.keras.layers.Dropout(rate = 0.5))\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def gen_downsample_noise(filters, size, apply_batchnorm=True):\n",
    "    initializer = tf.random_normal_initializer(mean, std_dev) \n",
    "  \n",
    "\n",
    "    result = tf.keras.Sequential()\n",
    "    result.add(\n",
    "      tf.keras.layers.Conv2DTranspose(filters, size, strides=2, padding='same',\n",
    "                             kernel_initializer=initializer,\n",
    "                             use_bias=False))\n",
    "\n",
    "    if apply_batchnorm:\n",
    "        result.add(tf.keras.layers.BatchNormalization())\n",
    "        \n",
    "    result.add(tf.keras.layers.ELU())\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_upsample(filters, size,apply_batchnorm = False):\n",
    "    initializer = tf.random_normal_initializer(mean, std_dev)\n",
    "\n",
    "    result = tf.keras.Sequential()\n",
    "    result.add(\n",
    "    tf.keras.layers.Conv2DTranspose(filters, size, strides=2,\n",
    "                                    padding='same',\n",
    "                                    kernel_initializer=initializer,\n",
    "                                   use_bias=False))\n",
    "    if apply_batchnorm:\n",
    "        result.add(tf.keras.layers.BatchNormalization())\n",
    "        result.add(tf.keras.layers.ELU())\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def EncoderNN():\n",
    "    down_stack_parent = [\n",
    "    gen_downsample_parent(32,4,apply_batchnorm=True, apply_dropout=False),\n",
    "    gen_downsample_parent(64,4,apply_batchnorm=True, apply_dropout=False)\n",
    "    ]\n",
    "    \n",
    "#     down_stack_noise =[\n",
    "# #   z = 4x4x64\n",
    "#     gen_downsample_noise(64,4,apply_batchnorm=True), #8x8x64\n",
    "#     gen_downsample_noise(32,4,apply_batchnorm=True) #16x16x32      \n",
    "#     ]\n",
    "    \n",
    "    final_conv =[\n",
    "        gen_upsample(32,4 ,apply_batchnorm = True)\n",
    "    ]\n",
    "    \n",
    "    initializer = tf.random_normal_initializer(mean, sd_random_normal_init)\n",
    "    last = tf.keras.layers.Conv2DTranspose(OUTPUT_CHANNELS, 4,\n",
    "                                         strides=2,\n",
    "                                         padding='same',\n",
    "                                         kernel_initializer=initializer,\n",
    "                                         activation='tanh')\n",
    "\n",
    "    concat = tf.keras.layers.Concatenate()\n",
    "\n",
    "    father = tf.keras.layers.Input(shape=(img_size,img_size,3))\n",
    "    mother = tf.keras.layers.Input(shape=(img_size,img_size,3))\n",
    "\n",
    "    \n",
    "    \n",
    "    x1 = father\n",
    "    for down in down_stack_parent:\n",
    "        x1 = down(x1)\n",
    "    \n",
    "#     print(x1.shape)\n",
    "    \n",
    "    x2 = mother\n",
    "    for down in down_stack_parent:\n",
    "        x2 = down(x2) \n",
    "    \n",
    "#     print(x2.shape)\n",
    "    \n",
    "    final = concat([x1,x2])\n",
    "#     print(final.shape)\n",
    "    final = final_conv[0](final)\n",
    "    \n",
    "    final = last(final)\n",
    "#     print(final.shape)\n",
    "    return tf.keras.Model(inputs=[father, mother], outputs=final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_optimizer = tf.keras.optimizers.Adam(learning_rate = lr, beta_1=b1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tensor_to_array(tensor1):\n",
    "    return tensor1.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_encoder(father_batch, mother_batch, target_batch, b_size):\n",
    "    with tf.GradientTape() as enc_tape:\n",
    "        gen_outputs = encoder([father_batch, mother_batch], training=True)\n",
    "        \n",
    "        diff = tf.abs(target_batch - gen_outputs)\n",
    "        flatten_diff = tf.reshape(diff, (b_size, img_size*img_size*3))\n",
    "        \n",
    "        encoder_loss_batch = tf.reduce_mean(flatten_diff, axis=1)\n",
    "        encoder_loss = tf.reduce_mean(encoder_loss_batch)\n",
    "    \n",
    "    print(\"ENCODER_LOSS: \",tensor_to_array(encoder_loss))\n",
    "    #calculate gradients\n",
    "    encoder_gradients = enc_tape.gradient(encoder_loss,encoder.trainable_variables)\n",
    "\n",
    "    #apply gradients on optimizer\n",
    "    encoder_optimizer.apply_gradients(zip(encoder_gradients,encoder.trainable_variables))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_encoder(train_ds, epochs, test_ds, batch):\n",
    "    losses=np.array([])\n",
    "    for epoch in range(epochs):\n",
    "        print(\"______________________________EPOCH %d_______________________________\"%(epoch+1))\n",
    "        start = time.time()\n",
    "        for i in range(len(train_ds)//batch):\n",
    "            batch_data = np.asarray(generate_batch(train_ds[i*batch:(i+1)*batch]))\n",
    "            batch_data = batch_data / 255 * 2 -1\n",
    "            \n",
    "            \n",
    "            print(\"Generated batch\", batch_data.shape)\n",
    "\n",
    "            X_Father_train = tf.convert_to_tensor(batch_data[:,0],dtype =tf.float32)\n",
    "            X_Mother_train = tf.convert_to_tensor(batch_data[:,1],dtype =tf.float32)\n",
    "            Y_train = tf.convert_to_tensor(batch_data[:,3],dtype =tf.float32)\n",
    "            \n",
    "            train_encoder(X_Father_train, X_Mother_train, Y_train,batch)\n",
    "            \n",
    "            print(\"Trained for batch %d/%d\"%(i+1,(len(train_ds)//batch)))\n",
    "    print(\"______________________________TRAINING COMPLETED_______________________________\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "______________________________EPOCH 1_______________________________\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.40341973\n",
      "Trained for batch 1/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3747058\n",
      "Trained for batch 2/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.4229235\n",
      "Trained for batch 3/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.4062442\n",
      "Trained for batch 4/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.37259284\n",
      "Trained for batch 5/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.40570754\n",
      "Trained for batch 6/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.43097487\n",
      "Trained for batch 7/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.37538522\n",
      "Trained for batch 8/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3661008\n",
      "Trained for batch 9/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.36800843\n",
      "Trained for batch 10/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3724699\n",
      "Trained for batch 11/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.43448296\n",
      "Trained for batch 12/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35709864\n",
      "Trained for batch 13/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3950496\n",
      "Trained for batch 14/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3688807\n",
      "Trained for batch 15/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3860542\n",
      "Trained for batch 16/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.44605786\n",
      "Trained for batch 17/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34664398\n",
      "Trained for batch 18/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.39454833\n",
      "Trained for batch 19/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.33471403\n",
      "Trained for batch 20/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3614666\n",
      "Trained for batch 21/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.40210095\n",
      "Trained for batch 22/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.42147255\n",
      "Trained for batch 23/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35217696\n",
      "Trained for batch 24/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.38657412\n",
      "Trained for batch 25/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.41433\n",
      "Trained for batch 26/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35280803\n",
      "Trained for batch 27/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32902092\n",
      "Trained for batch 28/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.365082\n",
      "Trained for batch 29/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.36655417\n",
      "Trained for batch 30/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.40149218\n",
      "Trained for batch 31/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35119835\n",
      "Trained for batch 32/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.33154935\n",
      "Trained for batch 33/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.38874537\n",
      "Trained for batch 34/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3770574\n",
      "Trained for batch 35/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.37216097\n",
      "Trained for batch 36/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.30604583\n",
      "Trained for batch 37/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34849322\n",
      "Trained for batch 38/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34970385\n",
      "Trained for batch 39/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35399386\n",
      "Trained for batch 40/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.37763038\n",
      "Trained for batch 41/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3642118\n",
      "Trained for batch 42/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32215607\n",
      "Trained for batch 43/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34084243\n",
      "Trained for batch 44/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3115418\n",
      "Trained for batch 45/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.405502\n",
      "Trained for batch 46/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.33786473\n",
      "Trained for batch 47/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34356505\n",
      "Trained for batch 48/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34688368\n",
      "Trained for batch 49/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35725087\n",
      "Trained for batch 50/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.40099317\n",
      "Trained for batch 51/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.31783652\n",
      "Trained for batch 52/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3588978\n",
      "Trained for batch 53/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3546448\n",
      "Trained for batch 54/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.38290676\n",
      "Trained for batch 55/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35456428\n",
      "Trained for batch 56/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.4008767\n",
      "Trained for batch 57/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.39036384\n",
      "Trained for batch 58/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3118421\n",
      "Trained for batch 59/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.40766144\n",
      "Trained for batch 60/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.33152086\n",
      "Trained for batch 61/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.318183\n",
      "Trained for batch 62/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3289036\n",
      "Trained for batch 63/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.30764475\n",
      "Trained for batch 64/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.2862015\n",
      "Trained for batch 65/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3151431\n",
      "Trained for batch 66/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35122877\n",
      "Trained for batch 67/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.38102263\n",
      "Trained for batch 68/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.31507578\n",
      "Trained for batch 69/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3562093\n",
      "Trained for batch 70/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34080186\n",
      "Trained for batch 71/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34523338\n",
      "Trained for batch 72/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3719592\n",
      "Trained for batch 73/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35613218\n",
      "Trained for batch 74/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.36692142\n",
      "Trained for batch 75/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3916842\n",
      "Trained for batch 76/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.31589094\n",
      "Trained for batch 77/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3126195\n",
      "Trained for batch 78/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.36948365\n",
      "Trained for batch 79/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.40351337\n",
      "Trained for batch 80/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.33806187\n",
      "Trained for batch 81/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.31995544\n",
      "Trained for batch 82/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3503887\n",
      "Trained for batch 83/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3623436\n",
      "Trained for batch 84/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35348386\n",
      "Trained for batch 85/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.39553097\n",
      "Trained for batch 86/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3288309\n",
      "Trained for batch 87/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.40606794\n",
      "Trained for batch 88/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32926646\n",
      "Trained for batch 89/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34279853\n",
      "Trained for batch 90/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3104426\n",
      "Trained for batch 91/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.38569975\n",
      "Trained for batch 92/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.38053983\n",
      "Trained for batch 93/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34726876\n",
      "Trained for batch 94/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3098844\n",
      "Trained for batch 95/297\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3418943\n",
      "Trained for batch 96/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32782188\n",
      "Trained for batch 97/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3961449\n",
      "Trained for batch 98/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.4083057\n",
      "Trained for batch 99/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3278299\n",
      "Trained for batch 100/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34413868\n",
      "Trained for batch 101/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.38020015\n",
      "Trained for batch 102/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3772472\n",
      "Trained for batch 103/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3852674\n",
      "Trained for batch 104/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.40276408\n",
      "Trained for batch 105/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.40233207\n",
      "Trained for batch 106/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.40068522\n",
      "Trained for batch 107/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.37049\n",
      "Trained for batch 108/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32912558\n",
      "Trained for batch 109/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.38004512\n",
      "Trained for batch 110/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.36647478\n",
      "Trained for batch 111/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3394824\n",
      "Trained for batch 112/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.40759143\n",
      "Trained for batch 113/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3582391\n",
      "Trained for batch 114/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3369761\n",
      "Trained for batch 115/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.33504963\n",
      "Trained for batch 116/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.39396816\n",
      "Trained for batch 117/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3000876\n",
      "Trained for batch 118/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34635255\n",
      "Trained for batch 119/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.36694965\n",
      "Trained for batch 120/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.31094608\n",
      "Trained for batch 121/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.33864194\n",
      "Trained for batch 122/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3589235\n",
      "Trained for batch 123/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.30613384\n",
      "Trained for batch 124/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.351471\n",
      "Trained for batch 125/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.36603197\n",
      "Trained for batch 126/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.37361926\n",
      "Trained for batch 127/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.37908292\n",
      "Trained for batch 128/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.36170238\n",
      "Trained for batch 129/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.33452803\n",
      "Trained for batch 130/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.36218885\n",
      "Trained for batch 131/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35869986\n",
      "Trained for batch 132/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.36955762\n",
      "Trained for batch 133/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3598127\n",
      "Trained for batch 134/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.37451762\n",
      "Trained for batch 135/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34073627\n",
      "Trained for batch 136/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3565013\n",
      "Trained for batch 137/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3290338\n",
      "Trained for batch 138/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.33184046\n",
      "Trained for batch 139/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35839128\n",
      "Trained for batch 140/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3746533\n",
      "Trained for batch 141/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.40055758\n",
      "Trained for batch 142/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.39849436\n",
      "Trained for batch 143/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3598178\n",
      "Trained for batch 144/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.37936616\n",
      "Trained for batch 145/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3399381\n",
      "Trained for batch 146/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35540384\n",
      "Trained for batch 147/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.36530238\n",
      "Trained for batch 148/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32297707\n",
      "Trained for batch 149/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35357457\n",
      "Trained for batch 150/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34338614\n",
      "Trained for batch 151/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.33494866\n",
      "Trained for batch 152/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34781784\n",
      "Trained for batch 153/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35041833\n",
      "Trained for batch 154/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.33357236\n",
      "Trained for batch 155/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.37624672\n",
      "Trained for batch 156/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.33619896\n",
      "Trained for batch 157/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32835624\n",
      "Trained for batch 158/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.33670765\n",
      "Trained for batch 159/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34308815\n",
      "Trained for batch 160/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34738016\n",
      "Trained for batch 161/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3164476\n",
      "Trained for batch 162/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.4058362\n",
      "Trained for batch 163/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.33897725\n",
      "Trained for batch 164/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3627148\n",
      "Trained for batch 165/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34604043\n",
      "Trained for batch 166/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3272407\n",
      "Trained for batch 167/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32592872\n",
      "Trained for batch 168/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3369739\n",
      "Trained for batch 169/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.31541196\n",
      "Trained for batch 170/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.37738052\n",
      "Trained for batch 171/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34293395\n",
      "Trained for batch 172/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.36903626\n",
      "Trained for batch 173/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.39481682\n",
      "Trained for batch 174/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.40912443\n",
      "Trained for batch 175/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.36937547\n",
      "Trained for batch 176/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.39203212\n",
      "Trained for batch 177/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.30162996\n",
      "Trained for batch 178/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3508251\n",
      "Trained for batch 179/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.31752685\n",
      "Trained for batch 180/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32552582\n",
      "Trained for batch 181/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.37447137\n",
      "Trained for batch 182/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.38042808\n",
      "Trained for batch 183/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.4098319\n",
      "Trained for batch 184/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.33308834\n",
      "Trained for batch 185/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35219592\n",
      "Trained for batch 186/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32845524\n",
      "Trained for batch 187/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3455466\n",
      "Trained for batch 188/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.39791098\n",
      "Trained for batch 189/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.37015155\n",
      "Trained for batch 190/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.36830154\n",
      "Trained for batch 191/297\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35476568\n",
      "Trained for batch 192/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.30310583\n",
      "Trained for batch 193/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32215577\n",
      "Trained for batch 194/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.39985672\n",
      "Trained for batch 195/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3774629\n",
      "Trained for batch 196/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3994551\n",
      "Trained for batch 197/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.41230774\n",
      "Trained for batch 198/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3691421\n",
      "Trained for batch 199/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34682274\n",
      "Trained for batch 200/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35760108\n",
      "Trained for batch 201/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3703218\n",
      "Trained for batch 202/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.38052118\n",
      "Trained for batch 203/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34548306\n",
      "Trained for batch 204/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.38417575\n",
      "Trained for batch 205/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3626496\n",
      "Trained for batch 206/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3327333\n",
      "Trained for batch 207/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35859448\n",
      "Trained for batch 208/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.31412768\n",
      "Trained for batch 209/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.4087223\n",
      "Trained for batch 210/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.33559346\n",
      "Trained for batch 211/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35813218\n",
      "Trained for batch 212/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34245703\n",
      "Trained for batch 213/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.31584492\n",
      "Trained for batch 214/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.372717\n",
      "Trained for batch 215/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32986602\n",
      "Trained for batch 216/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32561958\n",
      "Trained for batch 217/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35080227\n",
      "Trained for batch 218/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.29995838\n",
      "Trained for batch 219/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.36787492\n",
      "Trained for batch 220/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34204534\n",
      "Trained for batch 221/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32174462\n",
      "Trained for batch 222/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32507995\n",
      "Trained for batch 223/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.36532563\n",
      "Trained for batch 224/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.43838763\n",
      "Trained for batch 225/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35078615\n",
      "Trained for batch 226/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34059104\n",
      "Trained for batch 227/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.33669445\n",
      "Trained for batch 228/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3465475\n",
      "Trained for batch 229/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.29561645\n",
      "Trained for batch 230/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34386414\n",
      "Trained for batch 231/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34123188\n",
      "Trained for batch 232/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3778117\n",
      "Trained for batch 233/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3309192\n",
      "Trained for batch 234/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.31123477\n",
      "Trained for batch 235/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.31792578\n",
      "Trained for batch 236/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34541398\n",
      "Trained for batch 237/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.36553982\n",
      "Trained for batch 238/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.33304718\n",
      "Trained for batch 239/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.30014628\n",
      "Trained for batch 240/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32886332\n",
      "Trained for batch 241/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.33435488\n",
      "Trained for batch 242/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.36138263\n",
      "Trained for batch 243/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.31001395\n",
      "Trained for batch 244/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.36772257\n",
      "Trained for batch 245/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3397925\n",
      "Trained for batch 246/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.33811983\n",
      "Trained for batch 247/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.36868283\n",
      "Trained for batch 248/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3294046\n",
      "Trained for batch 249/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35071772\n",
      "Trained for batch 250/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35415906\n",
      "Trained for batch 251/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.39565587\n",
      "Trained for batch 252/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3319091\n",
      "Trained for batch 253/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3622118\n",
      "Trained for batch 254/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.37385198\n",
      "Trained for batch 255/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3426749\n",
      "Trained for batch 256/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.33036104\n",
      "Trained for batch 257/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3591022\n",
      "Trained for batch 258/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.33705598\n",
      "Trained for batch 259/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.40358075\n",
      "Trained for batch 260/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3276917\n",
      "Trained for batch 261/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.37832603\n",
      "Trained for batch 262/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32308763\n",
      "Trained for batch 263/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3797599\n",
      "Trained for batch 264/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3157265\n",
      "Trained for batch 265/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34170756\n",
      "Trained for batch 266/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3930717\n",
      "Trained for batch 267/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.4349234\n",
      "Trained for batch 268/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35096374\n",
      "Trained for batch 269/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.39138955\n",
      "Trained for batch 270/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34437346\n",
      "Trained for batch 271/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3440649\n",
      "Trained for batch 272/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.39172333\n",
      "Trained for batch 273/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.41015998\n",
      "Trained for batch 274/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35652637\n",
      "Trained for batch 275/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.33260292\n",
      "Trained for batch 276/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3518052\n",
      "Trained for batch 277/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3637877\n",
      "Trained for batch 278/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34804767\n",
      "Trained for batch 279/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.37677115\n",
      "Trained for batch 280/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.31042546\n",
      "Trained for batch 281/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.37373203\n",
      "Trained for batch 282/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.40547252\n",
      "Trained for batch 283/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.36500305\n",
      "Trained for batch 284/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.36045307\n",
      "Trained for batch 285/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.37550953\n",
      "Trained for batch 286/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3728792\n",
      "Trained for batch 287/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.33425462\n",
      "Trained for batch 288/297\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.38096565\n",
      "Trained for batch 289/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34656438\n",
      "Trained for batch 290/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.37729165\n",
      "Trained for batch 291/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32616666\n",
      "Trained for batch 292/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.2984097\n",
      "Trained for batch 293/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3828677\n",
      "Trained for batch 294/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.4285779\n",
      "Trained for batch 295/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3626742\n",
      "Trained for batch 296/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.36576393\n",
      "Trained for batch 297/297\n",
      "______________________________EPOCH 2_______________________________\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.36520624\n",
      "Trained for batch 1/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32794917\n",
      "Trained for batch 2/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.30993694\n",
      "Trained for batch 3/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.4052969\n",
      "Trained for batch 4/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.37279043\n",
      "Trained for batch 5/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3762009\n",
      "Trained for batch 6/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.40672565\n",
      "Trained for batch 7/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.374333\n",
      "Trained for batch 8/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.38907585\n",
      "Trained for batch 9/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32834107\n",
      "Trained for batch 10/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.36100215\n",
      "Trained for batch 11/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35098758\n",
      "Trained for batch 12/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34123206\n",
      "Trained for batch 13/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3772146\n",
      "Trained for batch 14/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3358142\n",
      "Trained for batch 15/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3575122\n",
      "Trained for batch 16/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3844834\n",
      "Trained for batch 17/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.33725756\n",
      "Trained for batch 18/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35629722\n",
      "Trained for batch 19/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3323529\n",
      "Trained for batch 20/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.33170578\n",
      "Trained for batch 21/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.37422842\n",
      "Trained for batch 22/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.37106892\n",
      "Trained for batch 23/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.40584904\n",
      "Trained for batch 24/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34483737\n",
      "Trained for batch 25/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.38883993\n",
      "Trained for batch 26/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34009725\n",
      "Trained for batch 27/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3054936\n",
      "Trained for batch 28/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3609543\n",
      "Trained for batch 29/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34295562\n",
      "Trained for batch 30/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3138731\n",
      "Trained for batch 31/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.33774894\n",
      "Trained for batch 32/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.30921394\n",
      "Trained for batch 33/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.36784497\n",
      "Trained for batch 34/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.4011876\n",
      "Trained for batch 35/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3255808\n",
      "Trained for batch 36/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.33247924\n",
      "Trained for batch 37/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.30828112\n",
      "Trained for batch 38/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3755627\n",
      "Trained for batch 39/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35171875\n",
      "Trained for batch 40/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.362099\n",
      "Trained for batch 41/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3403306\n",
      "Trained for batch 42/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3142822\n",
      "Trained for batch 43/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35506493\n",
      "Trained for batch 44/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.30466175\n",
      "Trained for batch 45/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3587524\n",
      "Trained for batch 46/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.33305913\n",
      "Trained for batch 47/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32108563\n",
      "Trained for batch 48/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.33209193\n",
      "Trained for batch 49/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34146315\n",
      "Trained for batch 50/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.37148586\n",
      "Trained for batch 51/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3091886\n",
      "Trained for batch 52/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3776757\n",
      "Trained for batch 53/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.36533535\n",
      "Trained for batch 54/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32305703\n",
      "Trained for batch 55/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34112933\n",
      "Trained for batch 56/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.40553084\n",
      "Trained for batch 57/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.37190977\n",
      "Trained for batch 58/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.28287682\n",
      "Trained for batch 59/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.47471452\n",
      "Trained for batch 60/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.2972132\n",
      "Trained for batch 61/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3220799\n",
      "Trained for batch 62/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3396409\n",
      "Trained for batch 63/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.30795377\n",
      "Trained for batch 64/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3270313\n",
      "Trained for batch 65/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3257032\n",
      "Trained for batch 66/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.38823017\n",
      "Trained for batch 67/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.36901578\n",
      "Trained for batch 68/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.2860408\n",
      "Trained for batch 69/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3723581\n",
      "Trained for batch 70/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.36666134\n",
      "Trained for batch 71/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35174757\n",
      "Trained for batch 72/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34395018\n",
      "Trained for batch 73/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.38856047\n",
      "Trained for batch 74/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3441348\n",
      "Trained for batch 75/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.37042677\n",
      "Trained for batch 76/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.31530416\n",
      "Trained for batch 77/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.31988853\n",
      "Trained for batch 78/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3517403\n",
      "Trained for batch 79/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.36979455\n",
      "Trained for batch 80/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.36367926\n",
      "Trained for batch 81/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.28282306\n",
      "Trained for batch 82/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.33897677\n",
      "Trained for batch 83/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.36634192\n",
      "Trained for batch 84/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34503275\n",
      "Trained for batch 85/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3499847\n",
      "Trained for batch 86/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35252118\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained for batch 87/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.4009406\n",
      "Trained for batch 88/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32550102\n",
      "Trained for batch 89/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32527357\n",
      "Trained for batch 90/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.30826584\n",
      "Trained for batch 91/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.36444038\n",
      "Trained for batch 92/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.362953\n",
      "Trained for batch 93/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.36955935\n",
      "Trained for batch 94/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32375208\n",
      "Trained for batch 95/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3094355\n",
      "Trained for batch 96/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34374073\n",
      "Trained for batch 97/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.37855554\n",
      "Trained for batch 98/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.4011186\n",
      "Trained for batch 99/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.324022\n",
      "Trained for batch 100/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.435646\n",
      "Trained for batch 101/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35776407\n",
      "Trained for batch 102/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.40210813\n",
      "Trained for batch 103/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3571113\n",
      "Trained for batch 104/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3635715\n",
      "Trained for batch 105/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3600475\n",
      "Trained for batch 106/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.43170014\n",
      "Trained for batch 107/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.31925228\n",
      "Trained for batch 108/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.31491166\n",
      "Trained for batch 109/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.36494517\n",
      "Trained for batch 110/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.38127318\n",
      "Trained for batch 111/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32712826\n",
      "Trained for batch 112/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35578018\n",
      "Trained for batch 113/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.37780505\n",
      "Trained for batch 114/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.321928\n",
      "Trained for batch 115/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.327529\n",
      "Trained for batch 116/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.40191713\n",
      "Trained for batch 117/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34194952\n",
      "Trained for batch 118/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3232661\n",
      "Trained for batch 119/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.41648874\n",
      "Trained for batch 120/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.31370553\n",
      "Trained for batch 121/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.332709\n",
      "Trained for batch 122/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.36667323\n",
      "Trained for batch 123/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.31702614\n",
      "Trained for batch 124/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34509462\n",
      "Trained for batch 125/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35758322\n",
      "Trained for batch 126/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.39119914\n",
      "Trained for batch 127/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34792262\n",
      "Trained for batch 128/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.33926925\n",
      "Trained for batch 129/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32991737\n",
      "Trained for batch 130/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.33353382\n",
      "Trained for batch 131/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3351348\n",
      "Trained for batch 132/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.37091914\n",
      "Trained for batch 133/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3707065\n",
      "Trained for batch 134/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3026734\n",
      "Trained for batch 135/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32896718\n",
      "Trained for batch 136/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35616434\n",
      "Trained for batch 137/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34039658\n",
      "Trained for batch 138/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.31662077\n",
      "Trained for batch 139/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.4015401\n",
      "Trained for batch 140/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34988374\n",
      "Trained for batch 141/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34644222\n",
      "Trained for batch 142/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35687762\n",
      "Trained for batch 143/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3660871\n",
      "Trained for batch 144/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.40144864\n",
      "Trained for batch 145/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3135908\n",
      "Trained for batch 146/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.36399776\n",
      "Trained for batch 147/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35609967\n",
      "Trained for batch 148/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.30775553\n",
      "Trained for batch 149/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.31388804\n",
      "Trained for batch 150/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35898617\n",
      "Trained for batch 151/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3139713\n",
      "Trained for batch 152/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3348033\n",
      "Trained for batch 153/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34035268\n",
      "Trained for batch 154/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3312343\n",
      "Trained for batch 155/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3449951\n",
      "Trained for batch 156/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3364535\n",
      "Trained for batch 157/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3148778\n",
      "Trained for batch 158/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.29775324\n",
      "Trained for batch 159/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.33401546\n",
      "Trained for batch 160/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.29969987\n",
      "Trained for batch 161/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3047192\n",
      "Trained for batch 162/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3468213\n",
      "Trained for batch 163/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35016322\n",
      "Trained for batch 164/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.36663526\n",
      "Trained for batch 165/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3693399\n",
      "Trained for batch 166/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32407802\n",
      "Trained for batch 167/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32686386\n",
      "Trained for batch 168/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35488564\n",
      "Trained for batch 169/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3258211\n",
      "Trained for batch 170/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.39244446\n",
      "Trained for batch 171/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3717475\n",
      "Trained for batch 172/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3612748\n",
      "Trained for batch 173/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.39184543\n",
      "Trained for batch 174/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35473675\n",
      "Trained for batch 175/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.40509424\n",
      "Trained for batch 176/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.38966006\n",
      "Trained for batch 177/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3635152\n",
      "Trained for batch 178/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35808283\n",
      "Trained for batch 179/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3140524\n",
      "Trained for batch 180/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.308513\n",
      "Trained for batch 181/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.38193685\n",
      "Trained for batch 182/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ENCODER_LOSS:  0.38731903\n",
      "Trained for batch 183/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.43327516\n",
      "Trained for batch 184/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.41068235\n",
      "Trained for batch 185/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3507204\n",
      "Trained for batch 186/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34521347\n",
      "Trained for batch 187/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35790005\n",
      "Trained for batch 188/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.36633292\n",
      "Trained for batch 189/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3345775\n",
      "Trained for batch 190/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3892107\n",
      "Trained for batch 191/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34003153\n",
      "Trained for batch 192/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35354093\n",
      "Trained for batch 193/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.30726805\n",
      "Trained for batch 194/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3920226\n",
      "Trained for batch 195/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3650372\n",
      "Trained for batch 196/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.33416504\n",
      "Trained for batch 197/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.41237944\n",
      "Trained for batch 198/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.36314672\n",
      "Trained for batch 199/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34770384\n",
      "Trained for batch 200/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.31955424\n",
      "Trained for batch 201/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3552607\n",
      "Trained for batch 202/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3986216\n",
      "Trained for batch 203/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.38236168\n",
      "Trained for batch 204/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35269618\n",
      "Trained for batch 205/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.37437496\n",
      "Trained for batch 206/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3235992\n",
      "Trained for batch 207/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32074532\n",
      "Trained for batch 208/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32208377\n",
      "Trained for batch 209/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.39694476\n",
      "Trained for batch 210/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.31684968\n",
      "Trained for batch 211/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3605436\n",
      "Trained for batch 212/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32680482\n",
      "Trained for batch 213/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.33468893\n",
      "Trained for batch 214/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.37043458\n",
      "Trained for batch 215/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34121314\n",
      "Trained for batch 216/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.33392176\n",
      "Trained for batch 217/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3571148\n",
      "Trained for batch 218/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.31775057\n",
      "Trained for batch 219/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35774747\n",
      "Trained for batch 220/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.36964303\n",
      "Trained for batch 221/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35498166\n",
      "Trained for batch 222/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35643458\n",
      "Trained for batch 223/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.40587005\n",
      "Trained for batch 224/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35214582\n",
      "Trained for batch 225/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35768446\n",
      "Trained for batch 226/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.30827525\n",
      "Trained for batch 227/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.37719226\n",
      "Trained for batch 228/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34084135\n",
      "Trained for batch 229/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3075633\n",
      "Trained for batch 230/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32477632\n",
      "Trained for batch 231/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.37843\n",
      "Trained for batch 232/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.43105072\n",
      "Trained for batch 233/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3585183\n",
      "Trained for batch 234/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.33888024\n",
      "Trained for batch 235/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3294925\n",
      "Trained for batch 236/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35754246\n",
      "Trained for batch 237/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3438991\n",
      "Trained for batch 238/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32566357\n",
      "Trained for batch 239/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3324098\n",
      "Trained for batch 240/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3044257\n",
      "Trained for batch 241/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3426493\n",
      "Trained for batch 242/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34090218\n",
      "Trained for batch 243/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.29293066\n",
      "Trained for batch 244/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3473838\n",
      "Trained for batch 245/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32333103\n",
      "Trained for batch 246/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3443057\n",
      "Trained for batch 247/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.39537925\n",
      "Trained for batch 248/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.33725327\n",
      "Trained for batch 249/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34409794\n",
      "Trained for batch 250/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3508408\n",
      "Trained for batch 251/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34901154\n",
      "Trained for batch 252/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.33670163\n",
      "Trained for batch 253/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.36487764\n",
      "Trained for batch 254/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.378359\n",
      "Trained for batch 255/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3663569\n",
      "Trained for batch 256/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.31254074\n",
      "Trained for batch 257/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34025386\n",
      "Trained for batch 258/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3408894\n",
      "Trained for batch 259/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3715137\n",
      "Trained for batch 260/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.31837997\n",
      "Trained for batch 261/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.38227972\n",
      "Trained for batch 262/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.316581\n",
      "Trained for batch 263/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3346385\n",
      "Trained for batch 264/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.31089625\n",
      "Trained for batch 265/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.36314026\n",
      "Trained for batch 266/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.31666723\n",
      "Trained for batch 267/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.31155556\n",
      "Trained for batch 268/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.36427468\n",
      "Trained for batch 269/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34453547\n",
      "Trained for batch 270/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34765276\n",
      "Trained for batch 271/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.36595416\n",
      "Trained for batch 272/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3272787\n",
      "Trained for batch 273/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.38035852\n",
      "Trained for batch 274/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.37752146\n",
      "Trained for batch 275/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3980347\n",
      "Trained for batch 276/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.36392087\n",
      "Trained for batch 277/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ENCODER_LOSS:  0.3440715\n",
      "Trained for batch 278/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32737592\n",
      "Trained for batch 279/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3228541\n",
      "Trained for batch 280/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34547263\n",
      "Trained for batch 281/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35670337\n",
      "Trained for batch 282/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.38251057\n",
      "Trained for batch 283/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.36385554\n",
      "Trained for batch 284/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3525514\n",
      "Trained for batch 285/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35728425\n",
      "Trained for batch 286/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.33079183\n",
      "Trained for batch 287/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3042326\n",
      "Trained for batch 288/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.37773532\n",
      "Trained for batch 289/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35308725\n",
      "Trained for batch 290/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.37168342\n",
      "Trained for batch 291/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3246644\n",
      "Trained for batch 292/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3323202\n",
      "Trained for batch 293/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.38100713\n",
      "Trained for batch 294/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.4786272\n",
      "Trained for batch 295/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3206934\n",
      "Trained for batch 296/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3541829\n",
      "Trained for batch 297/297\n",
      "______________________________EPOCH 3_______________________________\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.33749864\n",
      "Trained for batch 1/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3348674\n",
      "Trained for batch 2/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32947612\n",
      "Trained for batch 3/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.36504656\n",
      "Trained for batch 4/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35644802\n",
      "Trained for batch 5/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3588894\n",
      "Trained for batch 6/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.39128557\n",
      "Trained for batch 7/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35298955\n",
      "Trained for batch 8/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.329336\n",
      "Trained for batch 9/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3123563\n",
      "Trained for batch 10/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34723496\n",
      "Trained for batch 11/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.303611\n",
      "Trained for batch 12/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.30805102\n",
      "Trained for batch 13/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3765269\n",
      "Trained for batch 14/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.41146192\n",
      "Trained for batch 15/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3134246\n",
      "Trained for batch 16/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3916811\n",
      "Trained for batch 17/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.33525315\n",
      "Trained for batch 18/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3502825\n",
      "Trained for batch 19/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32002336\n",
      "Trained for batch 20/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32545963\n",
      "Trained for batch 21/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.38441628\n",
      "Trained for batch 22/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.38439155\n",
      "Trained for batch 23/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.40979853\n",
      "Trained for batch 24/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3437413\n",
      "Trained for batch 25/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3675055\n",
      "Trained for batch 26/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34207034\n",
      "Trained for batch 27/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32415596\n",
      "Trained for batch 28/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.40762562\n",
      "Trained for batch 29/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34117448\n",
      "Trained for batch 30/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.38909617\n",
      "Trained for batch 31/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34089833\n",
      "Trained for batch 32/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32469368\n",
      "Trained for batch 33/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.37837046\n",
      "Trained for batch 34/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.33417574\n",
      "Trained for batch 35/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3058775\n",
      "Trained for batch 36/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.38031563\n",
      "Trained for batch 37/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.30450255\n",
      "Trained for batch 38/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34267253\n",
      "Trained for batch 39/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.30312443\n",
      "Trained for batch 40/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32336783\n",
      "Trained for batch 41/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35270867\n",
      "Trained for batch 42/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.29694888\n",
      "Trained for batch 43/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35086983\n",
      "Trained for batch 44/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.2843222\n",
      "Trained for batch 45/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3849036\n",
      "Trained for batch 46/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32524428\n",
      "Trained for batch 47/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.30232054\n",
      "Trained for batch 48/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.2836489\n",
      "Trained for batch 49/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.33670038\n",
      "Trained for batch 50/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.343432\n",
      "Trained for batch 51/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3065557\n",
      "Trained for batch 52/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3463546\n",
      "Trained for batch 53/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3337737\n",
      "Trained for batch 54/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3313673\n",
      "Trained for batch 55/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3777725\n",
      "Trained for batch 56/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.4084506\n",
      "Trained for batch 57/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32498205\n",
      "Trained for batch 58/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.27896714\n",
      "Trained for batch 59/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.422645\n",
      "Trained for batch 60/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.30837306\n",
      "Trained for batch 61/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32770532\n",
      "Trained for batch 62/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.31754628\n",
      "Trained for batch 63/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3081898\n",
      "Trained for batch 64/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.2834191\n",
      "Trained for batch 65/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32634592\n",
      "Trained for batch 66/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.37063438\n",
      "Trained for batch 67/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3998177\n",
      "Trained for batch 68/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32057753\n",
      "Trained for batch 69/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.36853546\n",
      "Trained for batch 70/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.29257718\n",
      "Trained for batch 71/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.31866288\n",
      "Trained for batch 72/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.33928615\n",
      "Trained for batch 73/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.33583525\n",
      "Trained for batch 74/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3340797\n",
      "Trained for batch 75/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3557177\n",
      "Trained for batch 76/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.2983593\n",
      "Trained for batch 77/297\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.29062217\n",
      "Trained for batch 78/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3370381\n",
      "Trained for batch 79/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.40192747\n",
      "Trained for batch 80/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35136476\n",
      "Trained for batch 81/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3260686\n",
      "Trained for batch 82/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3668025\n",
      "Trained for batch 83/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.40478745\n",
      "Trained for batch 84/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.31649667\n",
      "Trained for batch 85/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34536237\n",
      "Trained for batch 86/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.316284\n",
      "Trained for batch 87/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.40579337\n",
      "Trained for batch 88/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35352892\n",
      "Trained for batch 89/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3331198\n",
      "Trained for batch 90/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.36456415\n",
      "Trained for batch 91/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35632834\n",
      "Trained for batch 92/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3059244\n",
      "Trained for batch 93/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35090217\n",
      "Trained for batch 94/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3155017\n",
      "Trained for batch 95/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.30640608\n",
      "Trained for batch 96/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.33668762\n",
      "Trained for batch 97/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.36004025\n",
      "Trained for batch 98/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.38173822\n",
      "Trained for batch 99/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34664577\n",
      "Trained for batch 100/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.37813655\n",
      "Trained for batch 101/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.38680005\n",
      "Trained for batch 102/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.40725604\n",
      "Trained for batch 103/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32766005\n",
      "Trained for batch 104/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35744023\n",
      "Trained for batch 105/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.33407357\n",
      "Trained for batch 106/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.40000933\n",
      "Trained for batch 107/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35053298\n",
      "Trained for batch 108/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.28211015\n",
      "Trained for batch 109/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34976387\n",
      "Trained for batch 110/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35216075\n",
      "Trained for batch 111/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34149933\n",
      "Trained for batch 112/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32931682\n",
      "Trained for batch 113/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.37657353\n",
      "Trained for batch 114/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.30824158\n",
      "Trained for batch 115/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3170444\n",
      "Trained for batch 116/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.36754292\n",
      "Trained for batch 117/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.30071035\n",
      "Trained for batch 118/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.30576134\n",
      "Trained for batch 119/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.44084707\n",
      "Trained for batch 120/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.2823204\n",
      "Trained for batch 121/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3076845\n",
      "Trained for batch 122/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32417426\n",
      "Trained for batch 123/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35327837\n",
      "Trained for batch 124/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.33265257\n",
      "Trained for batch 125/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.37080547\n",
      "Trained for batch 126/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.375022\n",
      "Trained for batch 127/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.38284254\n",
      "Trained for batch 128/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32544532\n",
      "Trained for batch 129/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3394838\n",
      "Trained for batch 130/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3371603\n",
      "Trained for batch 131/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3354351\n",
      "Trained for batch 132/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.30810434\n",
      "Trained for batch 133/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34732375\n",
      "Trained for batch 134/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.36443296\n",
      "Trained for batch 135/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.31229272\n",
      "Trained for batch 136/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35247338\n",
      "Trained for batch 137/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.33510602\n",
      "Trained for batch 138/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.30870908\n",
      "Trained for batch 139/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.41754764\n",
      "Trained for batch 140/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.39013904\n",
      "Trained for batch 141/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3761043\n",
      "Trained for batch 142/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3753695\n",
      "Trained for batch 143/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.41618174\n",
      "Trained for batch 144/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.37832788\n",
      "Trained for batch 145/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.31753337\n",
      "Trained for batch 146/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34044597\n",
      "Trained for batch 147/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35221225\n",
      "Trained for batch 148/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.31301123\n",
      "Trained for batch 149/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35279733\n",
      "Trained for batch 150/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3977901\n",
      "Trained for batch 151/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.33083874\n",
      "Trained for batch 152/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.36491567\n",
      "Trained for batch 153/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.33712667\n",
      "Trained for batch 154/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3211356\n",
      "Trained for batch 155/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3709019\n",
      "Trained for batch 156/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3240945\n",
      "Trained for batch 157/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.33065447\n",
      "Trained for batch 158/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3319226\n",
      "Trained for batch 159/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.36899656\n",
      "Trained for batch 160/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3523403\n",
      "Trained for batch 161/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.2840026\n",
      "Trained for batch 162/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3424666\n",
      "Trained for batch 163/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3675349\n",
      "Trained for batch 164/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.37330538\n",
      "Trained for batch 165/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3597898\n",
      "Trained for batch 166/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3116456\n",
      "Trained for batch 167/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34390512\n",
      "Trained for batch 168/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.33889195\n",
      "Trained for batch 169/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32081577\n",
      "Trained for batch 170/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.410322\n",
      "Trained for batch 171/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.383702\n",
      "Trained for batch 172/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.36528483\n",
      "Trained for batch 173/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ENCODER_LOSS:  0.38347635\n",
      "Trained for batch 174/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35707203\n",
      "Trained for batch 175/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.36420798\n",
      "Trained for batch 176/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.33378866\n",
      "Trained for batch 177/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.31808576\n",
      "Trained for batch 178/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32104638\n",
      "Trained for batch 179/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34531373\n",
      "Trained for batch 180/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.321994\n",
      "Trained for batch 181/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3499526\n",
      "Trained for batch 182/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.36006647\n",
      "Trained for batch 183/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.39998323\n",
      "Trained for batch 184/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.361432\n",
      "Trained for batch 185/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32304326\n",
      "Trained for batch 186/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34189758\n",
      "Trained for batch 187/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34184986\n",
      "Trained for batch 188/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3522194\n",
      "Trained for batch 189/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32400492\n",
      "Trained for batch 190/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.36316416\n",
      "Trained for batch 191/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3674968\n",
      "Trained for batch 192/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.31850624\n",
      "Trained for batch 193/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32408202\n",
      "Trained for batch 194/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.36783686\n",
      "Trained for batch 195/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.36701566\n",
      "Trained for batch 196/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3731249\n",
      "Trained for batch 197/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.39126423\n",
      "Trained for batch 198/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.36494642\n",
      "Trained for batch 199/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.359527\n",
      "Trained for batch 200/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3362123\n",
      "Trained for batch 201/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35970712\n",
      "Trained for batch 202/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.38637915\n",
      "Trained for batch 203/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.38826638\n",
      "Trained for batch 204/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.39506167\n",
      "Trained for batch 205/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.37147424\n",
      "Trained for batch 206/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3071152\n",
      "Trained for batch 207/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34387547\n",
      "Trained for batch 208/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3056565\n",
      "Trained for batch 209/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.38419455\n",
      "Trained for batch 210/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3590555\n",
      "Trained for batch 211/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3761908\n",
      "Trained for batch 212/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32391986\n",
      "Trained for batch 213/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32896698\n",
      "Trained for batch 214/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3489911\n",
      "Trained for batch 215/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.33776313\n",
      "Trained for batch 216/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34594163\n",
      "Trained for batch 217/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3586137\n",
      "Trained for batch 218/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3068967\n",
      "Trained for batch 219/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34787112\n",
      "Trained for batch 220/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35585794\n",
      "Trained for batch 221/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32644787\n",
      "Trained for batch 222/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.41966605\n",
      "Trained for batch 223/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3544684\n",
      "Trained for batch 224/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.39727482\n",
      "Trained for batch 225/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3303101\n",
      "Trained for batch 226/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.33236733\n",
      "Trained for batch 227/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3918038\n",
      "Trained for batch 228/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.31903854\n",
      "Trained for batch 229/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3059475\n",
      "Trained for batch 230/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.29286417\n",
      "Trained for batch 231/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34489208\n",
      "Trained for batch 232/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.4353558\n",
      "Trained for batch 233/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.33572978\n",
      "Trained for batch 234/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3676919\n",
      "Trained for batch 235/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3354807\n",
      "Trained for batch 236/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.33833367\n",
      "Trained for batch 237/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3499948\n",
      "Trained for batch 238/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.31643438\n",
      "Trained for batch 239/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32434273\n",
      "Trained for batch 240/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32255754\n",
      "Trained for batch 241/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3323508\n",
      "Trained for batch 242/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.31635946\n",
      "Trained for batch 243/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3127244\n",
      "Trained for batch 244/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34952378\n",
      "Trained for batch 245/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.37729797\n",
      "Trained for batch 246/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3088171\n",
      "Trained for batch 247/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.38625115\n",
      "Trained for batch 248/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34055194\n",
      "Trained for batch 249/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.369332\n",
      "Trained for batch 250/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.2911807\n",
      "Trained for batch 251/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35524315\n",
      "Trained for batch 252/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3492624\n",
      "Trained for batch 253/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32374212\n",
      "Trained for batch 254/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.37364903\n",
      "Trained for batch 255/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32083753\n",
      "Trained for batch 256/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34373587\n",
      "Trained for batch 257/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.33498663\n",
      "Trained for batch 258/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.40478858\n",
      "Trained for batch 259/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.39394993\n",
      "Trained for batch 260/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3079843\n",
      "Trained for batch 261/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3667761\n",
      "Trained for batch 262/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32117704\n",
      "Trained for batch 263/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3407923\n",
      "Trained for batch 264/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.2844698\n",
      "Trained for batch 265/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3605875\n",
      "Trained for batch 266/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34776175\n",
      "Trained for batch 267/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35550767\n",
      "Trained for batch 268/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ENCODER_LOSS:  0.37222868\n",
      "Trained for batch 269/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3822223\n",
      "Trained for batch 270/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3358348\n",
      "Trained for batch 271/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.30527806\n",
      "Trained for batch 272/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34834856\n",
      "Trained for batch 273/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.39925826\n",
      "Trained for batch 274/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3142352\n",
      "Trained for batch 275/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3562758\n",
      "Trained for batch 276/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.36873597\n",
      "Trained for batch 277/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.36785063\n",
      "Trained for batch 278/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35242164\n",
      "Trained for batch 279/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3502883\n",
      "Trained for batch 280/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3153295\n",
      "Trained for batch 281/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.39030346\n",
      "Trained for batch 282/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3694425\n",
      "Trained for batch 283/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.39287144\n",
      "Trained for batch 284/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34331027\n",
      "Trained for batch 285/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.39497852\n",
      "Trained for batch 286/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32471102\n",
      "Trained for batch 287/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.29553214\n",
      "Trained for batch 288/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3508428\n",
      "Trained for batch 289/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32300672\n",
      "Trained for batch 290/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.38461676\n",
      "Trained for batch 291/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.2982167\n",
      "Trained for batch 292/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34269083\n",
      "Trained for batch 293/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34841794\n",
      "Trained for batch 294/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.46859628\n",
      "Trained for batch 295/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3310706\n",
      "Trained for batch 296/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3232185\n",
      "Trained for batch 297/297\n",
      "______________________________EPOCH 4_______________________________\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.37562805\n",
      "Trained for batch 1/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.2834676\n",
      "Trained for batch 2/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.29086757\n",
      "Trained for batch 3/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34502873\n",
      "Trained for batch 4/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.38596237\n",
      "Trained for batch 5/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32683265\n",
      "Trained for batch 6/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.427265\n",
      "Trained for batch 7/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34941262\n",
      "Trained for batch 8/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35383004\n",
      "Trained for batch 9/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34653437\n",
      "Trained for batch 10/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.31644455\n",
      "Trained for batch 11/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3259698\n",
      "Trained for batch 12/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.31767422\n",
      "Trained for batch 13/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35216522\n",
      "Trained for batch 14/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.29819155\n",
      "Trained for batch 15/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35301638\n",
      "Trained for batch 16/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.37541825\n",
      "Trained for batch 17/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3387604\n",
      "Trained for batch 18/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3489034\n",
      "Trained for batch 19/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.30699342\n",
      "Trained for batch 20/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.30492443\n",
      "Trained for batch 21/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.37235317\n",
      "Trained for batch 22/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.37939045\n",
      "Trained for batch 23/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.39330316\n",
      "Trained for batch 24/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.36510926\n",
      "Trained for batch 25/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.37568066\n",
      "Trained for batch 26/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34753492\n",
      "Trained for batch 27/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3318491\n",
      "Trained for batch 28/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.33099723\n",
      "Trained for batch 29/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34275442\n",
      "Trained for batch 30/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34623536\n",
      "Trained for batch 31/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34020537\n",
      "Trained for batch 32/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34855407\n",
      "Trained for batch 33/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.33330622\n",
      "Trained for batch 34/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35696253\n",
      "Trained for batch 35/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.339845\n",
      "Trained for batch 36/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32085428\n",
      "Trained for batch 37/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32102323\n",
      "Trained for batch 38/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.33242875\n",
      "Trained for batch 39/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35389084\n",
      "Trained for batch 40/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3488966\n",
      "Trained for batch 41/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35984975\n",
      "Trained for batch 42/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.333504\n",
      "Trained for batch 43/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3730072\n",
      "Trained for batch 44/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3043496\n",
      "Trained for batch 45/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.36526707\n",
      "Trained for batch 46/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3194291\n",
      "Trained for batch 47/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.31470677\n",
      "Trained for batch 48/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32881954\n",
      "Trained for batch 49/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34077382\n",
      "Trained for batch 50/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3984285\n",
      "Trained for batch 51/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.2984645\n",
      "Trained for batch 52/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3667717\n",
      "Trained for batch 53/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35219705\n",
      "Trained for batch 54/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35312253\n",
      "Trained for batch 55/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35927498\n",
      "Trained for batch 56/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.38676757\n",
      "Trained for batch 57/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.31101963\n",
      "Trained for batch 58/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.29957563\n",
      "Trained for batch 59/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.42220074\n",
      "Trained for batch 60/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34556317\n",
      "Trained for batch 61/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.30417442\n",
      "Trained for batch 62/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3091237\n",
      "Trained for batch 63/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32154518\n",
      "Trained for batch 64/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3355717\n",
      "Trained for batch 65/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.30551663\n",
      "Trained for batch 66/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3656591\n",
      "Trained for batch 67/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3651201\n",
      "Trained for batch 68/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ENCODER_LOSS:  0.28192842\n",
      "Trained for batch 69/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.36018935\n",
      "Trained for batch 70/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3151818\n",
      "Trained for batch 71/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3919248\n",
      "Trained for batch 72/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.33967414\n",
      "Trained for batch 73/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32288718\n",
      "Trained for batch 74/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3310415\n",
      "Trained for batch 75/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.36134332\n",
      "Trained for batch 76/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3091785\n",
      "Trained for batch 77/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.27953705\n",
      "Trained for batch 78/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.33670664\n",
      "Trained for batch 79/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35771933\n",
      "Trained for batch 80/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.33345884\n",
      "Trained for batch 81/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.31716657\n",
      "Trained for batch 82/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3202459\n",
      "Trained for batch 83/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.37670285\n",
      "Trained for batch 84/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3057986\n",
      "Trained for batch 85/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3595662\n",
      "Trained for batch 86/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.27961558\n",
      "Trained for batch 87/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.38842574\n",
      "Trained for batch 88/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3136027\n",
      "Trained for batch 89/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.31538624\n",
      "Trained for batch 90/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.31208938\n",
      "Trained for batch 91/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.38113093\n",
      "Trained for batch 92/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.33409697\n",
      "Trained for batch 93/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.358548\n",
      "Trained for batch 94/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.30151206\n",
      "Trained for batch 95/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.29893374\n",
      "Trained for batch 96/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.30847448\n",
      "Trained for batch 97/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.347725\n",
      "Trained for batch 98/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.41606522\n",
      "Trained for batch 99/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34554702\n",
      "Trained for batch 100/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3954701\n",
      "Trained for batch 101/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.36638469\n",
      "Trained for batch 102/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.38364488\n",
      "Trained for batch 103/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3697543\n",
      "Trained for batch 104/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.4103467\n",
      "Trained for batch 105/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.33273894\n",
      "Trained for batch 106/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3818987\n",
      "Trained for batch 107/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34130675\n",
      "Trained for batch 108/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32658333\n",
      "Trained for batch 109/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.36678156\n",
      "Trained for batch 110/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.40999776\n",
      "Trained for batch 111/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32618612\n",
      "Trained for batch 112/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.36934346\n",
      "Trained for batch 113/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.36801812\n",
      "Trained for batch 114/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3309074\n",
      "Trained for batch 115/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.31941742\n",
      "Trained for batch 116/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.36080328\n",
      "Trained for batch 117/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3589241\n",
      "Trained for batch 118/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32024103\n",
      "Trained for batch 119/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3819688\n",
      "Trained for batch 120/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.30932936\n",
      "Trained for batch 121/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3149766\n",
      "Trained for batch 122/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.36494035\n",
      "Trained for batch 123/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34298152\n",
      "Trained for batch 124/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34415734\n",
      "Trained for batch 125/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35063007\n",
      "Trained for batch 126/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35424542\n",
      "Trained for batch 127/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3791042\n",
      "Trained for batch 128/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3260028\n",
      "Trained for batch 129/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35915047\n",
      "Trained for batch 130/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35820097\n",
      "Trained for batch 131/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.36325717\n",
      "Trained for batch 132/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3085274\n",
      "Trained for batch 133/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35469988\n",
      "Trained for batch 134/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.36380467\n",
      "Trained for batch 135/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.29770422\n",
      "Trained for batch 136/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.37977627\n",
      "Trained for batch 137/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.31208536\n",
      "Trained for batch 138/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3183096\n",
      "Trained for batch 139/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.38617063\n",
      "Trained for batch 140/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35054842\n",
      "Trained for batch 141/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3340724\n",
      "Trained for batch 142/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.36836553\n",
      "Trained for batch 143/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.40058643\n",
      "Trained for batch 144/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.37770742\n",
      "Trained for batch 145/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3450885\n",
      "Trained for batch 146/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3489427\n",
      "Trained for batch 147/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35132977\n",
      "Trained for batch 148/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34225437\n",
      "Trained for batch 149/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32864803\n",
      "Trained for batch 150/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.36516085\n",
      "Trained for batch 151/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.33354923\n",
      "Trained for batch 152/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3430356\n",
      "Trained for batch 153/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3194392\n",
      "Trained for batch 154/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34171224\n",
      "Trained for batch 155/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3936853\n",
      "Trained for batch 156/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.33573684\n",
      "Trained for batch 157/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34056205\n",
      "Trained for batch 158/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34255633\n",
      "Trained for batch 159/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32276538\n",
      "Trained for batch 160/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.33603436\n",
      "Trained for batch 161/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.29141086\n",
      "Trained for batch 162/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.33991757\n",
      "Trained for batch 163/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.36229697\n",
      "Trained for batch 164/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.38981938\n",
      "Trained for batch 165/297\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.37433806\n",
      "Trained for batch 166/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35173407\n",
      "Trained for batch 167/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.31991422\n",
      "Trained for batch 168/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.33535975\n",
      "Trained for batch 169/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32116726\n",
      "Trained for batch 170/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.31974858\n",
      "Trained for batch 171/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.42225876\n",
      "Trained for batch 172/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.36393774\n",
      "Trained for batch 173/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.4202196\n",
      "Trained for batch 174/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.36335993\n",
      "Trained for batch 175/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3866499\n",
      "Trained for batch 176/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.33611006\n",
      "Trained for batch 177/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.36418453\n",
      "Trained for batch 178/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.36314595\n",
      "Trained for batch 179/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35712355\n",
      "Trained for batch 180/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34866884\n",
      "Trained for batch 181/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35360655\n",
      "Trained for batch 182/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.38920397\n",
      "Trained for batch 183/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.39920568\n",
      "Trained for batch 184/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.36984307\n",
      "Trained for batch 185/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34441954\n",
      "Trained for batch 186/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3287833\n",
      "Trained for batch 187/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32409734\n",
      "Trained for batch 188/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.38444963\n",
      "Trained for batch 189/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3343152\n",
      "Trained for batch 190/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.4157877\n",
      "Trained for batch 191/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32977384\n",
      "Trained for batch 192/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.30758247\n",
      "Trained for batch 193/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32756191\n",
      "Trained for batch 194/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.373113\n",
      "Trained for batch 195/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.359781\n",
      "Trained for batch 196/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.40510902\n",
      "Trained for batch 197/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.40097934\n",
      "Trained for batch 198/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.39009413\n",
      "Trained for batch 199/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32785887\n",
      "Trained for batch 200/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3162598\n",
      "Trained for batch 201/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.367611\n",
      "Trained for batch 202/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.40603733\n",
      "Trained for batch 203/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3686391\n",
      "Trained for batch 204/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.4152062\n",
      "Trained for batch 205/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35893357\n",
      "Trained for batch 206/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34189278\n",
      "Trained for batch 207/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32649916\n",
      "Trained for batch 208/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.30965942\n",
      "Trained for batch 209/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35900307\n",
      "Trained for batch 210/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.33472222\n",
      "Trained for batch 211/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3707456\n",
      "Trained for batch 212/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.33851644\n",
      "Trained for batch 213/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.33178005\n",
      "Trained for batch 214/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3352303\n",
      "Trained for batch 215/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3377752\n",
      "Trained for batch 216/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3475918\n",
      "Trained for batch 217/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3180027\n",
      "Trained for batch 218/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35272998\n",
      "Trained for batch 219/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35945493\n",
      "Trained for batch 220/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.31650043\n",
      "Trained for batch 221/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.31430802\n",
      "Trained for batch 222/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.31780654\n",
      "Trained for batch 223/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.357351\n",
      "Trained for batch 224/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3871588\n",
      "Trained for batch 225/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32406208\n",
      "Trained for batch 226/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.29595608\n",
      "Trained for batch 227/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.31262255\n",
      "Trained for batch 228/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.344584\n",
      "Trained for batch 229/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.30173975\n",
      "Trained for batch 230/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.31894034\n",
      "Trained for batch 231/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.33377045\n",
      "Trained for batch 232/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.36763147\n",
      "Trained for batch 233/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3779893\n",
      "Trained for batch 234/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.33966133\n",
      "Trained for batch 235/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3194821\n",
      "Trained for batch 236/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.38361016\n",
      "Trained for batch 237/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32946157\n",
      "Trained for batch 238/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32210404\n",
      "Trained for batch 239/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3187502\n",
      "Trained for batch 240/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.31765833\n",
      "Trained for batch 241/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34715113\n",
      "Trained for batch 242/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.38214988\n",
      "Trained for batch 243/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.33742395\n",
      "Trained for batch 244/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3682183\n",
      "Trained for batch 245/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32660064\n",
      "Trained for batch 246/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.2686595\n",
      "Trained for batch 247/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.38936058\n",
      "Trained for batch 248/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.30165544\n",
      "Trained for batch 249/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34477755\n",
      "Trained for batch 250/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.31437248\n",
      "Trained for batch 251/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3519441\n",
      "Trained for batch 252/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32751593\n",
      "Trained for batch 253/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3021805\n",
      "Trained for batch 254/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.38529053\n",
      "Trained for batch 255/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.30269194\n",
      "Trained for batch 256/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34058055\n",
      "Trained for batch 257/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3639678\n",
      "Trained for batch 258/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.39914522\n",
      "Trained for batch 259/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3760188\n",
      "Trained for batch 260/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.318199\n",
      "Trained for batch 261/297\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.38220152\n",
      "Trained for batch 262/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.33763343\n",
      "Trained for batch 263/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3475513\n",
      "Trained for batch 264/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.27202106\n",
      "Trained for batch 265/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3388925\n",
      "Trained for batch 266/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.327787\n",
      "Trained for batch 267/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3344982\n",
      "Trained for batch 268/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.36203924\n",
      "Trained for batch 269/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.37802064\n",
      "Trained for batch 270/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34023193\n",
      "Trained for batch 271/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.391531\n",
      "Trained for batch 272/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.37548104\n",
      "Trained for batch 273/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.38995272\n",
      "Trained for batch 274/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3416353\n",
      "Trained for batch 275/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.39127272\n",
      "Trained for batch 276/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35979608\n",
      "Trained for batch 277/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35635638\n",
      "Trained for batch 278/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.33276996\n",
      "Trained for batch 279/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3827282\n",
      "Trained for batch 280/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.2926367\n",
      "Trained for batch 281/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.33163032\n",
      "Trained for batch 282/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3885684\n",
      "Trained for batch 283/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34051841\n",
      "Trained for batch 284/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35670558\n",
      "Trained for batch 285/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35862017\n",
      "Trained for batch 286/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3463712\n",
      "Trained for batch 287/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.29474083\n",
      "Trained for batch 288/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.31956735\n",
      "Trained for batch 289/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32660916\n",
      "Trained for batch 290/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34581876\n",
      "Trained for batch 291/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34189883\n",
      "Trained for batch 292/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.36268312\n",
      "Trained for batch 293/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3818411\n",
      "Trained for batch 294/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.4028496\n",
      "Trained for batch 295/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.33350143\n",
      "Trained for batch 296/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.33601803\n",
      "Trained for batch 297/297\n",
      "______________________________EPOCH 5_______________________________\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3464741\n",
      "Trained for batch 1/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.29212016\n",
      "Trained for batch 2/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35819706\n",
      "Trained for batch 3/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.36549833\n",
      "Trained for batch 4/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3457325\n",
      "Trained for batch 5/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35405305\n",
      "Trained for batch 6/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3949632\n",
      "Trained for batch 7/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3292649\n",
      "Trained for batch 8/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3740211\n",
      "Trained for batch 9/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32918394\n",
      "Trained for batch 10/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35705382\n",
      "Trained for batch 11/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.33336982\n",
      "Trained for batch 12/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32396007\n",
      "Trained for batch 13/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.33984798\n",
      "Trained for batch 14/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34176096\n",
      "Trained for batch 15/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34040862\n",
      "Trained for batch 16/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.40647936\n",
      "Trained for batch 17/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.33503947\n",
      "Trained for batch 18/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34719253\n",
      "Trained for batch 19/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3487741\n",
      "Trained for batch 20/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3009793\n",
      "Trained for batch 21/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.38188586\n",
      "Trained for batch 22/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.38157573\n",
      "Trained for batch 23/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3660928\n",
      "Trained for batch 24/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.38713863\n",
      "Trained for batch 25/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3759554\n",
      "Trained for batch 26/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34290117\n",
      "Trained for batch 27/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3249855\n",
      "Trained for batch 28/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3604927\n",
      "Trained for batch 29/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34414062\n",
      "Trained for batch 30/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.385489\n",
      "Trained for batch 31/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.36091766\n",
      "Trained for batch 32/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32597893\n",
      "Trained for batch 33/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.39900512\n",
      "Trained for batch 34/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.4038314\n",
      "Trained for batch 35/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3361327\n",
      "Trained for batch 36/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.33193916\n",
      "Trained for batch 37/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.31892595\n",
      "Trained for batch 38/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.37352937\n",
      "Trained for batch 39/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34291962\n",
      "Trained for batch 40/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.36784273\n",
      "Trained for batch 41/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.31640428\n",
      "Trained for batch 42/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.30562007\n",
      "Trained for batch 43/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.31109294\n",
      "Trained for batch 44/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.28779987\n",
      "Trained for batch 45/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32808033\n",
      "Trained for batch 46/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3071874\n",
      "Trained for batch 47/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.31217575\n",
      "Trained for batch 48/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.27184278\n",
      "Trained for batch 49/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3321394\n",
      "Trained for batch 50/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3406879\n",
      "Trained for batch 51/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.30633593\n",
      "Trained for batch 52/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.36880884\n",
      "Trained for batch 53/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.31781507\n",
      "Trained for batch 54/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.36389774\n",
      "Trained for batch 55/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3686901\n",
      "Trained for batch 56/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.38343725\n",
      "Trained for batch 57/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35555822\n",
      "Trained for batch 58/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.290996\n",
      "Trained for batch 59/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.40770227\n",
      "Trained for batch 60/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32564458\n",
      "Trained for batch 61/297\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3359932\n",
      "Trained for batch 62/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.339865\n",
      "Trained for batch 63/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.28248087\n",
      "Trained for batch 64/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3319884\n",
      "Trained for batch 65/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.31271574\n",
      "Trained for batch 66/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32484317\n",
      "Trained for batch 67/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.38612446\n",
      "Trained for batch 68/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.31328726\n",
      "Trained for batch 69/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.36480612\n",
      "Trained for batch 70/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3236538\n",
      "Trained for batch 71/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3221702\n",
      "Trained for batch 72/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.36247683\n",
      "Trained for batch 73/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34522456\n",
      "Trained for batch 74/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.33379644\n",
      "Trained for batch 75/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3600816\n",
      "Trained for batch 76/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.2726279\n",
      "Trained for batch 77/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.29550862\n",
      "Trained for batch 78/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.33928007\n",
      "Trained for batch 79/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.4178869\n",
      "Trained for batch 80/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3096426\n",
      "Trained for batch 81/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34169358\n",
      "Trained for batch 82/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32272676\n",
      "Trained for batch 83/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34228534\n",
      "Trained for batch 84/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.33353764\n",
      "Trained for batch 85/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3541214\n",
      "Trained for batch 86/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.36406606\n",
      "Trained for batch 87/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.39485914\n",
      "Trained for batch 88/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3490561\n",
      "Trained for batch 89/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3216069\n",
      "Trained for batch 90/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32436815\n",
      "Trained for batch 91/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.36480945\n",
      "Trained for batch 92/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32410845\n",
      "Trained for batch 93/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3690105\n",
      "Trained for batch 94/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3132235\n",
      "Trained for batch 95/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3119325\n",
      "Trained for batch 96/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35781989\n",
      "Trained for batch 97/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.4500909\n",
      "Trained for batch 98/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3982028\n",
      "Trained for batch 99/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35729492\n",
      "Trained for batch 100/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35009867\n",
      "Trained for batch 101/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.37202486\n",
      "Trained for batch 102/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3853225\n",
      "Trained for batch 103/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3353001\n",
      "Trained for batch 104/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.38306874\n",
      "Trained for batch 105/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.40600172\n",
      "Trained for batch 106/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.38442257\n",
      "Trained for batch 107/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.36106113\n",
      "Trained for batch 108/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.2875339\n",
      "Trained for batch 109/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.38755333\n",
      "Trained for batch 110/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34618124\n",
      "Trained for batch 111/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.31439608\n",
      "Trained for batch 112/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.33118242\n",
      "Trained for batch 113/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.39498907\n",
      "Trained for batch 114/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32520205\n",
      "Trained for batch 115/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32661554\n",
      "Trained for batch 116/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.38155144\n",
      "Trained for batch 117/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.2869042\n",
      "Trained for batch 118/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3261649\n",
      "Trained for batch 119/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.31236592\n",
      "Trained for batch 120/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.2784571\n",
      "Trained for batch 121/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3414922\n",
      "Trained for batch 122/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3326829\n",
      "Trained for batch 123/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3054791\n",
      "Trained for batch 124/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34340033\n",
      "Trained for batch 125/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.39348382\n",
      "Trained for batch 126/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.43974447\n",
      "Trained for batch 127/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34660178\n",
      "Trained for batch 128/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34301248\n",
      "Trained for batch 129/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.31545877\n",
      "Trained for batch 130/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32914743\n",
      "Trained for batch 131/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.36659807\n",
      "Trained for batch 132/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3386667\n",
      "Trained for batch 133/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3687568\n",
      "Trained for batch 134/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.37558943\n",
      "Trained for batch 135/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.31539282\n",
      "Trained for batch 136/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3581321\n",
      "Trained for batch 137/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3327178\n",
      "Trained for batch 138/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.30538183\n",
      "Trained for batch 139/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.41555804\n",
      "Trained for batch 140/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3585879\n",
      "Trained for batch 141/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.31481916\n",
      "Trained for batch 142/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.37225676\n",
      "Trained for batch 143/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.4103809\n",
      "Trained for batch 144/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.33445644\n",
      "Trained for batch 145/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.29926258\n",
      "Trained for batch 146/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3803988\n",
      "Trained for batch 147/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.37052903\n",
      "Trained for batch 148/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.30859217\n",
      "Trained for batch 149/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34119216\n",
      "Trained for batch 150/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.402323\n",
      "Trained for batch 151/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34618425\n",
      "Trained for batch 152/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32205573\n",
      "Trained for batch 153/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.31530043\n",
      "Trained for batch 154/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.31168237\n",
      "Trained for batch 155/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.31612667\n",
      "Trained for batch 156/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.31274986\n",
      "Trained for batch 157/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35252252\n",
      "Trained for batch 158/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.30645686\n",
      "Trained for batch 159/297\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32769567\n",
      "Trained for batch 160/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.33600563\n",
      "Trained for batch 161/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.28899974\n",
      "Trained for batch 162/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35511702\n",
      "Trained for batch 163/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.36619782\n",
      "Trained for batch 164/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3874557\n",
      "Trained for batch 165/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.4078528\n",
      "Trained for batch 166/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3661114\n",
      "Trained for batch 167/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3273483\n",
      "Trained for batch 168/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.33546782\n",
      "Trained for batch 169/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3253964\n",
      "Trained for batch 170/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.36253172\n",
      "Trained for batch 171/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.36223572\n",
      "Trained for batch 172/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.37050766\n",
      "Trained for batch 173/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.38137263\n",
      "Trained for batch 174/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35126743\n",
      "Trained for batch 175/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.39233392\n",
      "Trained for batch 176/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.38255405\n",
      "Trained for batch 177/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.30872166\n",
      "Trained for batch 178/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35324422\n",
      "Trained for batch 179/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32667407\n",
      "Trained for batch 180/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3477219\n",
      "Trained for batch 181/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.36655203\n",
      "Trained for batch 182/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.40698323\n",
      "Trained for batch 183/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.40209275\n",
      "Trained for batch 184/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.33325633\n",
      "Trained for batch 185/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.332976\n",
      "Trained for batch 186/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.38595358\n",
      "Trained for batch 187/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.349613\n",
      "Trained for batch 188/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.40639156\n",
      "Trained for batch 189/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32431912\n",
      "Trained for batch 190/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.39199477\n",
      "Trained for batch 191/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3831777\n",
      "Trained for batch 192/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.29148245\n",
      "Trained for batch 193/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.30454013\n",
      "Trained for batch 194/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.36530328\n",
      "Trained for batch 195/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3738196\n",
      "Trained for batch 196/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34788504\n",
      "Trained for batch 197/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.37605113\n",
      "Trained for batch 198/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.37212723\n",
      "Trained for batch 199/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.31062847\n",
      "Trained for batch 200/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3347507\n",
      "Trained for batch 201/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.36623067\n",
      "Trained for batch 202/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.40519843\n",
      "Trained for batch 203/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.37560228\n",
      "Trained for batch 204/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.40240222\n",
      "Trained for batch 205/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35724494\n",
      "Trained for batch 206/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.38758138\n",
      "Trained for batch 207/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3311918\n",
      "Trained for batch 208/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.30422434\n",
      "Trained for batch 209/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3541634\n",
      "Trained for batch 210/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.33372378\n",
      "Trained for batch 211/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.36912856\n",
      "Trained for batch 212/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.29825687\n",
      "Trained for batch 213/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.31145838\n",
      "Trained for batch 214/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.38012555\n",
      "Trained for batch 215/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.36591974\n",
      "Trained for batch 216/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.33461624\n",
      "Trained for batch 217/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35642284\n",
      "Trained for batch 218/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3184267\n",
      "Trained for batch 219/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34064496\n",
      "Trained for batch 220/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.33050936\n",
      "Trained for batch 221/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32610667\n",
      "Trained for batch 222/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35599336\n",
      "Trained for batch 223/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35473114\n",
      "Trained for batch 224/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3897451\n",
      "Trained for batch 225/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.37346345\n",
      "Trained for batch 226/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32487845\n",
      "Trained for batch 227/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.38611373\n",
      "Trained for batch 228/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3561933\n",
      "Trained for batch 229/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3193473\n",
      "Trained for batch 230/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.30982822\n",
      "Trained for batch 231/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3623279\n",
      "Trained for batch 232/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3714589\n",
      "Trained for batch 233/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34132007\n",
      "Trained for batch 234/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.33674708\n",
      "Trained for batch 235/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3544969\n",
      "Trained for batch 236/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35567158\n",
      "Trained for batch 237/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34097174\n",
      "Trained for batch 238/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.33652154\n",
      "Trained for batch 239/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.33823615\n",
      "Trained for batch 240/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.29102606\n",
      "Trained for batch 241/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.33977127\n",
      "Trained for batch 242/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.33142367\n",
      "Trained for batch 243/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.33213177\n",
      "Trained for batch 244/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.343074\n",
      "Trained for batch 245/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35592645\n",
      "Trained for batch 246/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.28808576\n",
      "Trained for batch 247/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.40403706\n",
      "Trained for batch 248/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32262534\n",
      "Trained for batch 249/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.36305967\n",
      "Trained for batch 250/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32860532\n",
      "Trained for batch 251/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.33675155\n",
      "Trained for batch 252/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.31785017\n",
      "Trained for batch 253/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35240716\n",
      "Trained for batch 254/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.397728\n",
      "Trained for batch 255/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.38131243\n",
      "Trained for batch 256/297\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.29940516\n",
      "Trained for batch 257/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.33916005\n",
      "Trained for batch 258/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.31294316\n",
      "Trained for batch 259/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35436448\n",
      "Trained for batch 260/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.2943121\n",
      "Trained for batch 261/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3978892\n",
      "Trained for batch 262/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.33103034\n",
      "Trained for batch 263/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35148743\n",
      "Trained for batch 264/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.28310224\n",
      "Trained for batch 265/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.38833472\n",
      "Trained for batch 266/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.30327967\n",
      "Trained for batch 267/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3762933\n",
      "Trained for batch 268/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3222452\n",
      "Trained for batch 269/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34860834\n",
      "Trained for batch 270/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32485\n",
      "Trained for batch 271/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34698695\n",
      "Trained for batch 272/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32776558\n",
      "Trained for batch 273/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34989503\n",
      "Trained for batch 274/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32155353\n",
      "Trained for batch 275/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35152894\n",
      "Trained for batch 276/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3240224\n",
      "Trained for batch 277/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.36656165\n",
      "Trained for batch 278/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.31583127\n",
      "Trained for batch 279/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.37717897\n",
      "Trained for batch 280/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.31312937\n",
      "Trained for batch 281/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3448514\n",
      "Trained for batch 282/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.39050964\n",
      "Trained for batch 283/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.37181604\n",
      "Trained for batch 284/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3765646\n",
      "Trained for batch 285/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.37073123\n",
      "Trained for batch 286/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34362847\n",
      "Trained for batch 287/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.31207606\n",
      "Trained for batch 288/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.38574463\n",
      "Trained for batch 289/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3173319\n",
      "Trained for batch 290/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35111362\n",
      "Trained for batch 291/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.38650376\n",
      "Trained for batch 292/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35225368\n",
      "Trained for batch 293/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35753563\n",
      "Trained for batch 294/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3812284\n",
      "Trained for batch 295/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3424304\n",
      "Trained for batch 296/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.33633524\n",
      "Trained for batch 297/297\n",
      "______________________________EPOCH 6_______________________________\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.36831987\n",
      "Trained for batch 1/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3141655\n",
      "Trained for batch 2/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32570198\n",
      "Trained for batch 3/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.38997036\n",
      "Trained for batch 4/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.33837748\n",
      "Trained for batch 5/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32964915\n",
      "Trained for batch 6/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.41213483\n",
      "Trained for batch 7/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34704456\n",
      "Trained for batch 8/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34662175\n",
      "Trained for batch 9/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34892148\n",
      "Trained for batch 10/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3509999\n",
      "Trained for batch 11/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34469455\n",
      "Trained for batch 12/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.27759042\n",
      "Trained for batch 13/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35435933\n",
      "Trained for batch 14/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.29955727\n",
      "Trained for batch 15/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3819954\n",
      "Trained for batch 16/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3854199\n",
      "Trained for batch 17/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.33340055\n",
      "Trained for batch 18/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.36337462\n",
      "Trained for batch 19/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.2997344\n",
      "Trained for batch 20/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.30884668\n",
      "Trained for batch 21/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3990721\n",
      "Trained for batch 22/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3596436\n",
      "Trained for batch 23/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.38188767\n",
      "Trained for batch 24/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3055107\n",
      "Trained for batch 25/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.37932673\n",
      "Trained for batch 26/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.33625916\n",
      "Trained for batch 27/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32811707\n",
      "Trained for batch 28/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.37168536\n",
      "Trained for batch 29/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.30211422\n",
      "Trained for batch 30/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3894562\n",
      "Trained for batch 31/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32230082\n",
      "Trained for batch 32/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.30850583\n",
      "Trained for batch 33/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3413015\n",
      "Trained for batch 34/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.36637536\n",
      "Trained for batch 35/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3200538\n",
      "Trained for batch 36/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3680536\n",
      "Trained for batch 37/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.2971691\n",
      "Trained for batch 38/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.33890042\n",
      "Trained for batch 39/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35106617\n",
      "Trained for batch 40/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34992418\n",
      "Trained for batch 41/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.33487067\n",
      "Trained for batch 42/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.28098053\n",
      "Trained for batch 43/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.37443635\n",
      "Trained for batch 44/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.30209532\n",
      "Trained for batch 45/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.38543177\n",
      "Trained for batch 46/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3298152\n",
      "Trained for batch 47/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.31574345\n",
      "Trained for batch 48/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.29238933\n",
      "Trained for batch 49/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3398026\n",
      "Trained for batch 50/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35051665\n",
      "Trained for batch 51/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.29480675\n",
      "Trained for batch 52/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.357694\n",
      "Trained for batch 53/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.30546284\n",
      "Trained for batch 54/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.33940113\n",
      "Trained for batch 55/297\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.36564308\n",
      "Trained for batch 56/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.42295513\n",
      "Trained for batch 57/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.36707267\n",
      "Trained for batch 58/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.29192314\n",
      "Trained for batch 59/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.37343404\n",
      "Trained for batch 60/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.30735117\n",
      "Trained for batch 61/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.30546707\n",
      "Trained for batch 62/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3176033\n",
      "Trained for batch 63/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.29116526\n",
      "Trained for batch 64/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.29861996\n",
      "Trained for batch 65/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3196461\n",
      "Trained for batch 66/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34659606\n",
      "Trained for batch 67/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.38189176\n",
      "Trained for batch 68/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32394022\n",
      "Trained for batch 69/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.36292493\n",
      "Trained for batch 70/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35624835\n",
      "Trained for batch 71/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3334715\n",
      "Trained for batch 72/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.31838304\n",
      "Trained for batch 73/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35732025\n",
      "Trained for batch 74/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.38351542\n",
      "Trained for batch 75/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34758395\n",
      "Trained for batch 76/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3183276\n",
      "Trained for batch 77/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3135603\n",
      "Trained for batch 78/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32860786\n",
      "Trained for batch 79/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.37971392\n",
      "Trained for batch 80/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3421132\n",
      "Trained for batch 81/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.33020476\n",
      "Trained for batch 82/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.38789332\n",
      "Trained for batch 83/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3271606\n",
      "Trained for batch 84/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.31313524\n",
      "Trained for batch 85/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3444518\n",
      "Trained for batch 86/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.28516707\n",
      "Trained for batch 87/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3949019\n",
      "Trained for batch 88/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.37234926\n",
      "Trained for batch 89/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34097144\n",
      "Trained for batch 90/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.309462\n",
      "Trained for batch 91/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34297067\n",
      "Trained for batch 92/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.31631508\n",
      "Trained for batch 93/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35460752\n",
      "Trained for batch 94/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.30009013\n",
      "Trained for batch 95/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32057104\n",
      "Trained for batch 96/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.31841567\n",
      "Trained for batch 97/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.37012744\n",
      "Trained for batch 98/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.38082474\n",
      "Trained for batch 99/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35747364\n",
      "Trained for batch 100/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.38773796\n",
      "Trained for batch 101/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35803694\n",
      "Trained for batch 102/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.4312016\n",
      "Trained for batch 103/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35527888\n",
      "Trained for batch 104/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3367054\n",
      "Trained for batch 105/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3529201\n",
      "Trained for batch 106/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.37754732\n",
      "Trained for batch 107/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3416516\n",
      "Trained for batch 108/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.29889044\n",
      "Trained for batch 109/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.342333\n",
      "Trained for batch 110/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.42055154\n",
      "Trained for batch 111/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.30968148\n",
      "Trained for batch 112/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34584278\n",
      "Trained for batch 113/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3527235\n",
      "Trained for batch 114/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.30150267\n",
      "Trained for batch 115/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32244197\n",
      "Trained for batch 116/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.40768823\n",
      "Trained for batch 117/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35308844\n",
      "Trained for batch 118/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.31898\n",
      "Trained for batch 119/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.37805519\n",
      "Trained for batch 120/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32199648\n",
      "Trained for batch 121/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3210451\n",
      "Trained for batch 122/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.36210507\n",
      "Trained for batch 123/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3498587\n",
      "Trained for batch 124/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34945968\n",
      "Trained for batch 125/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35434976\n",
      "Trained for batch 126/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35531136\n",
      "Trained for batch 127/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3353678\n",
      "Trained for batch 128/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32751724\n",
      "Trained for batch 129/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34495166\n",
      "Trained for batch 130/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3119827\n",
      "Trained for batch 131/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3605486\n",
      "Trained for batch 132/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3173926\n",
      "Trained for batch 133/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3129842\n",
      "Trained for batch 134/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.40610546\n",
      "Trained for batch 135/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.31475943\n",
      "Trained for batch 136/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.38804096\n",
      "Trained for batch 137/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32885048\n",
      "Trained for batch 138/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.31038955\n",
      "Trained for batch 139/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.37753224\n",
      "Trained for batch 140/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34664658\n",
      "Trained for batch 141/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.2958584\n",
      "Trained for batch 142/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35926667\n",
      "Trained for batch 143/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34056526\n",
      "Trained for batch 144/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34937644\n",
      "Trained for batch 145/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.33093214\n",
      "Trained for batch 146/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.36195213\n",
      "Trained for batch 147/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34051397\n",
      "Trained for batch 148/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3289811\n",
      "Trained for batch 149/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34706587\n",
      "Trained for batch 150/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.36348516\n",
      "Trained for batch 151/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.28934377\n",
      "Trained for batch 152/297\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.36227217\n",
      "Trained for batch 153/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3378144\n",
      "Trained for batch 154/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34072414\n",
      "Trained for batch 155/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.36173072\n",
      "Trained for batch 156/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.30731717\n",
      "Trained for batch 157/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3247979\n",
      "Trained for batch 158/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34491208\n",
      "Trained for batch 159/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3278628\n",
      "Trained for batch 160/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.33483523\n",
      "Trained for batch 161/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.31628612\n",
      "Trained for batch 162/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3426725\n",
      "Trained for batch 163/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34934813\n",
      "Trained for batch 164/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.36825168\n",
      "Trained for batch 165/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35272366\n",
      "Trained for batch 166/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3137048\n",
      "Trained for batch 167/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.33948344\n",
      "Trained for batch 168/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.33158022\n",
      "Trained for batch 169/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.31798753\n",
      "Trained for batch 170/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.36556423\n",
      "Trained for batch 171/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35659516\n",
      "Trained for batch 172/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.37410527\n",
      "Trained for batch 173/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3354911\n",
      "Trained for batch 174/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35391787\n",
      "Trained for batch 175/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.38631105\n",
      "Trained for batch 176/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3775456\n",
      "Trained for batch 177/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3331511\n",
      "Trained for batch 178/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.36793542\n",
      "Trained for batch 179/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35864702\n",
      "Trained for batch 180/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.31866443\n",
      "Trained for batch 181/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34864566\n",
      "Trained for batch 182/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3765124\n",
      "Trained for batch 183/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.38365066\n",
      "Trained for batch 184/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.39007825\n",
      "Trained for batch 185/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35640842\n",
      "Trained for batch 186/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3364499\n",
      "Trained for batch 187/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35133767\n",
      "Trained for batch 188/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3478756\n",
      "Trained for batch 189/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3350343\n",
      "Trained for batch 190/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.38706082\n",
      "Trained for batch 191/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35473204\n",
      "Trained for batch 192/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.30082807\n",
      "Trained for batch 193/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3025977\n",
      "Trained for batch 194/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.36141938\n",
      "Trained for batch 195/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.36163956\n",
      "Trained for batch 196/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.37128592\n",
      "Trained for batch 197/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34016752\n",
      "Trained for batch 198/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.39957145\n",
      "Trained for batch 199/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.26483914\n",
      "Trained for batch 200/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.31035548\n",
      "Trained for batch 201/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3765823\n",
      "Trained for batch 202/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.399706\n",
      "Trained for batch 203/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35259512\n",
      "Trained for batch 204/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34794316\n",
      "Trained for batch 205/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34222957\n",
      "Trained for batch 206/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.37633958\n",
      "Trained for batch 207/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.319999\n",
      "Trained for batch 208/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32184917\n",
      "Trained for batch 209/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3636616\n",
      "Trained for batch 210/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.31166258\n",
      "Trained for batch 211/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3480917\n",
      "Trained for batch 212/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34475932\n",
      "Trained for batch 213/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.33192745\n",
      "Trained for batch 214/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3539851\n",
      "Trained for batch 215/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.33945423\n",
      "Trained for batch 216/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.33279037\n",
      "Trained for batch 217/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.33409172\n",
      "Trained for batch 218/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.31074387\n",
      "Trained for batch 219/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34169\n",
      "Trained for batch 220/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3729517\n",
      "Trained for batch 221/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35860914\n",
      "Trained for batch 222/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.38034788\n",
      "Trained for batch 223/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.33443838\n",
      "Trained for batch 224/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.4262711\n",
      "Trained for batch 225/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35139784\n",
      "Trained for batch 226/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3466818\n",
      "Trained for batch 227/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32075596\n",
      "Trained for batch 228/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.37494117\n",
      "Trained for batch 229/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3202176\n",
      "Trained for batch 230/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3353179\n",
      "Trained for batch 231/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3371919\n",
      "Trained for batch 232/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.4056161\n",
      "Trained for batch 233/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.31407252\n",
      "Trained for batch 234/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.33754677\n",
      "Trained for batch 235/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.30956882\n",
      "Trained for batch 236/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.37984747\n",
      "Trained for batch 237/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34861872\n",
      "Trained for batch 238/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34712848\n",
      "Trained for batch 239/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3393856\n",
      "Trained for batch 240/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3001977\n",
      "Trained for batch 241/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34501982\n",
      "Trained for batch 242/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.39061168\n",
      "Trained for batch 243/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3003258\n",
      "Trained for batch 244/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.36374167\n",
      "Trained for batch 245/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35351655\n",
      "Trained for batch 246/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.29129538\n",
      "Trained for batch 247/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3553131\n",
      "Trained for batch 248/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.30691734\n",
      "Trained for batch 249/297\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.29796207\n",
      "Trained for batch 250/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.33708525\n",
      "Trained for batch 251/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3299283\n",
      "Trained for batch 252/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.33284616\n",
      "Trained for batch 253/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.31811792\n",
      "Trained for batch 254/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.37520605\n",
      "Trained for batch 255/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.36291438\n",
      "Trained for batch 256/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.31902662\n",
      "Trained for batch 257/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.33009696\n",
      "Trained for batch 258/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.33801338\n",
      "Trained for batch 259/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.37820536\n",
      "Trained for batch 260/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32446966\n",
      "Trained for batch 261/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3809868\n",
      "Trained for batch 262/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.29995528\n",
      "Trained for batch 263/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3350346\n",
      "Trained for batch 264/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.30745775\n",
      "Trained for batch 265/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.39286342\n",
      "Trained for batch 266/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.31780404\n",
      "Trained for batch 267/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.29787293\n",
      "Trained for batch 268/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.36626703\n",
      "Trained for batch 269/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35969\n",
      "Trained for batch 270/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32076842\n",
      "Trained for batch 271/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35769978\n",
      "Trained for batch 272/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34857053\n",
      "Trained for batch 273/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3781498\n",
      "Trained for batch 274/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.36128125\n",
      "Trained for batch 275/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.367394\n",
      "Trained for batch 276/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32787076\n",
      "Trained for batch 277/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.36014077\n",
      "Trained for batch 278/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3556559\n",
      "Trained for batch 279/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.30878586\n",
      "Trained for batch 280/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.33689338\n",
      "Trained for batch 281/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35956925\n",
      "Trained for batch 282/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.39381546\n",
      "Trained for batch 283/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3462789\n",
      "Trained for batch 284/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.353724\n",
      "Trained for batch 285/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34102958\n",
      "Trained for batch 286/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.36001396\n",
      "Trained for batch 287/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32142997\n",
      "Trained for batch 288/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.33647078\n",
      "Trained for batch 289/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.331659\n",
      "Trained for batch 290/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35287136\n",
      "Trained for batch 291/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.31310394\n",
      "Trained for batch 292/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32063788\n",
      "Trained for batch 293/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.37264895\n",
      "Trained for batch 294/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35223883\n",
      "Trained for batch 295/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34469485\n",
      "Trained for batch 296/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.33860105\n",
      "Trained for batch 297/297\n",
      "______________________________EPOCH 7_______________________________\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.39187947\n",
      "Trained for batch 1/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.28571147\n",
      "Trained for batch 2/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.31335732\n",
      "Trained for batch 3/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.38861683\n",
      "Trained for batch 4/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32391328\n",
      "Trained for batch 5/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3737568\n",
      "Trained for batch 6/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.33654377\n",
      "Trained for batch 7/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35268626\n",
      "Trained for batch 8/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3726123\n",
      "Trained for batch 9/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.31168467\n",
      "Trained for batch 10/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3196736\n",
      "Trained for batch 11/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34995338\n",
      "Trained for batch 12/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3600708\n",
      "Trained for batch 13/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.33919206\n",
      "Trained for batch 14/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.31472737\n",
      "Trained for batch 15/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32929882\n",
      "Trained for batch 16/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.40669623\n",
      "Trained for batch 17/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.38403243\n",
      "Trained for batch 18/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.33358198\n",
      "Trained for batch 19/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.28300467\n",
      "Trained for batch 20/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.29705924\n",
      "Trained for batch 21/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.38094717\n",
      "Trained for batch 22/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3438595\n",
      "Trained for batch 23/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3586393\n",
      "Trained for batch 24/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.36270547\n",
      "Trained for batch 25/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35918602\n",
      "Trained for batch 26/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3422863\n",
      "Trained for batch 27/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.30515388\n",
      "Trained for batch 28/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35264343\n",
      "Trained for batch 29/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.40419388\n",
      "Trained for batch 30/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.37590772\n",
      "Trained for batch 31/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.33077645\n",
      "Trained for batch 32/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.31481308\n",
      "Trained for batch 33/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35164088\n",
      "Trained for batch 34/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.38191837\n",
      "Trained for batch 35/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.325254\n",
      "Trained for batch 36/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.36854935\n",
      "Trained for batch 37/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3101124\n",
      "Trained for batch 38/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.33323056\n",
      "Trained for batch 39/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34120864\n",
      "Trained for batch 40/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3783018\n",
      "Trained for batch 41/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34818935\n",
      "Trained for batch 42/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.30677566\n",
      "Trained for batch 43/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3336521\n",
      "Trained for batch 44/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.28525525\n",
      "Trained for batch 45/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35224032\n",
      "Trained for batch 46/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32044476\n",
      "Trained for batch 47/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32841057\n",
      "Trained for batch 48/297\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3022105\n",
      "Trained for batch 49/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.33029875\n",
      "Trained for batch 50/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3505675\n",
      "Trained for batch 51/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.30337954\n",
      "Trained for batch 52/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35381603\n",
      "Trained for batch 53/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.31742388\n",
      "Trained for batch 54/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3386628\n",
      "Trained for batch 55/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.39359123\n",
      "Trained for batch 56/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.38577583\n",
      "Trained for batch 57/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3507556\n",
      "Trained for batch 58/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.29221135\n",
      "Trained for batch 59/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.42355138\n",
      "Trained for batch 60/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.309502\n",
      "Trained for batch 61/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.31194553\n",
      "Trained for batch 62/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32990998\n",
      "Trained for batch 63/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3207814\n",
      "Trained for batch 64/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.30184835\n",
      "Trained for batch 65/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.30499315\n",
      "Trained for batch 66/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.36404863\n",
      "Trained for batch 67/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.37121812\n",
      "Trained for batch 68/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32354337\n",
      "Trained for batch 69/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.41455668\n",
      "Trained for batch 70/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.33224726\n",
      "Trained for batch 71/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.31971043\n",
      "Trained for batch 72/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35385618\n",
      "Trained for batch 73/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32644552\n",
      "Trained for batch 74/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32023734\n",
      "Trained for batch 75/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.33015138\n",
      "Trained for batch 76/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34207064\n",
      "Trained for batch 77/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.31559697\n",
      "Trained for batch 78/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.36253324\n",
      "Trained for batch 79/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.41350812\n",
      "Trained for batch 80/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.33681613\n",
      "Trained for batch 81/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.29273522\n",
      "Trained for batch 82/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.342208\n",
      "Trained for batch 83/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.36787772\n",
      "Trained for batch 84/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.29725415\n",
      "Trained for batch 85/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.36338693\n",
      "Trained for batch 86/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.33052984\n",
      "Trained for batch 87/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.39090145\n",
      "Trained for batch 88/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.36994684\n",
      "Trained for batch 89/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3213995\n",
      "Trained for batch 90/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.29623753\n",
      "Trained for batch 91/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34008408\n",
      "Trained for batch 92/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.29375425\n",
      "Trained for batch 93/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3490561\n",
      "Trained for batch 94/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.33488244\n",
      "Trained for batch 95/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.31658238\n",
      "Trained for batch 96/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3701748\n",
      "Trained for batch 97/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.33233443\n",
      "Trained for batch 98/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.4006421\n",
      "Trained for batch 99/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3591116\n",
      "Trained for batch 100/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.4051128\n",
      "Trained for batch 101/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.37292606\n",
      "Trained for batch 102/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.39127392\n",
      "Trained for batch 103/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.33968964\n",
      "Trained for batch 104/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.41368198\n",
      "Trained for batch 105/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3894743\n",
      "Trained for batch 106/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.40607968\n",
      "Trained for batch 107/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.31791055\n",
      "Trained for batch 108/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35080755\n",
      "Trained for batch 109/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.36741918\n",
      "Trained for batch 110/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.37268218\n",
      "Trained for batch 111/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.36902928\n",
      "Trained for batch 112/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3632913\n",
      "Trained for batch 113/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3758727\n",
      "Trained for batch 114/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.31913942\n",
      "Trained for batch 115/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.31485328\n",
      "Trained for batch 116/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.38258874\n",
      "Trained for batch 117/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34456038\n",
      "Trained for batch 118/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3151865\n",
      "Trained for batch 119/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.37355557\n",
      "Trained for batch 120/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32236853\n",
      "Trained for batch 121/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32724565\n",
      "Trained for batch 122/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3580833\n",
      "Trained for batch 123/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3270684\n",
      "Trained for batch 124/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32432866\n",
      "Trained for batch 125/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.40215644\n",
      "Trained for batch 126/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3739203\n",
      "Trained for batch 127/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3395134\n",
      "Trained for batch 128/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35861108\n",
      "Trained for batch 129/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3523987\n",
      "Trained for batch 130/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3709597\n",
      "Trained for batch 131/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.36105943\n",
      "Trained for batch 132/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32683644\n",
      "Trained for batch 133/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3282959\n",
      "Trained for batch 134/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.36442125\n",
      "Trained for batch 135/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32864255\n",
      "Trained for batch 136/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35336396\n",
      "Trained for batch 137/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3498346\n",
      "Trained for batch 138/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.30265278\n",
      "Trained for batch 139/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.38864177\n",
      "Trained for batch 140/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34403795\n",
      "Trained for batch 141/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35563216\n",
      "Trained for batch 142/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.38938752\n",
      "Trained for batch 143/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3740018\n",
      "Trained for batch 144/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34610587\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained for batch 145/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3178343\n",
      "Trained for batch 146/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3769548\n",
      "Trained for batch 147/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32884774\n",
      "Trained for batch 148/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3325253\n",
      "Trained for batch 149/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34922743\n",
      "Trained for batch 150/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.37094286\n",
      "Trained for batch 151/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3156\n",
      "Trained for batch 152/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.29946378\n",
      "Trained for batch 153/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.33164445\n",
      "Trained for batch 154/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.33047146\n",
      "Trained for batch 155/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3495105\n",
      "Trained for batch 156/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.33629125\n",
      "Trained for batch 157/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32760006\n",
      "Trained for batch 158/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35292277\n",
      "Trained for batch 159/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34507358\n",
      "Trained for batch 160/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3214992\n",
      "Trained for batch 161/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.30791864\n",
      "Trained for batch 162/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3395555\n",
      "Trained for batch 163/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3556593\n",
      "Trained for batch 164/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.36508378\n",
      "Trained for batch 165/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.38865575\n",
      "Trained for batch 166/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3628052\n",
      "Trained for batch 167/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32527393\n",
      "Trained for batch 168/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.30583087\n",
      "Trained for batch 169/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.29493985\n",
      "Trained for batch 170/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.36393726\n",
      "Trained for batch 171/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.36949652\n",
      "Trained for batch 172/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3542411\n",
      "Trained for batch 173/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35096955\n",
      "Trained for batch 174/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.39399713\n",
      "Trained for batch 175/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.38993672\n",
      "Trained for batch 176/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3731609\n",
      "Trained for batch 177/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.30751655\n",
      "Trained for batch 178/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35588312\n",
      "Trained for batch 179/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35981184\n",
      "Trained for batch 180/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32781768\n",
      "Trained for batch 181/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3774136\n",
      "Trained for batch 182/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.411161\n",
      "Trained for batch 183/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.42936364\n",
      "Trained for batch 184/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3606767\n",
      "Trained for batch 185/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32815462\n",
      "Trained for batch 186/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34939972\n",
      "Trained for batch 187/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32927114\n",
      "Trained for batch 188/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3583843\n",
      "Trained for batch 189/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.30668312\n",
      "Trained for batch 190/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.36733606\n",
      "Trained for batch 191/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.36089152\n",
      "Trained for batch 192/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.29941303\n",
      "Trained for batch 193/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3097568\n",
      "Trained for batch 194/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.41609946\n",
      "Trained for batch 195/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3563177\n",
      "Trained for batch 196/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32229766\n",
      "Trained for batch 197/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.364527\n",
      "Trained for batch 198/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.36223003\n",
      "Trained for batch 199/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34131545\n",
      "Trained for batch 200/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.33900386\n",
      "Trained for batch 201/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35398895\n",
      "Trained for batch 202/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.40556496\n",
      "Trained for batch 203/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.36454532\n",
      "Trained for batch 204/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3935646\n",
      "Trained for batch 205/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.36014047\n",
      "Trained for batch 206/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.37729213\n",
      "Trained for batch 207/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3454725\n",
      "Trained for batch 208/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.31423998\n",
      "Trained for batch 209/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35578406\n",
      "Trained for batch 210/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34349677\n",
      "Trained for batch 211/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.33089006\n",
      "Trained for batch 212/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.31228513\n",
      "Trained for batch 213/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.33487338\n",
      "Trained for batch 214/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3610003\n",
      "Trained for batch 215/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.38313636\n",
      "Trained for batch 216/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3066017\n",
      "Trained for batch 217/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3560432\n",
      "Trained for batch 218/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.31057328\n",
      "Trained for batch 219/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3341189\n",
      "Trained for batch 220/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3341078\n",
      "Trained for batch 221/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.31377956\n",
      "Trained for batch 222/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.36006537\n",
      "Trained for batch 223/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.37888\n",
      "Trained for batch 224/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.39886275\n",
      "Trained for batch 225/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3026018\n",
      "Trained for batch 226/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.29396725\n",
      "Trained for batch 227/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32766557\n",
      "Trained for batch 228/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.33254832\n",
      "Trained for batch 229/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.2968884\n",
      "Trained for batch 230/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34788048\n",
      "Trained for batch 231/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.39196214\n",
      "Trained for batch 232/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.37222928\n",
      "Trained for batch 233/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.373175\n",
      "Trained for batch 234/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34602457\n",
      "Trained for batch 235/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3358532\n",
      "Trained for batch 236/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35393804\n",
      "Trained for batch 237/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.30445045\n",
      "Trained for batch 238/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.30499512\n",
      "Trained for batch 239/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.31633323\n",
      "Trained for batch 240/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ENCODER_LOSS:  0.33693916\n",
      "Trained for batch 241/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35391867\n",
      "Trained for batch 242/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3634351\n",
      "Trained for batch 243/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.31472343\n",
      "Trained for batch 244/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.38196006\n",
      "Trained for batch 245/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35402516\n",
      "Trained for batch 246/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34186852\n",
      "Trained for batch 247/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3964009\n",
      "Trained for batch 248/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3415746\n",
      "Trained for batch 249/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3305865\n",
      "Trained for batch 250/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3461059\n",
      "Trained for batch 251/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.36268607\n",
      "Trained for batch 252/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.30566144\n",
      "Trained for batch 253/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3079744\n",
      "Trained for batch 254/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.36317885\n",
      "Trained for batch 255/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3273632\n",
      "Trained for batch 256/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3051898\n",
      "Trained for batch 257/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35573307\n",
      "Trained for batch 258/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35416347\n",
      "Trained for batch 259/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.38379028\n",
      "Trained for batch 260/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3171835\n",
      "Trained for batch 261/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3639734\n",
      "Trained for batch 262/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3020048\n",
      "Trained for batch 263/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32925206\n",
      "Trained for batch 264/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.33193964\n",
      "Trained for batch 265/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3918485\n",
      "Trained for batch 266/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32380143\n",
      "Trained for batch 267/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3460321\n",
      "Trained for batch 268/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3306979\n",
      "Trained for batch 269/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3440581\n",
      "Trained for batch 270/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3592406\n",
      "Trained for batch 271/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34784085\n",
      "Trained for batch 272/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.38791877\n",
      "Trained for batch 273/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3786557\n",
      "Trained for batch 274/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.361929\n",
      "Trained for batch 275/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3480948\n",
      "Trained for batch 276/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34595555\n",
      "Trained for batch 277/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34181142\n",
      "Trained for batch 278/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.33056882\n",
      "Trained for batch 279/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3788158\n",
      "Trained for batch 280/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32907015\n",
      "Trained for batch 281/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.33536705\n",
      "Trained for batch 282/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3830111\n",
      "Trained for batch 283/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3819602\n",
      "Trained for batch 284/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.36827105\n",
      "Trained for batch 285/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35019436\n",
      "Trained for batch 286/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32037956\n",
      "Trained for batch 287/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3254102\n",
      "Trained for batch 288/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.38073096\n",
      "Trained for batch 289/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32632905\n",
      "Trained for batch 290/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.352774\n",
      "Trained for batch 291/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3069288\n",
      "Trained for batch 292/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32800698\n",
      "Trained for batch 293/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35406795\n",
      "Trained for batch 294/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.4468451\n",
      "Trained for batch 295/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32792234\n",
      "Trained for batch 296/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.30619472\n",
      "Trained for batch 297/297\n",
      "______________________________EPOCH 8_______________________________\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3551001\n",
      "Trained for batch 1/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.28265437\n",
      "Trained for batch 2/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.33414665\n",
      "Trained for batch 3/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3442166\n",
      "Trained for batch 4/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.30520618\n",
      "Trained for batch 5/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35051823\n",
      "Trained for batch 6/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.37511212\n",
      "Trained for batch 7/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.36082497\n",
      "Trained for batch 8/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.36102173\n",
      "Trained for batch 9/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.31458655\n",
      "Trained for batch 10/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3434737\n",
      "Trained for batch 11/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3593556\n",
      "Trained for batch 12/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3083691\n",
      "Trained for batch 13/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.36119604\n",
      "Trained for batch 14/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.31740254\n",
      "Trained for batch 15/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.33510545\n",
      "Trained for batch 16/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35776955\n",
      "Trained for batch 17/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.33616275\n",
      "Trained for batch 18/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3303933\n",
      "Trained for batch 19/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3054049\n",
      "Trained for batch 20/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.29782152\n",
      "Trained for batch 21/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3983444\n",
      "Trained for batch 22/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3494304\n",
      "Trained for batch 23/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.44127995\n",
      "Trained for batch 24/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35476705\n",
      "Trained for batch 25/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.37283763\n",
      "Trained for batch 26/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.340755\n",
      "Trained for batch 27/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3492188\n",
      "Trained for batch 28/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32469207\n",
      "Trained for batch 29/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.31836286\n",
      "Trained for batch 30/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.31488967\n",
      "Trained for batch 31/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.31608766\n",
      "Trained for batch 32/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.31240934\n",
      "Trained for batch 33/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.37604302\n",
      "Trained for batch 34/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.39702758\n",
      "Trained for batch 35/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.29823047\n",
      "Trained for batch 36/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.33976194\n",
      "Trained for batch 37/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3153352\n",
      "Trained for batch 38/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3613078\n",
      "Trained for batch 39/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35302788\n",
      "Trained for batch 40/297\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.33679193\n",
      "Trained for batch 41/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35253224\n",
      "Trained for batch 42/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.2880394\n",
      "Trained for batch 43/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.30610064\n",
      "Trained for batch 44/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.29482666\n",
      "Trained for batch 45/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.37650508\n",
      "Trained for batch 46/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32607797\n",
      "Trained for batch 47/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.31938916\n",
      "Trained for batch 48/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.33587724\n",
      "Trained for batch 49/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.33454955\n",
      "Trained for batch 50/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3688293\n",
      "Trained for batch 51/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.30729672\n",
      "Trained for batch 52/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34042376\n",
      "Trained for batch 53/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3167634\n",
      "Trained for batch 54/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34718484\n",
      "Trained for batch 55/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3777779\n",
      "Trained for batch 56/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3744308\n",
      "Trained for batch 57/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.36467272\n",
      "Trained for batch 58/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32569218\n",
      "Trained for batch 59/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.38973862\n",
      "Trained for batch 60/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3238915\n",
      "Trained for batch 61/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.33159453\n",
      "Trained for batch 62/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32217628\n",
      "Trained for batch 63/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.28680333\n",
      "Trained for batch 64/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.27602863\n",
      "Trained for batch 65/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.31610483\n",
      "Trained for batch 66/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.33965576\n",
      "Trained for batch 67/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.36726326\n",
      "Trained for batch 68/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.2970804\n",
      "Trained for batch 69/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.39181176\n",
      "Trained for batch 70/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.30581775\n",
      "Trained for batch 71/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.36618176\n",
      "Trained for batch 72/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.36161\n",
      "Trained for batch 73/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3407348\n",
      "Trained for batch 74/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.30692214\n",
      "Trained for batch 75/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.38562074\n",
      "Trained for batch 76/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.29222876\n",
      "Trained for batch 77/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.31417817\n",
      "Trained for batch 78/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.33742172\n",
      "Trained for batch 79/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.36629358\n",
      "Trained for batch 80/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3227389\n",
      "Trained for batch 81/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35200304\n",
      "Trained for batch 82/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.37403312\n",
      "Trained for batch 83/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3535209\n",
      "Trained for batch 84/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.30335575\n",
      "Trained for batch 85/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3832961\n",
      "Trained for batch 86/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.2788886\n",
      "Trained for batch 87/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.39973253\n",
      "Trained for batch 88/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32751545\n",
      "Trained for batch 89/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3348545\n",
      "Trained for batch 90/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32595652\n",
      "Trained for batch 91/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35188788\n",
      "Trained for batch 92/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3412413\n",
      "Trained for batch 93/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.30956554\n",
      "Trained for batch 94/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.30909505\n",
      "Trained for batch 95/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.2934629\n",
      "Trained for batch 96/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.37926653\n",
      "Trained for batch 97/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3992003\n",
      "Trained for batch 98/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.38934177\n",
      "Trained for batch 99/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32211939\n",
      "Trained for batch 100/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.36199027\n",
      "Trained for batch 101/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3740831\n",
      "Trained for batch 102/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3795012\n",
      "Trained for batch 103/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.33297718\n",
      "Trained for batch 104/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.37375313\n",
      "Trained for batch 105/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.37758762\n",
      "Trained for batch 106/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.38384548\n",
      "Trained for batch 107/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.36724818\n",
      "Trained for batch 108/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.2997828\n",
      "Trained for batch 109/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34861857\n",
      "Trained for batch 110/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32960123\n",
      "Trained for batch 111/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.30828348\n",
      "Trained for batch 112/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.33179805\n",
      "Trained for batch 113/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34692323\n",
      "Trained for batch 114/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3249061\n",
      "Trained for batch 115/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.31641206\n",
      "Trained for batch 116/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.36409792\n",
      "Trained for batch 117/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3052989\n",
      "Trained for batch 118/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.30419475\n",
      "Trained for batch 119/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3736878\n",
      "Trained for batch 120/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.28911358\n",
      "Trained for batch 121/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.33296433\n",
      "Trained for batch 122/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.37569675\n",
      "Trained for batch 123/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3154468\n",
      "Trained for batch 124/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3388644\n",
      "Trained for batch 125/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.36095306\n",
      "Trained for batch 126/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3352297\n",
      "Trained for batch 127/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35829717\n",
      "Trained for batch 128/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.33134022\n",
      "Trained for batch 129/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34525317\n",
      "Trained for batch 130/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32975003\n",
      "Trained for batch 131/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35578793\n",
      "Trained for batch 132/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.33063194\n",
      "Trained for batch 133/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.38041133\n",
      "Trained for batch 134/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.33820558\n",
      "Trained for batch 135/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.31029683\n",
      "Trained for batch 136/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3439642\n",
      "Trained for batch 137/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.36116678\n",
      "Trained for batch 138/297\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3023852\n",
      "Trained for batch 139/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.44264302\n",
      "Trained for batch 140/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.33303457\n",
      "Trained for batch 141/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35073692\n",
      "Trained for batch 142/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.36515447\n",
      "Trained for batch 143/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3786377\n",
      "Trained for batch 144/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3650462\n",
      "Trained for batch 145/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.31338006\n",
      "Trained for batch 146/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.38102692\n",
      "Trained for batch 147/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32141516\n",
      "Trained for batch 148/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32435998\n",
      "Trained for batch 149/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32016382\n",
      "Trained for batch 150/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.4219242\n",
      "Trained for batch 151/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.29715243\n",
      "Trained for batch 152/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.30635667\n",
      "Trained for batch 153/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32206744\n",
      "Trained for batch 154/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.36129975\n",
      "Trained for batch 155/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.36102846\n",
      "Trained for batch 156/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.30674583\n",
      "Trained for batch 157/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.33928105\n",
      "Trained for batch 158/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34670535\n",
      "Trained for batch 159/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35400304\n",
      "Trained for batch 160/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.33950558\n",
      "Trained for batch 161/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.30294344\n",
      "Trained for batch 162/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34124485\n",
      "Trained for batch 163/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34895918\n",
      "Trained for batch 164/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35500604\n",
      "Trained for batch 165/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.37109914\n",
      "Trained for batch 166/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3674157\n",
      "Trained for batch 167/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35366362\n",
      "Trained for batch 168/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.31198093\n",
      "Trained for batch 169/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3009896\n",
      "Trained for batch 170/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.33042243\n",
      "Trained for batch 171/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.36815992\n",
      "Trained for batch 172/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3487313\n",
      "Trained for batch 173/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.37549895\n",
      "Trained for batch 174/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3707985\n",
      "Trained for batch 175/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3675609\n",
      "Trained for batch 176/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.39646953\n",
      "Trained for batch 177/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.33690378\n",
      "Trained for batch 178/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35397172\n",
      "Trained for batch 179/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3276864\n",
      "Trained for batch 180/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.33614343\n",
      "Trained for batch 181/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35403198\n",
      "Trained for batch 182/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3526484\n",
      "Trained for batch 183/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3924442\n",
      "Trained for batch 184/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3525689\n",
      "Trained for batch 185/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.37068698\n",
      "Trained for batch 186/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3215589\n",
      "Trained for batch 187/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3411097\n",
      "Trained for batch 188/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.324138\n",
      "Trained for batch 189/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32379055\n",
      "Trained for batch 190/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.37134218\n",
      "Trained for batch 191/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3605975\n",
      "Trained for batch 192/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.29402775\n",
      "Trained for batch 193/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.30357632\n",
      "Trained for batch 194/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.36017677\n",
      "Trained for batch 195/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.38008168\n",
      "Trained for batch 196/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32996625\n",
      "Trained for batch 197/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34227562\n",
      "Trained for batch 198/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.38058463\n",
      "Trained for batch 199/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.2994828\n",
      "Trained for batch 200/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32139587\n",
      "Trained for batch 201/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.36014247\n",
      "Trained for batch 202/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.40553847\n",
      "Trained for batch 203/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.36537856\n",
      "Trained for batch 204/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35883918\n",
      "Trained for batch 205/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.37126082\n",
      "Trained for batch 206/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3266707\n",
      "Trained for batch 207/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3261506\n",
      "Trained for batch 208/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32509398\n",
      "Trained for batch 209/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.38598523\n",
      "Trained for batch 210/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34421206\n",
      "Trained for batch 211/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.37693232\n",
      "Trained for batch 212/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32005215\n",
      "Trained for batch 213/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.350181\n",
      "Trained for batch 214/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35598335\n",
      "Trained for batch 215/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3649096\n",
      "Trained for batch 216/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.31345907\n",
      "Trained for batch 217/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34860754\n",
      "Trained for batch 218/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3117968\n",
      "Trained for batch 219/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3034927\n",
      "Trained for batch 220/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.340347\n",
      "Trained for batch 221/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.33487928\n",
      "Trained for batch 222/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34394556\n",
      "Trained for batch 223/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3452857\n",
      "Trained for batch 224/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.4128862\n",
      "Trained for batch 225/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35503298\n",
      "Trained for batch 226/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32394928\n",
      "Trained for batch 227/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3404475\n",
      "Trained for batch 228/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.31440392\n",
      "Trained for batch 229/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32141313\n",
      "Trained for batch 230/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32648435\n",
      "Trained for batch 231/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.37548614\n",
      "Trained for batch 232/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.41956052\n",
      "Trained for batch 233/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32084188\n",
      "Trained for batch 234/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.37481675\n",
      "Trained for batch 235/297\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.33419204\n",
      "Trained for batch 236/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.39403835\n",
      "Trained for batch 237/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.33316198\n",
      "Trained for batch 238/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.33800843\n",
      "Trained for batch 239/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34995073\n",
      "Trained for batch 240/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32008606\n",
      "Trained for batch 241/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.36980352\n",
      "Trained for batch 242/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.37101662\n",
      "Trained for batch 243/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34979528\n",
      "Trained for batch 244/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35365182\n",
      "Trained for batch 245/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.30538478\n",
      "Trained for batch 246/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.2894792\n",
      "Trained for batch 247/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3634727\n",
      "Trained for batch 248/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.33939928\n",
      "Trained for batch 249/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.36981896\n",
      "Trained for batch 250/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35156438\n",
      "Trained for batch 251/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3615887\n",
      "Trained for batch 252/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34639823\n",
      "Trained for batch 253/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.27866906\n",
      "Trained for batch 254/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.37813058\n",
      "Trained for batch 255/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34231275\n",
      "Trained for batch 256/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32214323\n",
      "Trained for batch 257/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.36437488\n",
      "Trained for batch 258/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.40058866\n",
      "Trained for batch 259/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.37513632\n",
      "Trained for batch 260/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.36940894\n",
      "Trained for batch 261/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.36827326\n",
      "Trained for batch 262/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.30782038\n",
      "Trained for batch 263/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32612523\n",
      "Trained for batch 264/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.31732562\n",
      "Trained for batch 265/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.36474276\n",
      "Trained for batch 266/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.33916038\n",
      "Trained for batch 267/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.2987267\n",
      "Trained for batch 268/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35605368\n",
      "Trained for batch 269/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34794128\n",
      "Trained for batch 270/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.2987285\n",
      "Trained for batch 271/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3386255\n",
      "Trained for batch 272/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3834928\n",
      "Trained for batch 273/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3914979\n",
      "Trained for batch 274/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34109965\n",
      "Trained for batch 275/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34029627\n",
      "Trained for batch 276/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3582084\n",
      "Trained for batch 277/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35555005\n",
      "Trained for batch 278/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.33583972\n",
      "Trained for batch 279/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3422969\n",
      "Trained for batch 280/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.30093655\n",
      "Trained for batch 281/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34637696\n",
      "Trained for batch 282/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.37887484\n",
      "Trained for batch 283/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3744673\n",
      "Trained for batch 284/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.36507303\n",
      "Trained for batch 285/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34853706\n",
      "Trained for batch 286/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3302135\n",
      "Trained for batch 287/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.31210333\n",
      "Trained for batch 288/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.361331\n",
      "Trained for batch 289/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35988545\n",
      "Trained for batch 290/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34460273\n",
      "Trained for batch 291/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32479295\n",
      "Trained for batch 292/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.36736163\n",
      "Trained for batch 293/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35662365\n",
      "Trained for batch 294/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.42138425\n",
      "Trained for batch 295/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3227296\n",
      "Trained for batch 296/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.33570838\n",
      "Trained for batch 297/297\n",
      "______________________________EPOCH 9_______________________________\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.33296943\n",
      "Trained for batch 1/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.28941542\n",
      "Trained for batch 2/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.2953559\n",
      "Trained for batch 3/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3939852\n",
      "Trained for batch 4/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.353036\n",
      "Trained for batch 5/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3499207\n",
      "Trained for batch 6/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.40760416\n",
      "Trained for batch 7/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3499376\n",
      "Trained for batch 8/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3444592\n",
      "Trained for batch 9/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3466701\n",
      "Trained for batch 10/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35754633\n",
      "Trained for batch 11/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.2989282\n",
      "Trained for batch 12/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.33431602\n",
      "Trained for batch 13/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.37281895\n",
      "Trained for batch 14/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.30717444\n",
      "Trained for batch 15/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32651973\n",
      "Trained for batch 16/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3880852\n",
      "Trained for batch 17/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35024124\n",
      "Trained for batch 18/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35086632\n",
      "Trained for batch 19/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.31377774\n",
      "Trained for batch 20/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.30159453\n",
      "Trained for batch 21/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.4221999\n",
      "Trained for batch 22/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3587726\n",
      "Trained for batch 23/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.38674778\n",
      "Trained for batch 24/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32769457\n",
      "Trained for batch 25/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.38408926\n",
      "Trained for batch 26/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3434076\n",
      "Trained for batch 27/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3495937\n",
      "Trained for batch 28/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.38810524\n",
      "Trained for batch 29/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.31009513\n",
      "Trained for batch 30/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3497146\n",
      "Trained for batch 31/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32907528\n",
      "Trained for batch 32/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32728767\n",
      "Trained for batch 33/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3863633\n",
      "Trained for batch 34/297\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3796348\n",
      "Trained for batch 35/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3168254\n",
      "Trained for batch 36/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3418399\n",
      "Trained for batch 37/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.30257922\n",
      "Trained for batch 38/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.33095852\n",
      "Trained for batch 39/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3421443\n",
      "Trained for batch 40/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3411554\n",
      "Trained for batch 41/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.37404117\n",
      "Trained for batch 42/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.30943727\n",
      "Trained for batch 43/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.33858544\n",
      "Trained for batch 44/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.31657737\n",
      "Trained for batch 45/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.39568296\n",
      "Trained for batch 46/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.33242887\n",
      "Trained for batch 47/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.324806\n",
      "Trained for batch 48/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.33724982\n",
      "Trained for batch 49/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35135603\n",
      "Trained for batch 50/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.36032432\n",
      "Trained for batch 51/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.2858079\n",
      "Trained for batch 52/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35041684\n",
      "Trained for batch 53/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32191658\n",
      "Trained for batch 54/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3127703\n",
      "Trained for batch 55/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3723138\n",
      "Trained for batch 56/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.37807694\n",
      "Trained for batch 57/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3268513\n",
      "Trained for batch 58/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.28684133\n",
      "Trained for batch 59/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.40281123\n",
      "Trained for batch 60/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.30199942\n",
      "Trained for batch 61/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3416314\n",
      "Trained for batch 62/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3169857\n",
      "Trained for batch 63/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.29195616\n",
      "Trained for batch 64/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.30914053\n",
      "Trained for batch 65/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32096165\n",
      "Trained for batch 66/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3556691\n",
      "Trained for batch 67/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3824398\n",
      "Trained for batch 68/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.33287323\n",
      "Trained for batch 69/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.36914054\n",
      "Trained for batch 70/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32143465\n",
      "Trained for batch 71/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32763666\n",
      "Trained for batch 72/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.36872277\n",
      "Trained for batch 73/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34355843\n",
      "Trained for batch 74/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3468315\n",
      "Trained for batch 75/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.31598678\n",
      "Trained for batch 76/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.2918956\n",
      "Trained for batch 77/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32653967\n",
      "Trained for batch 78/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.36602378\n",
      "Trained for batch 79/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.39626855\n",
      "Trained for batch 80/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34867254\n",
      "Trained for batch 81/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.30916318\n",
      "Trained for batch 82/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35978025\n",
      "Trained for batch 83/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3374737\n",
      "Trained for batch 84/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3140041\n",
      "Trained for batch 85/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3418253\n",
      "Trained for batch 86/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.25549775\n",
      "Trained for batch 87/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3980413\n",
      "Trained for batch 88/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.33510584\n",
      "Trained for batch 89/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3367741\n",
      "Trained for batch 90/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.29601175\n",
      "Trained for batch 91/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32124043\n",
      "Trained for batch 92/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35313207\n",
      "Trained for batch 93/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.39118084\n",
      "Trained for batch 94/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3078925\n",
      "Trained for batch 95/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3044447\n",
      "Trained for batch 96/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.4049964\n",
      "Trained for batch 97/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3355379\n",
      "Trained for batch 98/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3840339\n",
      "Trained for batch 99/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35462913\n",
      "Trained for batch 100/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.36638272\n",
      "Trained for batch 101/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35424596\n",
      "Trained for batch 102/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.36495134\n",
      "Trained for batch 103/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32892922\n",
      "Trained for batch 104/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.33140278\n",
      "Trained for batch 105/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3880574\n",
      "Trained for batch 106/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3737828\n",
      "Trained for batch 107/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34403569\n",
      "Trained for batch 108/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.28616133\n",
      "Trained for batch 109/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35425192\n",
      "Trained for batch 110/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3407727\n",
      "Trained for batch 111/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.33976206\n",
      "Trained for batch 112/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.36111093\n",
      "Trained for batch 113/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3694399\n",
      "Trained for batch 114/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3159538\n",
      "Trained for batch 115/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32093355\n",
      "Trained for batch 116/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.393778\n",
      "Trained for batch 117/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35276595\n",
      "Trained for batch 118/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3198053\n",
      "Trained for batch 119/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.36683524\n",
      "Trained for batch 120/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3648066\n",
      "Trained for batch 121/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34784108\n",
      "Trained for batch 122/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.39873666\n",
      "Trained for batch 123/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32373685\n",
      "Trained for batch 124/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34146675\n",
      "Trained for batch 125/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.36762652\n",
      "Trained for batch 126/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.41833633\n",
      "Trained for batch 127/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34942126\n",
      "Trained for batch 128/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.2992298\n",
      "Trained for batch 129/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32395262\n",
      "Trained for batch 130/297\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32388964\n",
      "Trained for batch 131/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.323322\n",
      "Trained for batch 132/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.30888215\n",
      "Trained for batch 133/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.37224823\n",
      "Trained for batch 134/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3388362\n",
      "Trained for batch 135/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32118547\n",
      "Trained for batch 136/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35394782\n",
      "Trained for batch 137/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.318221\n",
      "Trained for batch 138/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.29761267\n",
      "Trained for batch 139/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.375335\n",
      "Trained for batch 140/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34264797\n",
      "Trained for batch 141/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.30858383\n",
      "Trained for batch 142/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.37515894\n",
      "Trained for batch 143/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.37414727\n",
      "Trained for batch 144/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.36432537\n",
      "Trained for batch 145/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.30506906\n",
      "Trained for batch 146/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.41304594\n",
      "Trained for batch 147/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3483222\n",
      "Trained for batch 148/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.2979738\n",
      "Trained for batch 149/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.28076574\n",
      "Trained for batch 150/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35923532\n",
      "Trained for batch 151/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.28870803\n",
      "Trained for batch 152/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3118182\n",
      "Trained for batch 153/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32762113\n",
      "Trained for batch 154/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.33773905\n",
      "Trained for batch 155/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.36131397\n",
      "Trained for batch 156/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.31954008\n",
      "Trained for batch 157/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35014766\n",
      "Trained for batch 158/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.36921468\n",
      "Trained for batch 159/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35491666\n",
      "Trained for batch 160/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3294254\n",
      "Trained for batch 161/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32721025\n",
      "Trained for batch 162/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34426516\n",
      "Trained for batch 163/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.31979412\n",
      "Trained for batch 164/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3574624\n",
      "Trained for batch 165/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3582757\n",
      "Trained for batch 166/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3399687\n",
      "Trained for batch 167/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3653551\n",
      "Trained for batch 168/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.30745482\n",
      "Trained for batch 169/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32097214\n",
      "Trained for batch 170/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3376546\n",
      "Trained for batch 171/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.39578956\n",
      "Trained for batch 172/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35321575\n",
      "Trained for batch 173/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.37984842\n",
      "Trained for batch 174/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3504996\n",
      "Trained for batch 175/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.37231466\n",
      "Trained for batch 176/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.4120984\n",
      "Trained for batch 177/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3340658\n",
      "Trained for batch 178/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34891272\n",
      "Trained for batch 179/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35529208\n",
      "Trained for batch 180/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3451162\n",
      "Trained for batch 181/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35894445\n",
      "Trained for batch 182/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35725397\n",
      "Trained for batch 183/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.38750523\n",
      "Trained for batch 184/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3441148\n",
      "Trained for batch 185/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.31688744\n",
      "Trained for batch 186/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34141147\n",
      "Trained for batch 187/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.31493738\n",
      "Trained for batch 188/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3014082\n",
      "Trained for batch 189/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34443444\n",
      "Trained for batch 190/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.38837492\n",
      "Trained for batch 191/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3548825\n",
      "Trained for batch 192/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.30643588\n",
      "Trained for batch 193/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.29253784\n",
      "Trained for batch 194/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3520768\n",
      "Trained for batch 195/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3393981\n",
      "Trained for batch 196/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3229516\n",
      "Trained for batch 197/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.37516937\n",
      "Trained for batch 198/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34842154\n",
      "Trained for batch 199/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34964222\n",
      "Trained for batch 200/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.301328\n",
      "Trained for batch 201/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3281063\n",
      "Trained for batch 202/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34114808\n",
      "Trained for batch 203/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.36627907\n",
      "Trained for batch 204/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3774476\n",
      "Trained for batch 205/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.352822\n",
      "Trained for batch 206/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34912735\n",
      "Trained for batch 207/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.38816532\n",
      "Trained for batch 208/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32110515\n",
      "Trained for batch 209/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35956758\n",
      "Trained for batch 210/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34479722\n",
      "Trained for batch 211/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.38668615\n",
      "Trained for batch 212/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.307279\n",
      "Trained for batch 213/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.33725107\n",
      "Trained for batch 214/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34530377\n",
      "Trained for batch 215/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3383258\n",
      "Trained for batch 216/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3470748\n",
      "Trained for batch 217/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.37074068\n",
      "Trained for batch 218/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.33613747\n",
      "Trained for batch 219/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.33075932\n",
      "Trained for batch 220/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.30847573\n",
      "Trained for batch 221/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32828125\n",
      "Trained for batch 222/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.33334914\n",
      "Trained for batch 223/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.36080408\n",
      "Trained for batch 224/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3285461\n",
      "Trained for batch 225/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.38259283\n",
      "Trained for batch 226/297\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3010694\n",
      "Trained for batch 227/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3061804\n",
      "Trained for batch 228/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35019785\n",
      "Trained for batch 229/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32632327\n",
      "Trained for batch 230/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3060719\n",
      "Trained for batch 231/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.37866038\n",
      "Trained for batch 232/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.37322083\n",
      "Trained for batch 233/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.37643772\n",
      "Trained for batch 234/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.30227283\n",
      "Trained for batch 235/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3125003\n",
      "Trained for batch 236/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.36727518\n",
      "Trained for batch 237/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.31224576\n",
      "Trained for batch 238/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3064126\n",
      "Trained for batch 239/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3085772\n",
      "Trained for batch 240/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.2805546\n",
      "Trained for batch 241/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35293478\n",
      "Trained for batch 242/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.33181724\n",
      "Trained for batch 243/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32279545\n",
      "Trained for batch 244/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.43898553\n",
      "Trained for batch 245/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.29467764\n",
      "Trained for batch 246/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.31553432\n",
      "Trained for batch 247/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35627106\n",
      "Trained for batch 248/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.31367713\n",
      "Trained for batch 249/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.31688154\n",
      "Trained for batch 250/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3286323\n",
      "Trained for batch 251/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3542263\n",
      "Trained for batch 252/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34895778\n",
      "Trained for batch 253/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.33777976\n",
      "Trained for batch 254/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3409864\n",
      "Trained for batch 255/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.33294263\n",
      "Trained for batch 256/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.31702918\n",
      "Trained for batch 257/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34895623\n",
      "Trained for batch 258/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35229033\n",
      "Trained for batch 259/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.36636174\n",
      "Trained for batch 260/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.31025332\n",
      "Trained for batch 261/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35035512\n",
      "Trained for batch 262/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32173544\n",
      "Trained for batch 263/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3014017\n",
      "Trained for batch 264/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.2979385\n",
      "Trained for batch 265/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3723281\n",
      "Trained for batch 266/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32729062\n",
      "Trained for batch 267/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.31649098\n",
      "Trained for batch 268/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32742366\n",
      "Trained for batch 269/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.37710533\n",
      "Trained for batch 270/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.31430903\n",
      "Trained for batch 271/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34674802\n",
      "Trained for batch 272/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.39254138\n",
      "Trained for batch 273/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.39447594\n",
      "Trained for batch 274/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32643253\n",
      "Trained for batch 275/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3361595\n",
      "Trained for batch 276/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3589414\n",
      "Trained for batch 277/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.36501426\n",
      "Trained for batch 278/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.33893004\n",
      "Trained for batch 279/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.4047432\n",
      "Trained for batch 280/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32966405\n",
      "Trained for batch 281/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.36063254\n",
      "Trained for batch 282/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3521835\n",
      "Trained for batch 283/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34628004\n",
      "Trained for batch 284/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.36135834\n",
      "Trained for batch 285/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.33292675\n",
      "Trained for batch 286/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.36619386\n",
      "Trained for batch 287/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32063395\n",
      "Trained for batch 288/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3465434\n",
      "Trained for batch 289/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3409411\n",
      "Trained for batch 290/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3704365\n",
      "Trained for batch 291/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.28071636\n",
      "Trained for batch 292/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3262197\n",
      "Trained for batch 293/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.38644034\n",
      "Trained for batch 294/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.4080606\n",
      "Trained for batch 295/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3315773\n",
      "Trained for batch 296/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32229254\n",
      "Trained for batch 297/297\n",
      "______________________________EPOCH 10_______________________________\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35539478\n",
      "Trained for batch 1/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.28588992\n",
      "Trained for batch 2/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35659418\n",
      "Trained for batch 3/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.36949825\n",
      "Trained for batch 4/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32793075\n",
      "Trained for batch 5/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32157487\n",
      "Trained for batch 6/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3797978\n",
      "Trained for batch 7/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32475916\n",
      "Trained for batch 8/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35257807\n",
      "Trained for batch 9/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35992166\n",
      "Trained for batch 10/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34390065\n",
      "Trained for batch 11/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32568485\n",
      "Trained for batch 12/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.31992975\n",
      "Trained for batch 13/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34872422\n",
      "Trained for batch 14/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.29439342\n",
      "Trained for batch 15/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.409238\n",
      "Trained for batch 16/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.38723052\n",
      "Trained for batch 17/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.36117548\n",
      "Trained for batch 18/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.33846292\n",
      "Trained for batch 19/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.33199066\n",
      "Trained for batch 20/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.30679864\n",
      "Trained for batch 21/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.40672952\n",
      "Trained for batch 22/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.37447608\n",
      "Trained for batch 23/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3480604\n",
      "Trained for batch 24/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ENCODER_LOSS:  0.31883574\n",
      "Trained for batch 25/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.41635552\n",
      "Trained for batch 26/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35120064\n",
      "Trained for batch 27/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.33973894\n",
      "Trained for batch 28/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.36110047\n",
      "Trained for batch 29/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3147204\n",
      "Trained for batch 30/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3384139\n",
      "Trained for batch 31/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.320926\n",
      "Trained for batch 32/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3457556\n",
      "Trained for batch 33/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35738665\n",
      "Trained for batch 34/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.36773485\n",
      "Trained for batch 35/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.31273827\n",
      "Trained for batch 36/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35776833\n",
      "Trained for batch 37/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.31555623\n",
      "Trained for batch 38/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3532172\n",
      "Trained for batch 39/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.29086384\n",
      "Trained for batch 40/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.33449563\n",
      "Trained for batch 41/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3179071\n",
      "Trained for batch 42/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3037045\n",
      "Trained for batch 43/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.37271005\n",
      "Trained for batch 44/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.2838856\n",
      "Trained for batch 45/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35598773\n",
      "Trained for batch 46/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.31177384\n",
      "Trained for batch 47/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.36308545\n",
      "Trained for batch 48/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.31830716\n",
      "Trained for batch 49/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35112208\n",
      "Trained for batch 50/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.33839837\n",
      "Trained for batch 51/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.31503063\n",
      "Trained for batch 52/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3448814\n",
      "Trained for batch 53/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3373068\n",
      "Trained for batch 54/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.39121127\n",
      "Trained for batch 55/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3543077\n",
      "Trained for batch 56/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.40438327\n",
      "Trained for batch 57/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.38937363\n",
      "Trained for batch 58/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.27248526\n",
      "Trained for batch 59/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3908475\n",
      "Trained for batch 60/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3226821\n",
      "Trained for batch 61/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.31497937\n",
      "Trained for batch 62/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.31856963\n",
      "Trained for batch 63/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.29908448\n",
      "Trained for batch 64/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.27423698\n",
      "Trained for batch 65/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32566434\n",
      "Trained for batch 66/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.33128673\n",
      "Trained for batch 67/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3259086\n",
      "Trained for batch 68/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32598203\n",
      "Trained for batch 69/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.36965093\n",
      "Trained for batch 70/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.36557692\n",
      "Trained for batch 71/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.33970833\n",
      "Trained for batch 72/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.38550287\n",
      "Trained for batch 73/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32308674\n",
      "Trained for batch 74/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.33768836\n",
      "Trained for batch 75/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32568678\n",
      "Trained for batch 76/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.30279082\n",
      "Trained for batch 77/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.2829091\n",
      "Trained for batch 78/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3375931\n",
      "Trained for batch 79/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3729077\n",
      "Trained for batch 80/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32523438\n",
      "Trained for batch 81/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3120227\n",
      "Trained for batch 82/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.36237627\n",
      "Trained for batch 83/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3143904\n",
      "Trained for batch 84/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.2899064\n",
      "Trained for batch 85/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.31974068\n",
      "Trained for batch 86/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.30639\n",
      "Trained for batch 87/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.39905602\n",
      "Trained for batch 88/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.37996632\n",
      "Trained for batch 89/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.33770585\n",
      "Trained for batch 90/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3067326\n",
      "Trained for batch 91/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3918704\n",
      "Trained for batch 92/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.30850467\n",
      "Trained for batch 93/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34371763\n",
      "Trained for batch 94/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.28271165\n",
      "Trained for batch 95/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32848987\n",
      "Trained for batch 96/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.39654523\n",
      "Trained for batch 97/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3805952\n",
      "Trained for batch 98/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.38713413\n",
      "Trained for batch 99/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35603404\n",
      "Trained for batch 100/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3689137\n",
      "Trained for batch 101/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3943407\n",
      "Trained for batch 102/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.4091382\n",
      "Trained for batch 103/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.36646327\n",
      "Trained for batch 104/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.36041752\n",
      "Trained for batch 105/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.36855957\n",
      "Trained for batch 106/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.39989614\n",
      "Trained for batch 107/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35495293\n",
      "Trained for batch 108/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.2758552\n",
      "Trained for batch 109/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35956272\n",
      "Trained for batch 110/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35178256\n",
      "Trained for batch 111/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3222854\n",
      "Trained for batch 112/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.39342567\n",
      "Trained for batch 113/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3852425\n",
      "Trained for batch 114/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.30445313\n",
      "Trained for batch 115/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3063447\n",
      "Trained for batch 116/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3479405\n",
      "Trained for batch 117/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35641932\n",
      "Trained for batch 118/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.2926173\n",
      "Trained for batch 119/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.38515347\n",
      "Trained for batch 120/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.29506248\n",
      "Trained for batch 121/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3455595\n",
      "Trained for batch 122/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34911463\n",
      "Trained for batch 123/297\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3043389\n",
      "Trained for batch 124/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3407587\n",
      "Trained for batch 125/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.37842256\n",
      "Trained for batch 126/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.42039028\n",
      "Trained for batch 127/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34904772\n",
      "Trained for batch 128/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.33943337\n",
      "Trained for batch 129/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32645446\n",
      "Trained for batch 130/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3170588\n",
      "Trained for batch 131/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3679373\n",
      "Trained for batch 132/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3058182\n",
      "Trained for batch 133/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34249258\n",
      "Trained for batch 134/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3988776\n",
      "Trained for batch 135/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3114909\n",
      "Trained for batch 136/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.33724895\n",
      "Trained for batch 137/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3540582\n",
      "Trained for batch 138/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3019135\n",
      "Trained for batch 139/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.42217523\n",
      "Trained for batch 140/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3498549\n",
      "Trained for batch 141/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.2797708\n",
      "Trained for batch 142/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32861412\n",
      "Trained for batch 143/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3440314\n",
      "Trained for batch 144/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.33772886\n",
      "Trained for batch 145/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.30104363\n",
      "Trained for batch 146/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34000722\n",
      "Trained for batch 147/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35398087\n",
      "Trained for batch 148/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.28254348\n",
      "Trained for batch 149/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.30499858\n",
      "Trained for batch 150/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3679263\n",
      "Trained for batch 151/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3078775\n",
      "Trained for batch 152/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3187809\n",
      "Trained for batch 153/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3030731\n",
      "Trained for batch 154/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34862244\n",
      "Trained for batch 155/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3516122\n",
      "Trained for batch 156/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35347646\n",
      "Trained for batch 157/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3471507\n",
      "Trained for batch 158/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3344007\n",
      "Trained for batch 159/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3121932\n",
      "Trained for batch 160/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32346547\n",
      "Trained for batch 161/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.28737244\n",
      "Trained for batch 162/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3748979\n",
      "Trained for batch 163/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.37051663\n",
      "Trained for batch 164/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.38531703\n",
      "Trained for batch 165/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.37808043\n",
      "Trained for batch 166/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.2930401\n",
      "Trained for batch 167/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32048237\n",
      "Trained for batch 168/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.319503\n",
      "Trained for batch 169/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32380575\n",
      "Trained for batch 170/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3521889\n",
      "Trained for batch 171/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34228224\n",
      "Trained for batch 172/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.36630097\n",
      "Trained for batch 173/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.31388706\n",
      "Trained for batch 174/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.38161594\n",
      "Trained for batch 175/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.41497603\n",
      "Trained for batch 176/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.33036193\n",
      "Trained for batch 177/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3013133\n",
      "Trained for batch 178/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3242336\n",
      "Trained for batch 179/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32226032\n",
      "Trained for batch 180/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32979578\n",
      "Trained for batch 181/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.37610787\n",
      "Trained for batch 182/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3888103\n",
      "Trained for batch 183/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.390258\n",
      "Trained for batch 184/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35843953\n",
      "Trained for batch 185/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.33762714\n",
      "Trained for batch 186/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3486177\n",
      "Trained for batch 187/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3084072\n",
      "Trained for batch 188/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35451144\n",
      "Trained for batch 189/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3158084\n",
      "Trained for batch 190/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3916723\n",
      "Trained for batch 191/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3572413\n",
      "Trained for batch 192/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3165489\n",
      "Trained for batch 193/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.2971801\n",
      "Trained for batch 194/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.374655\n",
      "Trained for batch 195/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35445923\n",
      "Trained for batch 196/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3350939\n",
      "Trained for batch 197/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3742798\n",
      "Trained for batch 198/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.37035197\n",
      "Trained for batch 199/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.29356936\n",
      "Trained for batch 200/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35288876\n",
      "Trained for batch 201/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.41492453\n",
      "Trained for batch 202/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.38562435\n",
      "Trained for batch 203/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34253493\n",
      "Trained for batch 204/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.37403923\n",
      "Trained for batch 205/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.38388005\n",
      "Trained for batch 206/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3518843\n",
      "Trained for batch 207/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3205003\n",
      "Trained for batch 208/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.31481966\n",
      "Trained for batch 209/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35511148\n",
      "Trained for batch 210/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32671684\n",
      "Trained for batch 211/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35429344\n",
      "Trained for batch 212/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3176559\n",
      "Trained for batch 213/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35123256\n",
      "Trained for batch 214/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.36999756\n",
      "Trained for batch 215/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3316709\n",
      "Trained for batch 216/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3401052\n",
      "Trained for batch 217/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.38270006\n",
      "Trained for batch 218/297\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.31817198\n",
      "Trained for batch 219/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3468508\n",
      "Trained for batch 220/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.30156118\n",
      "Trained for batch 221/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.36364666\n",
      "Trained for batch 222/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34083557\n",
      "Trained for batch 223/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3489079\n",
      "Trained for batch 224/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.36103243\n",
      "Trained for batch 225/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.33213648\n",
      "Trained for batch 226/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34551066\n",
      "Trained for batch 227/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.31514326\n",
      "Trained for batch 228/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.37313473\n",
      "Trained for batch 229/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32281956\n",
      "Trained for batch 230/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.31725246\n",
      "Trained for batch 231/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.37747708\n",
      "Trained for batch 232/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.4050398\n",
      "Trained for batch 233/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32459015\n",
      "Trained for batch 234/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34179324\n",
      "Trained for batch 235/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3197468\n",
      "Trained for batch 236/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3732619\n",
      "Trained for batch 237/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34436703\n",
      "Trained for batch 238/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.31270367\n",
      "Trained for batch 239/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.29310438\n",
      "Trained for batch 240/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34326768\n",
      "Trained for batch 241/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34080702\n",
      "Trained for batch 242/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3259127\n",
      "Trained for batch 243/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.29425323\n",
      "Trained for batch 244/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3491314\n",
      "Trained for batch 245/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.33397058\n",
      "Trained for batch 246/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.29434136\n",
      "Trained for batch 247/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3430833\n",
      "Trained for batch 248/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3029787\n",
      "Trained for batch 249/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3048789\n",
      "Trained for batch 250/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.2949042\n",
      "Trained for batch 251/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3542016\n",
      "Trained for batch 252/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32079035\n",
      "Trained for batch 253/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.31327462\n",
      "Trained for batch 254/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.40818587\n",
      "Trained for batch 255/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.37415084\n",
      "Trained for batch 256/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.30747554\n",
      "Trained for batch 257/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.367243\n",
      "Trained for batch 258/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.30382603\n",
      "Trained for batch 259/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.40162864\n",
      "Trained for batch 260/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32209745\n",
      "Trained for batch 261/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3404111\n",
      "Trained for batch 262/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.31813344\n",
      "Trained for batch 263/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34146878\n",
      "Trained for batch 264/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.28010297\n",
      "Trained for batch 265/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.38869178\n",
      "Trained for batch 266/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35835886\n",
      "Trained for batch 267/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.33107752\n",
      "Trained for batch 268/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.33013695\n",
      "Trained for batch 269/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.36334857\n",
      "Trained for batch 270/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3509792\n",
      "Trained for batch 271/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.30572173\n",
      "Trained for batch 272/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3742951\n",
      "Trained for batch 273/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3561626\n",
      "Trained for batch 274/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34305206\n",
      "Trained for batch 275/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.38961944\n",
      "Trained for batch 276/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.31751433\n",
      "Trained for batch 277/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.351371\n",
      "Trained for batch 278/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.33905163\n",
      "Trained for batch 279/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.33171803\n",
      "Trained for batch 280/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.29473555\n",
      "Trained for batch 281/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32707274\n",
      "Trained for batch 282/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.37233043\n",
      "Trained for batch 283/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3677141\n",
      "Trained for batch 284/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.36467367\n",
      "Trained for batch 285/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.33092767\n",
      "Trained for batch 286/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3232161\n",
      "Trained for batch 287/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.31680498\n",
      "Trained for batch 288/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34922788\n",
      "Trained for batch 289/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.31770024\n",
      "Trained for batch 290/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3458851\n",
      "Trained for batch 291/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34187418\n",
      "Trained for batch 292/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.34421334\n",
      "Trained for batch 293/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.35940352\n",
      "Trained for batch 294/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.45612273\n",
      "Trained for batch 295/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.3273939\n",
      "Trained for batch 296/297\n",
      "Generated batch (10, 4, 64, 64, 3)\n",
      "ENCODER_LOSS:  0.32281226\n",
      "Trained for batch 297/297\n",
      "______________________________TRAINING COMPLETED_______________________________\n"
     ]
    }
   ],
   "source": [
    "train_dataset = all_families[:-100]\n",
    "test_dataset = all_families[-100:]\n",
    "encoder = EncoderNN()\n",
    "\n",
    "with tf.device('/gpu:0'):\n",
    "    fit_encoder(train_dataset, EPOCHS, test_dataset,batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.704274\n",
      "0.8001106\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "f_no = 1106\n",
    "family_data = generate_batch([all_families[f_no]])\n",
    "inp = [family_data[0][0],family_data[0][1]]\n",
    "inp = tf.cast(inp, tf.float32)\n",
    "\n",
    "father_inp = inp[0][tf.newaxis,...]\n",
    "mother_inp = inp[1][tf.newaxis,...]\n",
    "\n",
    "with tf.device('/cpu:0'):\n",
    "    gen_output = encoder([father_inp, mother_inp], training=True)\n",
    "temp = gen_output.numpy()\n",
    "plt.imshow(np.squeeze(temp))\n",
    "# print(temp)\n",
    "print(np.amin(temp))\n",
    "print(np.amax(temp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x24d88e9e1c8>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "target = family_data[0][3]\n",
    "plt.imshow(target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###############################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def disc_downsample_parent_target(filters, size, apply_batchnorm=True):\n",
    "    initializer = tf.random_normal_initializer(mean, std_dev) \n",
    "  \n",
    "\n",
    "    result = tf.keras.Sequential()\n",
    "    result.add(\n",
    "      tf.keras.layers.Conv2D(filters, size, strides=2, padding='same',\n",
    "                             kernel_initializer=initializer,\n",
    "                             use_bias=False))\n",
    "\n",
    "    if apply_batchnorm:\n",
    "        result.add(tf.keras.layers.BatchNormalization())\n",
    "        \n",
    "    result.add(tf.keras.layers.LeakyReLU(alpha = 0.2))\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def disc_loss(filters, size,apply_batchnorm = False):\n",
    "    initializer = tf.random_normal_initializer(mean, std_dev)\n",
    "\n",
    "    result = tf.keras.Sequential()\n",
    "    result.add(\n",
    "    tf.keras.layers.Conv2D(filters, size, strides=2,\n",
    "                                    padding='same',\n",
    "                                    kernel_initializer=initializer,\n",
    "                                   use_bias=False))\n",
    "    if apply_batchnorm:\n",
    "        result.add(tf.keras.layers.BatchNormalization())\n",
    "        \n",
    "    result.add(tf.keras.layers.LeakyReLU(alpha = 0.2))\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Discriminator():\n",
    "\n",
    "    father = tf.keras.layers.Input(shape=(img_size,img_size,3))\n",
    "    mother = tf.keras.layers.Input(shape=(img_size,img_size,3))\n",
    "    target = tf.keras.layers.Input(shape=(img_size,img_size,3))\n",
    "    \n",
    "    down_stack_parent_target = [\n",
    "    disc_downsample_parent_target(32,4,apply_batchnorm=False), #32x32x32\n",
    "    disc_downsample_parent_target(64,4,apply_batchnorm=True)   #16x16x64\n",
    "    ]\n",
    "    \n",
    "    down_stack_combined =[\n",
    "    disc_loss(192,4,apply_batchnorm=True),\n",
    "    disc_loss(256,4,apply_batchnorm=False)\n",
    "    ]\n",
    "    \n",
    "    initializer = tf.random_normal_initializer(mean, sd_random_normal_init)\n",
    "    last = tf.keras.layers.Conv2D(1, 4, strides=1,padding='same',\n",
    "                                  kernel_initializer=initializer) # linear layer\n",
    "    \n",
    "    \n",
    "    concat = tf.keras.layers.Concatenate()\n",
    "    x1 = father\n",
    "    for down in down_stack_parent_target:\n",
    "        x1 = down(x1)\n",
    "    \n",
    "    x2 = mother\n",
    "    for down in down_stack_parent_target:\n",
    "        x2 = down(x2)\n",
    "        \n",
    "    x3 = target\n",
    "    for down in down_stack_parent_target:\n",
    "        x3 = down(x3)\n",
    "    \n",
    "    combined = concat([x1,x2,x3])\n",
    "    # combined is Batchx16x16x192\n",
    "    \n",
    "    x4 = combined\n",
    "    for down in down_stack_combined:\n",
    "        x4 = down(x4)\n",
    "#     print(x4.shape)\n",
    "    \n",
    "    output = last(x4) #4X4 \n",
    "    print(output.shape)\n",
    "\n",
    "    return tf.keras.Model(inputs=[father,mother,target], outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 4, 4, 1)\n"
     ]
    }
   ],
   "source": [
    "discriminator = Discriminator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# family_data = generate_image(all_families[126])\n",
    "# p1 = tf.cast(family_data[0], tf.float32)\n",
    "# p2 = tf.cast(family_data[1], tf.float32)\n",
    "# c = tf.cast(family_data[2], tf.float32)\n",
    "\n",
    "# discriminator = Discriminator()\n",
    "# with tf.device('/cpu:0'):\n",
    "#     disc_out = discriminator(inputs = [p1,p2,c], training=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "LAMBDA = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tensor_to_array(tensor1):\n",
    "    return tensor1.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator_loss(disc_real_output, disc_generated_output,b_size):\n",
    "    real_loss_diff = tf.abs(tf.ones_like(disc_real_output) - disc_real_output)\n",
    "    real_flatten_diff = tf.reshape(real_loss_diff, (b_size, 4*4*1))\n",
    "    real_loss_batch = tf.reduce_mean(real_flatten_diff, axis=1)\n",
    "    real_loss = tf.reduce_mean(real_loss_batch)\n",
    "    \n",
    "    gen_loss_diff = tf.abs(tf.zeros_like(disc_generated_output) - disc_generated_output)\n",
    "    gen_flatten_diff = tf.reshape(gen_loss_diff, (b_size, 4*4*1))\n",
    "    gen_loss_batch = tf.reduce_mean(gen_flatten_diff, axis=1)\n",
    "    gen_loss = tf.reduce_mean(gen_loss_batch)\n",
    "\n",
    "    total_disc_loss = real_loss + gen_loss\n",
    "    return total_disc_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_loss(disc_generated_output, gen_output, target,b_size):\n",
    "    gen_loss_diff = tf.abs(tf.ones_like(disc_generated_output) - disc_generated_output)\n",
    "    gen_flatten_diff = tf.reshape(gen_loss_diff, (b_size, 4*4*1))\n",
    "    gen_loss_batch = tf.reduce_mean(gen_flatten_diff, axis=1)\n",
    "    gen_loss = tf.reduce_mean(gen_loss_batch)\n",
    "    \n",
    "    l1_loss_diff = tf.abs(target - gen_output)\n",
    "    l1_flatten_diff = tf.reshape(l1_loss_diff, (b_size, img_size*img_size*3))\n",
    "    l1_loss_batch = tf.reduce_mean(l1_flatten_diff, axis=1)\n",
    "    l1_loss = tf.reduce_mean(l1_loss_batch)\n",
    " \n",
    "    total_gen_loss = gen_loss + LAMBDA * l1_loss  \n",
    "#     print(\"Reconstruction loss: {}, GAN loss: {}\".format(l1_loss, gen_loss))\n",
    "    return total_gen_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_optimizer = tf.keras.optimizers.Adam(lr, beta_1=b1 ,beta_2 = b2)\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(lr, beta_1=b1, beta_2 = b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(father_batch, mother_batch, target_batch,b_size):\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "        \n",
    "        gen_outputs = encoder([father_batch, mother_batch], training=True)\n",
    "#         print(\"Generated outputs\",gen_outputs.shape)\n",
    "        \n",
    "        disc_real_output = discriminator([father_batch, mother_batch, target_batch], training=True)\n",
    "#         print(\"disc_real_output \", disc_real_output.shape)\n",
    "        \n",
    "        disc_generated_output = discriminator([father_batch, mother_batch, gen_outputs], training=True)\n",
    "#         print(\"disc_generated_output \", disc_generated_output.shape)\n",
    "        \n",
    "        gen_loss =  generator_loss(disc_generated_output, gen_outputs, target_batch,b_size)\n",
    "        disc_loss = discriminator_loss(disc_real_output, disc_generated_output,b_size)\n",
    "    \n",
    "        \n",
    "    print(\"GEN_LOSS\",tensor_to_array(gen_loss))\n",
    "    print(\"DISC_LOSS\",tensor_to_array(disc_loss))\n",
    "\n",
    "    generator_gradients = gen_tape.gradient(gen_loss,encoder.trainable_variables)\n",
    "    discriminator_gradients = disc_tape.gradient(disc_loss,discriminator.trainable_variables)\n",
    "\n",
    "    generator_optimizer.apply_gradients(zip(generator_gradients,encoder.trainable_variables))\n",
    "    discriminator_optimizer.apply_gradients(zip(discriminator_gradients,discriminator.trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(train_ds, epochs, test_ds,batch):\n",
    "    for epoch in range(epochs):\n",
    "        print(\"______________________________EPOCH %d_______________________________\"%(epoch))\n",
    "        start = time.time()\n",
    "        for i in range(len(train_ds)//batch):\n",
    "            batch_data = np.asarray(generate_batch(train_ds[i*batch:(i+1)*batch]))\n",
    "            batch_data = batch_data / 255 * 2 -1\n",
    "            \n",
    "            print(\"Generated batch\", batch_data.shape)\n",
    "\n",
    "            X_father_train = tf.convert_to_tensor(batch_data[:,0],dtype =tf.float32)\n",
    "            X_mother_train = tf.convert_to_tensor(batch_data[:,1],dtype =tf.float32)\n",
    "#             print(\"Xtrain\",X_train.shape)\n",
    "#             print(\"Batch converted to tensor\")\n",
    "\n",
    "            Y_train = tf.convert_to_tensor(batch_data[:,3],dtype =tf.float32)\n",
    "            train_step(X_father_train, X_mother_train, Y_train, batch)\n",
    "            print(\"Trained for batch %d/%d\"%(i+1,(len(train_ds)//batch)))\n",
    "            \n",
    "#         family_no = 400\n",
    "#         family_data = generate_image(all_families[family_no][0], all_families[family_no][1], all_families[family_no][2])\n",
    "#         inp = [family_data[0],family_data[1]]\n",
    "#         inp = tf.cast(inp, tf.float32)\n",
    "#         father_inp = inp[0][tf.newaxis,...]\n",
    "#         mother_inp = inp[1][tf.newaxis,...]\n",
    "#         gen_output = encoder([father_inp, mother_inp], training=True)\n",
    "#         print(tf.reduce_min(gen_output))\n",
    "#         print(tf.reduce_max(gen_output))\n",
    "#         plt.figure()\n",
    "#         plt.imshow(gen_output[0,...])\n",
    "#         plt.show()\n",
    "        \n",
    "    print(\"______________________________TRAINING COMPLETED_______________________________\")\n",
    "    checkpoint.save(file_prefix = checkpoint_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat = tf.keras.layers.Concatenate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = all_families[:-10]\n",
    "test_dataset = all_families[-10:]\n",
    "encoder = EncoderNN()\n",
    "discriminator = Discriminator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = 64\n",
    "mean = 0.\n",
    "std_dev = 0.02\n",
    "lr = 0.0005\n",
    "b1 = 0.9\n",
    "b2 = 0.999\n",
    "sd_random_normal_init = 0.02\n",
    "\n",
    "EPOCHS = 5\n",
    "batch = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = './checkpoint'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n",
    "                                 discriminator_optimizer=discriminator_optimizer,\n",
    "                                 generator=encoder,\n",
    "                                 discriminator=discriminator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "______________________________EPOCH 0_______________________________\n",
      "Generated batch (25, 4, 64, 64, 3)\n",
      "GEN_LOSS 1.8714736\n",
      "DISC_LOSS 1.86838\n",
      "Trained for batch 1/40\n",
      "Generated batch (25, 4, 64, 64, 3)\n",
      "GEN_LOSS 2.4612353\n",
      "DISC_LOSS 4.9009223\n",
      "Trained for batch 2/40\n",
      "Generated batch (25, 4, 64, 64, 3)\n",
      "GEN_LOSS 1.5188591\n",
      "DISC_LOSS 3.105586\n",
      "Trained for batch 3/40\n",
      "Generated batch (25, 4, 64, 64, 3)\n",
      "GEN_LOSS 0.97126555\n",
      "DISC_LOSS 1.2524204\n",
      "Trained for batch 4/40\n",
      "Generated batch (25, 4, 64, 64, 3)\n",
      "GEN_LOSS 1.5256444\n",
      "DISC_LOSS 1.3195959\n",
      "Trained for batch 5/40\n",
      "Generated batch (25, 4, 64, 64, 3)\n",
      "GEN_LOSS 1.7478199\n",
      "DISC_LOSS 1.5654196\n",
      "Trained for batch 6/40\n",
      "Generated batch (25, 4, 64, 64, 3)\n",
      "GEN_LOSS 1.615851\n",
      "DISC_LOSS 1.3376899\n",
      "Trained for batch 7/40\n",
      "Generated batch (25, 4, 64, 64, 3)\n",
      "GEN_LOSS 1.3071386\n",
      "DISC_LOSS 1.0237919\n",
      "Trained for batch 8/40\n",
      "Generated batch (25, 4, 64, 64, 3)\n",
      "GEN_LOSS 1.033449\n",
      "DISC_LOSS 0.9461256\n",
      "Trained for batch 9/40\n",
      "Generated batch (25, 4, 64, 64, 3)\n",
      "GEN_LOSS 0.8963132\n",
      "DISC_LOSS 0.9979107\n",
      "Trained for batch 10/40\n",
      "Generated batch (25, 4, 64, 64, 3)\n",
      "GEN_LOSS 0.8280088\n",
      "DISC_LOSS 1.0079626\n",
      "Trained for batch 11/40\n",
      "Generated batch (25, 4, 64, 64, 3)\n",
      "GEN_LOSS 0.7844893\n",
      "DISC_LOSS 0.98840153\n",
      "Trained for batch 12/40\n",
      "Generated batch (25, 4, 64, 64, 3)\n",
      "GEN_LOSS 0.8130939\n",
      "DISC_LOSS 0.9575056\n",
      "Trained for batch 13/40\n",
      "Generated batch (25, 4, 64, 64, 3)\n",
      "GEN_LOSS 0.80703056\n",
      "DISC_LOSS 0.9344727\n",
      "Trained for batch 14/40\n",
      "Generated batch (25, 4, 64, 64, 3)\n",
      "GEN_LOSS 0.9170277\n",
      "DISC_LOSS 0.909178\n",
      "Trained for batch 15/40\n",
      "Generated batch (25, 4, 64, 64, 3)\n",
      "GEN_LOSS 0.9479166\n",
      "DISC_LOSS 0.89190656\n",
      "Trained for batch 16/40\n",
      "Generated batch (25, 4, 64, 64, 3)\n",
      "GEN_LOSS 0.96813387\n",
      "DISC_LOSS 0.91292846\n",
      "Trained for batch 17/40\n",
      "Generated batch (25, 4, 64, 64, 3)\n",
      "GEN_LOSS 0.9825418\n",
      "DISC_LOSS 0.9106399\n",
      "Trained for batch 18/40\n",
      "Generated batch (25, 4, 64, 64, 3)\n",
      "GEN_LOSS 1.0002934\n",
      "DISC_LOSS 0.89057213\n",
      "Trained for batch 19/40\n",
      "Generated batch (25, 4, 64, 64, 3)\n",
      "GEN_LOSS 0.9695563\n",
      "DISC_LOSS 0.9175471\n",
      "Trained for batch 20/40\n",
      "Generated batch (25, 4, 64, 64, 3)\n",
      "GEN_LOSS 0.9578241\n",
      "DISC_LOSS 0.9103563\n",
      "Trained for batch 21/40\n",
      "Generated batch (25, 4, 64, 64, 3)\n",
      "GEN_LOSS 0.9494082\n",
      "DISC_LOSS 0.93349683\n",
      "Trained for batch 22/40\n",
      "Generated batch (25, 4, 64, 64, 3)\n",
      "GEN_LOSS 0.96414757\n",
      "DISC_LOSS 0.96248746\n",
      "Trained for batch 23/40\n",
      "Generated batch (25, 4, 64, 64, 3)\n",
      "GEN_LOSS 0.9864141\n",
      "DISC_LOSS 0.9575828\n",
      "Trained for batch 24/40\n",
      "Generated batch (25, 4, 64, 64, 3)\n",
      "GEN_LOSS 1.0093925\n",
      "DISC_LOSS 0.9762958\n",
      "Trained for batch 25/40\n",
      "Generated batch (25, 4, 64, 64, 3)\n",
      "GEN_LOSS 1.0861416\n",
      "DISC_LOSS 0.92497194\n",
      "Trained for batch 26/40\n",
      "Generated batch (25, 4, 64, 64, 3)\n",
      "GEN_LOSS 1.0958909\n",
      "DISC_LOSS 0.9291233\n",
      "Trained for batch 27/40\n",
      "Generated batch (25, 4, 64, 64, 3)\n",
      "GEN_LOSS 1.0585023\n",
      "DISC_LOSS 0.9400269\n",
      "Trained for batch 28/40\n",
      "Generated batch (25, 4, 64, 64, 3)\n",
      "GEN_LOSS 1.1250031\n",
      "DISC_LOSS 0.9135808\n",
      "Trained for batch 29/40\n",
      "Generated batch (25, 4, 64, 64, 3)\n",
      "GEN_LOSS 1.0957966\n",
      "DISC_LOSS 0.941985\n",
      "Trained for batch 30/40\n",
      "Generated batch (25, 4, 64, 64, 3)\n",
      "GEN_LOSS 1.0928779\n",
      "DISC_LOSS 0.9060876\n",
      "Trained for batch 31/40\n",
      "Generated batch (25, 4, 64, 64, 3)\n",
      "GEN_LOSS 1.0167775\n",
      "DISC_LOSS 0.97104776\n",
      "Trained for batch 32/40\n",
      "Generated batch (25, 4, 64, 64, 3)\n",
      "GEN_LOSS 0.9991605\n",
      "DISC_LOSS 0.9424188\n",
      "Trained for batch 33/40\n",
      "Generated batch (25, 4, 64, 64, 3)\n",
      "GEN_LOSS 0.97426724\n",
      "DISC_LOSS 0.9429213\n",
      "Trained for batch 34/40\n",
      "Generated batch (25, 4, 64, 64, 3)\n",
      "GEN_LOSS 0.93371403\n",
      "DISC_LOSS 0.9179907\n",
      "Trained for batch 35/40\n",
      "Generated batch (25, 4, 64, 64, 3)\n",
      "GEN_LOSS 0.9309088\n",
      "DISC_LOSS 0.8584677\n",
      "Trained for batch 36/40\n",
      "Generated batch (25, 4, 64, 64, 3)\n",
      "GEN_LOSS 0.9956986\n",
      "DISC_LOSS 0.86251956\n",
      "Trained for batch 37/40\n",
      "Generated batch (25, 4, 64, 64, 3)\n",
      "GEN_LOSS 1.0101424\n",
      "DISC_LOSS 0.82430947\n",
      "Trained for batch 38/40\n",
      "Generated batch (25, 4, 64, 64, 3)\n",
      "GEN_LOSS 1.0703489\n",
      "DISC_LOSS 0.8889017\n",
      "Trained for batch 39/40\n",
      "Generated batch (25, 4, 64, 64, 3)\n",
      "GEN_LOSS 1.1007025\n",
      "DISC_LOSS 0.86110675\n",
      "Trained for batch 40/40\n",
      "______________________________EPOCH 1_______________________________\n",
      "Generated batch (25, 4, 64, 64, 3)\n",
      "GEN_LOSS 1.0465988\n",
      "DISC_LOSS 0.8305098\n",
      "Trained for batch 1/40\n",
      "Generated batch (25, 4, 64, 64, 3)\n",
      "GEN_LOSS 0.98515004\n",
      "DISC_LOSS 0.8789594\n",
      "Trained for batch 2/40\n",
      "Generated batch (25, 4, 64, 64, 3)\n",
      "GEN_LOSS 1.0371296\n",
      "DISC_LOSS 0.82892394\n",
      "Trained for batch 3/40\n",
      "Generated batch (25, 4, 64, 64, 3)\n",
      "GEN_LOSS 1.1436797\n",
      "DISC_LOSS 0.76781416\n",
      "Trained for batch 4/40\n",
      "Generated batch (25, 4, 64, 64, 3)\n",
      "GEN_LOSS 0.98828745\n",
      "DISC_LOSS 0.8327844\n",
      "Trained for batch 5/40\n",
      "Generated batch (25, 4, 64, 64, 3)\n",
      "GEN_LOSS 0.96988016\n",
      "DISC_LOSS 0.8151218\n",
      "Trained for batch 6/40\n",
      "Generated batch (25, 4, 64, 64, 3)\n",
      "GEN_LOSS 1.0995154\n",
      "DISC_LOSS 0.7874242\n",
      "Trained for batch 7/40\n",
      "Generated batch (25, 4, 64, 64, 3)\n",
      "GEN_LOSS 1.1080232\n",
      "DISC_LOSS 0.8091966\n",
      "Trained for batch 8/40\n",
      "Generated batch (25, 4, 64, 64, 3)\n",
      "GEN_LOSS 1.1456304\n",
      "DISC_LOSS 0.7980537\n",
      "Trained for batch 9/40\n",
      "Generated batch (25, 4, 64, 64, 3)\n",
      "GEN_LOSS 1.0870317\n",
      "DISC_LOSS 0.7926892\n",
      "Trained for batch 10/40\n",
      "Generated batch (25, 4, 64, 64, 3)\n",
      "GEN_LOSS 1.1679136\n",
      "DISC_LOSS 0.73891556\n",
      "Trained for batch 11/40\n",
      "Generated batch (25, 4, 64, 64, 3)\n",
      "GEN_LOSS 1.0935614\n",
      "DISC_LOSS 0.7004093\n",
      "Trained for batch 12/40\n",
      "Generated batch (25, 4, 64, 64, 3)\n",
      "GEN_LOSS 1.1414446\n",
      "DISC_LOSS 0.6916524\n",
      "Trained for batch 13/40\n",
      "Generated batch (25, 4, 64, 64, 3)\n",
      "GEN_LOSS 1.1969086\n",
      "DISC_LOSS 0.6280055\n",
      "Trained for batch 14/40\n",
      "Generated batch (25, 4, 64, 64, 3)\n",
      "GEN_LOSS 1.1256477\n",
      "DISC_LOSS 0.6662531\n",
      "Trained for batch 15/40\n",
      "Generated batch (25, 4, 64, 64, 3)\n",
      "GEN_LOSS 1.2153999\n",
      "DISC_LOSS 0.67171395\n",
      "Trained for batch 16/40\n",
      "Generated batch (25, 4, 64, 64, 3)\n",
      "GEN_LOSS 1.2723532\n",
      "DISC_LOSS 0.6211302\n",
      "Trained for batch 17/40\n",
      "Generated batch (25, 4, 64, 64, 3)\n",
      "GEN_LOSS 1.3242301\n",
      "DISC_LOSS 0.5451824\n",
      "Trained for batch 18/40\n",
      "Generated batch (25, 4, 64, 64, 3)\n",
      "GEN_LOSS 1.3218682\n",
      "DISC_LOSS 0.5655677\n",
      "Trained for batch 19/40\n",
      "Generated batch (25, 4, 64, 64, 3)\n",
      "GEN_LOSS 1.3787348\n",
      "DISC_LOSS 0.50307274\n",
      "Trained for batch 20/40\n",
      "Generated batch (25, 4, 64, 64, 3)\n",
      "GEN_LOSS 1.3548858\n",
      "DISC_LOSS 0.5147311\n",
      "Trained for batch 21/40\n",
      "Generated batch (25, 4, 64, 64, 3)\n",
      "GEN_LOSS 1.2932595\n",
      "DISC_LOSS 0.4773554\n",
      "Trained for batch 22/40\n",
      "Generated batch (25, 4, 64, 64, 3)\n",
      "GEN_LOSS 1.3981586\n",
      "DISC_LOSS 0.45202476\n",
      "Trained for batch 23/40\n",
      "Generated batch (25, 4, 64, 64, 3)\n",
      "GEN_LOSS 1.3732232\n",
      "DISC_LOSS 0.4811604\n",
      "Trained for batch 24/40\n",
      "Generated batch (25, 4, 64, 64, 3)\n",
      "GEN_LOSS 1.42959\n",
      "DISC_LOSS 0.4987492\n",
      "Trained for batch 25/40\n",
      "Generated batch (25, 4, 64, 64, 3)\n",
      "GEN_LOSS 1.3369378\n",
      "DISC_LOSS 0.48916674\n",
      "Trained for batch 26/40\n",
      "Generated batch (25, 4, 64, 64, 3)\n",
      "GEN_LOSS 1.3274763\n",
      "DISC_LOSS 0.49758807\n",
      "Trained for batch 27/40\n",
      "Generated batch (25, 4, 64, 64, 3)\n",
      "GEN_LOSS 1.3826015\n",
      "DISC_LOSS 0.49969247\n",
      "Trained for batch 28/40\n",
      "Generated batch (25, 4, 64, 64, 3)\n",
      "GEN_LOSS 1.232553\n",
      "DISC_LOSS 0.5970494\n",
      "Trained for batch 29/40\n",
      "Generated batch (25, 4, 64, 64, 3)\n",
      "GEN_LOSS 1.1694779\n",
      "DISC_LOSS 0.61546373\n",
      "Trained for batch 30/40\n",
      "Generated batch (25, 4, 64, 64, 3)\n",
      "GEN_LOSS 1.174477\n",
      "DISC_LOSS 0.6335112\n",
      "Trained for batch 31/40\n",
      "Generated batch (25, 4, 64, 64, 3)\n",
      "GEN_LOSS 1.2373971\n",
      "DISC_LOSS 0.6561134\n",
      "Trained for batch 32/40\n",
      "Generated batch (25, 4, 64, 64, 3)\n",
      "GEN_LOSS 1.2919565\n",
      "DISC_LOSS 0.58528715\n",
      "Trained for batch 33/40\n",
      "Generated batch (25, 4, 64, 64, 3)\n",
      "GEN_LOSS 1.2439705\n",
      "DISC_LOSS 0.5333974\n",
      "Trained for batch 34/40\n",
      "Generated batch (25, 4, 64, 64, 3)\n",
      "GEN_LOSS 1.1827548\n",
      "DISC_LOSS 0.5410408\n",
      "Trained for batch 35/40\n",
      "Generated batch (25, 4, 64, 64, 3)\n",
      "GEN_LOSS 1.4111747\n",
      "DISC_LOSS 0.48652083\n",
      "Trained for batch 36/40\n",
      "Generated batch (25, 4, 64, 64, 3)\n",
      "GEN_LOSS 1.1749924\n",
      "DISC_LOSS 0.59631115\n",
      "Trained for batch 37/40\n",
      "Generated batch (25, 4, 64, 64, 3)\n",
      "GEN_LOSS 1.3081505\n",
      "DISC_LOSS 0.59527826\n",
      "Trained for batch 38/40\n",
      "Generated batch (25, 4, 64, 64, 3)\n",
      "GEN_LOSS 1.4181799\n",
      "DISC_LOSS 0.5750201\n",
      "Trained for batch 39/40\n",
      "Generated batch (25, 4, 64, 64, 3)\n",
      "GEN_LOSS 1.279568\n",
      "DISC_LOSS 0.5244153\n",
      "Trained for batch 40/40\n",
      "______________________________EPOCH 2_______________________________\n",
      "Generated batch (25, 4, 64, 64, 3)\n",
      "GEN_LOSS 1.3625059\n",
      "DISC_LOSS 0.49883476\n",
      "Trained for batch 1/40\n",
      "Generated batch (25, 4, 64, 64, 3)\n",
      "GEN_LOSS 1.4587033\n",
      "DISC_LOSS 0.4600417\n",
      "Trained for batch 2/40\n",
      "Generated batch (25, 4, 64, 64, 3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GEN_LOSS 1.2841387\n",
      "DISC_LOSS 0.49561334\n",
      "Trained for batch 3/40\n",
      "Generated batch (25, 4, 64, 64, 3)\n",
      "GEN_LOSS 1.5364975\n",
      "DISC_LOSS 0.41733718\n",
      "Trained for batch 4/40\n",
      "Generated batch (25, 4, 64, 64, 3)\n",
      "GEN_LOSS 1.4693565\n",
      "DISC_LOSS 0.42433232\n",
      "Trained for batch 5/40\n",
      "Generated batch (25, 4, 64, 64, 3)\n",
      "GEN_LOSS 1.1695759\n",
      "DISC_LOSS 0.5148622\n",
      "Trained for batch 6/40\n",
      "Generated batch (25, 4, 64, 64, 3)\n",
      "GEN_LOSS 1.4071422\n",
      "DISC_LOSS 0.35677886\n",
      "Trained for batch 7/40\n",
      "Generated batch (25, 4, 64, 64, 3)\n",
      "GEN_LOSS 1.4664278\n",
      "DISC_LOSS 0.44131666\n",
      "Trained for batch 8/40\n",
      "Generated batch (25, 4, 64, 64, 3)\n",
      "GEN_LOSS 1.2189249\n",
      "DISC_LOSS 0.44369102\n",
      "Trained for batch 9/40\n",
      "Generated batch (25, 4, 64, 64, 3)\n",
      "GEN_LOSS 1.1590796\n",
      "DISC_LOSS 0.5533382\n",
      "Trained for batch 10/40\n",
      "Generated batch (25, 4, 64, 64, 3)\n",
      "GEN_LOSS 1.4041679\n",
      "DISC_LOSS 0.51370907\n",
      "Trained for batch 11/40\n",
      "Generated batch (25, 4, 64, 64, 3)\n",
      "GEN_LOSS 1.3565589\n",
      "DISC_LOSS 0.48733968\n",
      "Trained for batch 12/40\n",
      "Generated batch (25, 4, 64, 64, 3)\n",
      "GEN_LOSS 1.2861605\n",
      "DISC_LOSS 0.5999851\n",
      "Trained for batch 13/40\n",
      "Generated batch (25, 4, 64, 64, 3)\n",
      "GEN_LOSS 1.359235\n",
      "DISC_LOSS 0.50891817\n",
      "Trained for batch 14/40\n",
      "Generated batch (25, 4, 64, 64, 3)\n",
      "GEN_LOSS 1.4816235\n",
      "DISC_LOSS 0.61815727\n",
      "Trained for batch 15/40\n",
      "Generated batch (25, 4, 64, 64, 3)\n",
      "GEN_LOSS 1.5484529\n",
      "DISC_LOSS 0.50943947\n",
      "Trained for batch 16/40\n",
      "Generated batch (25, 4, 64, 64, 3)\n",
      "GEN_LOSS 1.455379\n",
      "DISC_LOSS 0.5026916\n",
      "Trained for batch 17/40\n",
      "Generated batch (25, 4, 64, 64, 3)\n",
      "GEN_LOSS 1.5201738\n",
      "DISC_LOSS 0.49490988\n",
      "Trained for batch 18/40\n",
      "Generated batch (25, 4, 64, 64, 3)\n",
      "GEN_LOSS 1.7268901\n",
      "DISC_LOSS 0.48528132\n",
      "Trained for batch 19/40\n",
      "Generated batch (25, 4, 64, 64, 3)\n",
      "GEN_LOSS 1.6091276\n",
      "DISC_LOSS 0.4152557\n",
      "Trained for batch 20/40\n",
      "Generated batch (25, 4, 64, 64, 3)\n",
      "GEN_LOSS 1.3897487\n",
      "DISC_LOSS 0.42748433\n",
      "Trained for batch 21/40\n",
      "Generated batch (25, 4, 64, 64, 3)\n",
      "GEN_LOSS 1.28841\n",
      "DISC_LOSS 0.4353811\n",
      "Trained for batch 22/40\n",
      "Generated batch (25, 4, 64, 64, 3)\n",
      "GEN_LOSS 1.4094889\n",
      "DISC_LOSS 0.46667394\n",
      "Trained for batch 23/40\n",
      "Generated batch (25, 4, 64, 64, 3)\n",
      "GEN_LOSS 1.4000428\n",
      "DISC_LOSS 0.45519805\n",
      "Trained for batch 24/40\n",
      "Generated batch (25, 4, 64, 64, 3)\n",
      "GEN_LOSS 1.4136298\n",
      "DISC_LOSS 0.4135387\n",
      "Trained for batch 25/40\n",
      "Generated batch (25, 4, 64, 64, 3)\n",
      "GEN_LOSS 1.3312364\n",
      "DISC_LOSS 0.4496367\n",
      "Trained for batch 26/40\n",
      "Generated batch (25, 4, 64, 64, 3)\n",
      "GEN_LOSS 1.4081274\n",
      "DISC_LOSS 0.38231912\n",
      "Trained for batch 27/40\n",
      "Generated batch (25, 4, 64, 64, 3)\n",
      "GEN_LOSS 1.4562418\n",
      "DISC_LOSS 0.36669612\n",
      "Trained for batch 28/40\n",
      "Generated batch (25, 4, 64, 64, 3)\n",
      "GEN_LOSS 1.4024457\n",
      "DISC_LOSS 0.40318972\n",
      "Trained for batch 29/40\n",
      "Generated batch (25, 4, 64, 64, 3)\n",
      "GEN_LOSS 1.2129558\n",
      "DISC_LOSS 0.4865634\n",
      "Trained for batch 30/40\n",
      "Generated batch (25, 4, 64, 64, 3)\n",
      "GEN_LOSS 1.3122184\n",
      "DISC_LOSS 0.48572555\n",
      "Trained for batch 31/40\n",
      "Generated batch (25, 4, 64, 64, 3)\n",
      "GEN_LOSS 1.2300272\n",
      "DISC_LOSS 0.6112444\n",
      "Trained for batch 32/40\n",
      "Generated batch (25, 4, 64, 64, 3)\n",
      "GEN_LOSS 1.1517258\n",
      "DISC_LOSS 0.6741786\n",
      "Trained for batch 33/40\n",
      "Generated batch (25, 4, 64, 64, 3)\n",
      "GEN_LOSS 1.0563126\n",
      "DISC_LOSS 0.74330854\n",
      "Trained for batch 34/40\n",
      "Generated batch (25, 4, 64, 64, 3)\n",
      "GEN_LOSS 0.9925212\n",
      "DISC_LOSS 0.718644\n",
      "Trained for batch 35/40\n",
      "Generated batch (25, 4, 64, 64, 3)\n",
      "GEN_LOSS 1.0533726\n",
      "DISC_LOSS 0.5992317\n",
      "Trained for batch 36/40\n",
      "Generated batch (25, 4, 64, 64, 3)\n",
      "GEN_LOSS 1.1895177\n",
      "DISC_LOSS 0.64998835\n",
      "Trained for batch 37/40\n",
      "Generated batch (25, 4, 64, 64, 3)\n",
      "GEN_LOSS 1.3257256\n",
      "DISC_LOSS 0.526993\n",
      "Trained for batch 38/40\n",
      "Generated batch (25, 4, 64, 64, 3)\n",
      "GEN_LOSS 1.3652663\n",
      "DISC_LOSS 0.50478345\n",
      "Trained for batch 39/40\n",
      "Generated batch (25, 4, 64, 64, 3)\n",
      "GEN_LOSS 1.288959\n",
      "DISC_LOSS 0.46692967\n",
      "Trained for batch 40/40\n",
      "______________________________EPOCH 3_______________________________\n",
      "Generated batch (25, 4, 64, 64, 3)\n",
      "GEN_LOSS 1.3400527\n",
      "DISC_LOSS 0.48929408\n",
      "Trained for batch 1/40\n",
      "Generated batch (25, 4, 64, 64, 3)\n",
      "GEN_LOSS 1.2790909\n",
      "DISC_LOSS 0.44225842\n",
      "Trained for batch 2/40\n",
      "Generated batch (25, 4, 64, 64, 3)\n",
      "GEN_LOSS 1.4624126\n",
      "DISC_LOSS 0.5087045\n",
      "Trained for batch 3/40\n",
      "Generated batch (25, 4, 64, 64, 3)\n",
      "GEN_LOSS 1.510776\n",
      "DISC_LOSS 0.48832923\n",
      "Trained for batch 4/40\n",
      "Generated batch (25, 4, 64, 64, 3)\n",
      "GEN_LOSS 1.0494044\n",
      "DISC_LOSS 0.5620141\n",
      "Trained for batch 5/40\n",
      "Generated batch (25, 4, 64, 64, 3)\n",
      "GEN_LOSS 0.995169\n",
      "DISC_LOSS 0.5716244\n",
      "Trained for batch 6/40\n",
      "Generated batch (25, 4, 64, 64, 3)\n",
      "GEN_LOSS 1.1267995\n",
      "DISC_LOSS 0.48291337\n",
      "Trained for batch 7/40\n",
      "Generated batch (25, 4, 64, 64, 3)\n",
      "GEN_LOSS 1.4072676\n",
      "DISC_LOSS 0.5432358\n",
      "Trained for batch 8/40\n",
      "Generated batch (25, 4, 64, 64, 3)\n",
      "GEN_LOSS 1.40695\n",
      "DISC_LOSS 0.59088576\n",
      "Trained for batch 9/40\n",
      "Generated batch (25, 4, 64, 64, 3)\n",
      "GEN_LOSS 1.2915552\n",
      "DISC_LOSS 0.59912235\n",
      "Trained for batch 10/40\n",
      "Generated batch (25, 4, 64, 64, 3)\n",
      "GEN_LOSS 1.09308\n",
      "DISC_LOSS 0.59716916\n",
      "Trained for batch 11/40\n",
      "Generated batch (25, 4, 64, 64, 3)\n",
      "GEN_LOSS 0.9359658\n",
      "DISC_LOSS 0.7130478\n",
      "Trained for batch 12/40\n",
      "Generated batch (25, 4, 64, 64, 3)\n",
      "GEN_LOSS 1.0612565\n",
      "DISC_LOSS 0.59848005\n",
      "Trained for batch 13/40\n",
      "Generated batch (25, 4, 64, 64, 3)\n",
      "GEN_LOSS 1.2794129\n",
      "DISC_LOSS 0.58283263\n",
      "Trained for batch 14/40\n",
      "Generated batch (25, 4, 64, 64, 3)\n",
      "GEN_LOSS 1.3537532\n",
      "DISC_LOSS 0.6019549\n",
      "Trained for batch 15/40\n",
      "Generated batch (25, 4, 64, 64, 3)\n",
      "GEN_LOSS 1.2723953\n",
      "DISC_LOSS 0.50659204\n",
      "Trained for batch 16/40\n",
      "Generated batch (25, 4, 64, 64, 3)\n",
      "GEN_LOSS 1.2531704\n",
      "DISC_LOSS 0.49632123\n",
      "Trained for batch 17/40\n",
      "Generated batch (25, 4, 64, 64, 3)\n",
      "GEN_LOSS 1.2189262\n",
      "DISC_LOSS 0.52543247\n",
      "Trained for batch 18/40\n",
      "Generated batch (25, 4, 64, 64, 3)\n",
      "GEN_LOSS 1.2915747\n",
      "DISC_LOSS 0.4495241\n",
      "Trained for batch 19/40\n",
      "Generated batch (25, 4, 64, 64, 3)\n",
      "GEN_LOSS 1.4038208\n",
      "DISC_LOSS 0.41314083\n",
      "Trained for batch 20/40\n",
      "Generated batch (25, 4, 64, 64, 3)\n",
      "GEN_LOSS 1.4533544\n",
      "DISC_LOSS 0.44190866\n",
      "Trained for batch 21/40\n",
      "Generated batch (25, 4, 64, 64, 3)\n",
      "GEN_LOSS 1.3489665\n",
      "DISC_LOSS 0.3730545\n",
      "Trained for batch 22/40\n",
      "Generated batch (25, 4, 64, 64, 3)\n",
      "GEN_LOSS 1.3170841\n",
      "DISC_LOSS 0.3337679\n",
      "Trained for batch 23/40\n",
      "Generated batch (25, 4, 64, 64, 3)\n",
      "GEN_LOSS 1.2784528\n",
      "DISC_LOSS 0.39236623\n",
      "Trained for batch 24/40\n",
      "Generated batch (25, 4, 64, 64, 3)\n",
      "GEN_LOSS 1.4378555\n",
      "DISC_LOSS 0.3837545\n",
      "Trained for batch 25/40\n",
      "Generated batch (25, 4, 64, 64, 3)\n",
      "GEN_LOSS 1.4804095\n",
      "DISC_LOSS 0.3475572\n",
      "Trained for batch 26/40\n",
      "Generated batch (25, 4, 64, 64, 3)\n",
      "GEN_LOSS 1.4466767\n",
      "DISC_LOSS 0.3650301\n",
      "Trained for batch 27/40\n",
      "Generated batch (25, 4, 64, 64, 3)\n",
      "GEN_LOSS 1.2876002\n",
      "DISC_LOSS 0.3093598\n",
      "Trained for batch 28/40\n",
      "Generated batch (25, 4, 64, 64, 3)\n",
      "GEN_LOSS 1.2588639\n",
      "DISC_LOSS 0.3701635\n",
      "Trained for batch 29/40\n",
      "Generated batch (25, 4, 64, 64, 3)\n",
      "GEN_LOSS 1.3211806\n",
      "DISC_LOSS 0.3319329\n",
      "Trained for batch 30/40\n",
      "Generated batch (25, 4, 64, 64, 3)\n",
      "GEN_LOSS 1.3645647\n",
      "DISC_LOSS 0.33140963\n",
      "Trained for batch 31/40\n",
      "Generated batch (25, 4, 64, 64, 3)\n",
      "GEN_LOSS 1.3816805\n",
      "DISC_LOSS 0.36745977\n",
      "Trained for batch 32/40\n",
      "Generated batch (25, 4, 64, 64, 3)\n",
      "GEN_LOSS 1.3394092\n",
      "DISC_LOSS 0.3492059\n",
      "Trained for batch 33/40\n",
      "Generated batch (25, 4, 64, 64, 3)\n",
      "GEN_LOSS 1.2825389\n",
      "DISC_LOSS 0.3924723\n",
      "Trained for batch 34/40\n",
      "Generated batch (25, 4, 64, 64, 3)\n",
      "GEN_LOSS 1.3229052\n",
      "DISC_LOSS 0.34336746\n",
      "Trained for batch 35/40\n",
      "Generated batch (25, 4, 64, 64, 3)\n",
      "GEN_LOSS 1.3460908\n",
      "DISC_LOSS 0.41777563\n",
      "Trained for batch 36/40\n",
      "Generated batch (25, 4, 64, 64, 3)\n",
      "GEN_LOSS 1.3822262\n",
      "DISC_LOSS 0.34968066\n",
      "Trained for batch 37/40\n",
      "Generated batch (25, 4, 64, 64, 3)\n",
      "GEN_LOSS 1.2013056\n",
      "DISC_LOSS 0.4033602\n",
      "Trained for batch 38/40\n",
      "Generated batch (25, 4, 64, 64, 3)\n",
      "GEN_LOSS 1.284923\n",
      "DISC_LOSS 0.39215386\n",
      "Trained for batch 39/40\n",
      "Generated batch (25, 4, 64, 64, 3)\n",
      "GEN_LOSS 1.4242787\n",
      "DISC_LOSS 0.4394651\n",
      "Trained for batch 40/40\n",
      "______________________________EPOCH 4_______________________________\n",
      "Generated batch (25, 4, 64, 64, 3)\n",
      "GEN_LOSS 1.3534443\n",
      "DISC_LOSS 0.38097852\n",
      "Trained for batch 1/40\n",
      "Generated batch (25, 4, 64, 64, 3)\n",
      "GEN_LOSS 1.3389902\n",
      "DISC_LOSS 0.42296162\n",
      "Trained for batch 2/40\n",
      "Generated batch (25, 4, 64, 64, 3)\n",
      "GEN_LOSS 1.3465823\n",
      "DISC_LOSS 0.4076442\n",
      "Trained for batch 3/40\n",
      "Generated batch (25, 4, 64, 64, 3)\n",
      "GEN_LOSS 1.5309143\n",
      "DISC_LOSS 0.4493803\n",
      "Trained for batch 4/40\n",
      "Generated batch (25, 4, 64, 64, 3)\n",
      "GEN_LOSS 1.354284\n",
      "DISC_LOSS 0.3848667\n",
      "Trained for batch 5/40\n",
      "Generated batch (25, 4, 64, 64, 3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GEN_LOSS 1.4466221\n",
      "DISC_LOSS 0.3695987\n",
      "Trained for batch 6/40\n",
      "Generated batch (25, 4, 64, 64, 3)\n",
      "GEN_LOSS 1.4987152\n",
      "DISC_LOSS 0.37348965\n",
      "Trained for batch 7/40\n",
      "Generated batch (25, 4, 64, 64, 3)\n",
      "GEN_LOSS 1.5487199\n",
      "DISC_LOSS 0.42369574\n",
      "Trained for batch 8/40\n",
      "Generated batch (25, 4, 64, 64, 3)\n",
      "GEN_LOSS 1.5518804\n",
      "DISC_LOSS 0.3809514\n",
      "Trained for batch 9/40\n",
      "Generated batch (25, 4, 64, 64, 3)\n",
      "GEN_LOSS 1.3473154\n",
      "DISC_LOSS 0.40007833\n",
      "Trained for batch 10/40\n",
      "Generated batch (25, 4, 64, 64, 3)\n",
      "GEN_LOSS 1.3288426\n",
      "DISC_LOSS 0.42930913\n",
      "Trained for batch 11/40\n",
      "Generated batch (25, 4, 64, 64, 3)\n",
      "GEN_LOSS 1.3517507\n",
      "DISC_LOSS 0.38130093\n",
      "Trained for batch 12/40\n",
      "Generated batch (25, 4, 64, 64, 3)\n",
      "GEN_LOSS 1.5254881\n",
      "DISC_LOSS 0.532272\n",
      "Trained for batch 13/40\n",
      "Generated batch (25, 4, 64, 64, 3)\n",
      "GEN_LOSS 1.3758067\n",
      "DISC_LOSS 0.5294571\n",
      "Trained for batch 14/40\n",
      "Generated batch (25, 4, 64, 64, 3)\n",
      "GEN_LOSS 1.2324489\n",
      "DISC_LOSS 0.43234694\n",
      "Trained for batch 15/40\n",
      "Generated batch (25, 4, 64, 64, 3)\n",
      "GEN_LOSS 1.1732564\n",
      "DISC_LOSS 0.46439728\n",
      "Trained for batch 16/40\n",
      "Generated batch (25, 4, 64, 64, 3)\n",
      "GEN_LOSS 1.4108707\n",
      "DISC_LOSS 0.43513572\n",
      "Trained for batch 17/40\n",
      "Generated batch (25, 4, 64, 64, 3)\n",
      "GEN_LOSS 1.4771549\n",
      "DISC_LOSS 0.35430986\n",
      "Trained for batch 18/40\n",
      "Generated batch (25, 4, 64, 64, 3)\n",
      "GEN_LOSS 1.3867124\n",
      "DISC_LOSS 0.3216411\n",
      "Trained for batch 19/40\n",
      "Generated batch (25, 4, 64, 64, 3)\n",
      "GEN_LOSS 1.3253204\n",
      "DISC_LOSS 0.28945285\n",
      "Trained for batch 20/40\n",
      "Generated batch (25, 4, 64, 64, 3)\n",
      "GEN_LOSS 1.35305\n",
      "DISC_LOSS 0.3831662\n",
      "Trained for batch 21/40\n",
      "Generated batch (25, 4, 64, 64, 3)\n",
      "GEN_LOSS 1.3244939\n",
      "DISC_LOSS 0.3608554\n",
      "Trained for batch 22/40\n",
      "Generated batch (25, 4, 64, 64, 3)\n",
      "GEN_LOSS 1.2906535\n",
      "DISC_LOSS 0.36576658\n",
      "Trained for batch 23/40\n",
      "Generated batch (25, 4, 64, 64, 3)\n",
      "GEN_LOSS 1.3711389\n",
      "DISC_LOSS 0.43244207\n",
      "Trained for batch 24/40\n",
      "Generated batch (25, 4, 64, 64, 3)\n",
      "GEN_LOSS 1.4023728\n",
      "DISC_LOSS 0.3967173\n",
      "Trained for batch 25/40\n",
      "Generated batch (25, 4, 64, 64, 3)\n",
      "GEN_LOSS 1.2339082\n",
      "DISC_LOSS 0.4716835\n",
      "Trained for batch 26/40\n",
      "Generated batch (25, 4, 64, 64, 3)\n",
      "GEN_LOSS 1.1736155\n",
      "DISC_LOSS 0.6295422\n",
      "Trained for batch 27/40\n",
      "Generated batch (25, 4, 64, 64, 3)\n",
      "GEN_LOSS 1.1011784\n",
      "DISC_LOSS 0.5484858\n",
      "Trained for batch 28/40\n",
      "Generated batch (25, 4, 64, 64, 3)\n",
      "GEN_LOSS 1.1892782\n",
      "DISC_LOSS 0.67616916\n",
      "Trained for batch 29/40\n",
      "Generated batch (25, 4, 64, 64, 3)\n",
      "GEN_LOSS 1.2493263\n",
      "DISC_LOSS 0.5632435\n",
      "Trained for batch 30/40\n",
      "Generated batch (25, 4, 64, 64, 3)\n",
      "GEN_LOSS 1.1263766\n",
      "DISC_LOSS 0.7000576\n",
      "Trained for batch 31/40\n",
      "Generated batch (25, 4, 64, 64, 3)\n",
      "GEN_LOSS 1.3193105\n",
      "DISC_LOSS 0.567309\n",
      "Trained for batch 32/40\n",
      "Generated batch (25, 4, 64, 64, 3)\n",
      "GEN_LOSS 1.1495032\n",
      "DISC_LOSS 0.61817664\n",
      "Trained for batch 33/40\n",
      "Generated batch (25, 4, 64, 64, 3)\n",
      "GEN_LOSS 1.1777829\n",
      "DISC_LOSS 0.556438\n",
      "Trained for batch 34/40\n",
      "Generated batch (25, 4, 64, 64, 3)\n",
      "GEN_LOSS 1.4284599\n",
      "DISC_LOSS 0.42373073\n",
      "Trained for batch 35/40\n",
      "Generated batch (25, 4, 64, 64, 3)\n",
      "GEN_LOSS 1.5434073\n",
      "DISC_LOSS 0.4807155\n",
      "Trained for batch 36/40\n",
      "Generated batch (25, 4, 64, 64, 3)\n",
      "GEN_LOSS 1.4480748\n",
      "DISC_LOSS 0.43413723\n",
      "Trained for batch 37/40\n",
      "Generated batch (25, 4, 64, 64, 3)\n",
      "GEN_LOSS 1.4321954\n",
      "DISC_LOSS 0.4520275\n",
      "Trained for batch 38/40\n",
      "Generated batch (25, 4, 64, 64, 3)\n",
      "GEN_LOSS 1.3405633\n",
      "DISC_LOSS 0.47413906\n",
      "Trained for batch 39/40\n",
      "Generated batch (25, 4, 64, 64, 3)\n",
      "GEN_LOSS 1.496553\n",
      "DISC_LOSS 0.38408107\n",
      "Trained for batch 40/40\n",
      "______________________________TRAINING COMPLETED_______________________________\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/gpu:0'):\n",
    "    fit(train_dataset, EPOCHS, test_dataset,batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.99875444\n",
      "0.961206\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "bad operand type for unary +: 'NoneType'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-101-d6bd1b87d974>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtemp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mamin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtemp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[1;33m+\u001b[0m\u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mamax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtemp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: bad operand type for unary +: 'NoneType'"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "family_no = 1011\n",
    "family_data = generate_image(all_families[family_no][0], all_families[family_no][1], all_families[family_no][2])\n",
    "inp = [family_data[0],family_data[1]]\n",
    "inp = tf.cast(inp, tf.float32)\n",
    "father_inp = inp[0][tf.newaxis,...]\n",
    "mother_inp = inp[1][tf.newaxis,...]\n",
    "with tf.device('/gpu:0'):\n",
    "    gen_output = encoder([father_inp, mother_inp], training=True)\n",
    "temp = gen_output.numpy()\n",
    "plt.imshow(np.squeeze(temp))\n",
    "print(np.amin(temp))\n",
    "+print(np.amax(temp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.99007344\n",
      "0.960232\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "family_no = 1011\n",
    "family_data = generate_image(all_families[family_no][0], all_families[family_no][1], all_families[family_no][2])\n",
    "inp = [family_data[0],family_data[1]]\n",
    "inp = tf.cast(inp, tf.float32)\n",
    "father_inp = inp[0][tf.newaxis,...]\n",
    "mother_inp = inp[1][tf.newaxis,...]\n",
    "with tf.device('/gpu:0'):\n",
    "    gen_output = encoder([father_inp, mother_inp], training=True)\n",
    "temp = gen_output.numpy()\n",
    "plt.imshow(np.squeeze(temp))\n",
    "print(np.amin(temp))\n",
    "print(np.amax(temp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu-3.7",
   "language": "python",
   "name": "gpu-3.7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
