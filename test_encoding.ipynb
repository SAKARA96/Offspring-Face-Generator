{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "from PIL import Image\n",
    "import time\n",
    "import tensorflow as tf\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path=\"C:/DL_Dataset/Project_data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_npdata(path):\n",
    "    for r, d, f in os.walk(path):\n",
    "        direc=d\n",
    "        break\n",
    "\n",
    "    np_images=[]\n",
    "    \n",
    "    start= time.time()\n",
    "    for d in direc:\n",
    "        dic={}\n",
    "        sub=[a for a in listdir(path+\"/\"+d)]\n",
    "        flag=0\n",
    "        for ele in sub:\n",
    "            mypath = path+\"/\"+d+\"/\"+ele+\"/\"\n",
    "            onlyfiles = [mypath+f for f in listdir(mypath)]\n",
    "            temp=[]\n",
    "            for addr in onlyfiles:\n",
    "                temp.append(np.array(Image.open(addr)))   \n",
    "            if len(temp)>0:\n",
    "                if ele[0].lower()=='f':\n",
    "                    dic['father']=temp\n",
    "                elif ele[0].lower()=='m':\n",
    "                    dic['mother']=temp\n",
    "                elif ele.lower()=='child_male':\n",
    "                    dic['child']=temp    \n",
    "                    dic['gender']=np.zeros((temp[0].shape))\n",
    "                elif ele.lower()=='child_female':\n",
    "                    dic['child']=temp    \n",
    "                    dic['gender']=np.ones((temp[0].shape))    \n",
    "            else:\n",
    "                flag=1\n",
    "                break\n",
    "\n",
    "        if flag!=1:\n",
    "            for x in dic['father']:\n",
    "                for y in dic['mother']:\n",
    "                    for z in dic['child']:\n",
    "                        np_images.append([x,y,dic['gender'],z])\n",
    "    print(\"time:\",time.time()-start)\n",
    "    return np_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 45.643808126449585\n",
      "1780631\n"
     ]
    }
   ],
   "source": [
    "full_data = load_npdata(path)\n",
    "print(len(full_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder(object):\n",
    "\n",
    "    def __init__(self, learning_rate=1e-4, batch_size=64, n_z=16 ):\n",
    "        # Set hyperparameters\n",
    "        self.learning_rate = learning_rate\n",
    "        self.batch_size = batch_size\n",
    "        self.n_z = n_z #latent dimension of the encoder\n",
    "\n",
    "        # Build the graph\n",
    "        self.build()\n",
    "\n",
    "        # Initialize paramters\n",
    "        self.sess = tf.InteractiveSession()\n",
    "        self.sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    def conv2d(self,input, kernel_size, stride, num_filter):\n",
    "        stride_shape = [1, stride, stride, 1]\n",
    "        filter_shape = [kernel_size, kernel_size, input.get_shape()[3], num_filter]\n",
    "\n",
    "        W = tf.get_variable('w', filter_shape, tf.float32, tf.random_normal_initializer(0.0, 0.02))\n",
    "        b = tf.get_variable('b', [1, 1, 1, num_filter], initializer=tf.constant_initializer(0.0))\n",
    "        return tf.nn.conv2d(input, W, stride_shape, padding='SAME') + b\n",
    "    \n",
    "    def de_conv2d(self,input, kernel_size, stride, output_shape,num_filter):\n",
    "        stride_shape = [1, stride, stride, 1]\n",
    "        filter_shape = [kernel_size, kernel_size, input.get_shape()[3], num_filter]\n",
    "        W = tf.get_variable('w', filter_shape, tf.float32, tf.random_normal_initializer(0.0, 0.02))\n",
    "        b = tf.get_variable('b', [1, 1, 1, num_filter], initializer=tf.constant_initializer(0.0))\n",
    "        return tf.nn.conv2d_transpose(input, W,output_shape, stride_shape, padding='SAME') + b\n",
    "\n",
    "    def max_pool(self,input, kernel_size, stride):\n",
    "        ksize = [1, kernel_size, kernel_size, 1]\n",
    "        strides = [1, stride, stride, 1]\n",
    "        return tf.nn.max_pool(input, ksize=ksize, strides=strides, padding='SAME')\n",
    "\n",
    "    # Build the netowrk and the loss functions\n",
    "    def build(self):\n",
    "        # TODOs\n",
    "        #reset the graph\n",
    "#         tf.reset_default_graph()\n",
    "        K.clear_session()\n",
    "        self.x=tf.placeholder(name='x',dtype=tf.float32,shape=[2,224,224,3])\n",
    "        \n",
    "        \n",
    "        # Encode :f\n",
    "        # x -> z\n",
    "        with tf.variable_scope('conv1'):\n",
    "            conv1 = self.conv2d (self.x, 128, 1, 3)\n",
    "            relu1 = tf.nn.relu(conv1)\n",
    "            pool1 = self.max_pool(relu1, 16, 2) #shape is (2,112,112,3)\n",
    "\n",
    "        with tf.variable_scope('conv2'):\n",
    "            conv2 = self.conv2d (pool1, 64, 1, 3)\n",
    "            relu2 = tf.nn.relu(conv2)\n",
    "            pool2 = self.max_pool(relu2, 8, 2) # shape is (2,56,56,3)\n",
    "\n",
    "        with tf.variable_scope('conv3'):    \n",
    "            conv3 = self.conv2d (pool2, 32, 1, 3)\n",
    "            relu3 = tf.nn.relu(conv3)\n",
    "            pool3 = self.max_pool(relu3, 4, 2) # shape is (2,28,28,3)\n",
    "        \n",
    "    \n",
    "        # Decode :g\n",
    "        # z -> x_hat\n",
    "        # TODOs\n",
    "        with tf.variable_scope('deconv1'):\n",
    "            deconv1 = self.de_conv2d(pool3,32,2,(2,56,56,3),3)\n",
    "        \n",
    "        with tf.variable_scope('deconv2'):\n",
    "            deconv2 = self.de_conv2d(deconv1,64,2,(2,112,112,3),3)\n",
    "        \n",
    "        with tf.variable_scope('deconv3'):\n",
    "            deconv3 = self.de_conv2d(deconv2,128,2,(2,224,224,3),3)\n",
    "        \n",
    "        \n",
    "        # Loss\n",
    "        # Reconstruction loss\n",
    "        # Minimize the cross-entropy loss\n",
    "        # H(x, x_hat) = -\\Sigma x*log(x_hat) + (1-x)*log(1-x_hat)\n",
    "        \n",
    "        eps=1e-10\n",
    "        #loss of input wrt to reconstruction\n",
    "        self.recon_loss = tf.reduce_mean(tf.nn.l2_loss(self.x - deconv3))\n",
    "        \n",
    "        \n",
    "        #store loss in dict to debug\n",
    "        self.losses = {'recon_loss':self.recon_loss}\n",
    "        \n",
    "        # Optimizer\n",
    "        #define adam optimizer and minimize over self.recon_loss\n",
    "        rmsprop=tf.train.optimizers.RMSprop(learning_rate = self.learning_rate)\n",
    "        self.train_op = rmsprop.minimize(self.recon_loss)\n",
    "        \n",
    "        return \n",
    "\n",
    "    # Execute the forward and the backward pass\n",
    "    def run_single_step(self, x ):\n",
    "        #fetches=[self.train_op,self.losses]\n",
    "        #feed_dict=self.x:x\n",
    "        \n",
    "        #in this we only use the loss to see if the model is trained correctly\n",
    "        \n",
    "        _,losses = self.sess.run([self.train_op,self.losses],feed_dict={self.x:x})\n",
    "        return losses\n",
    "    \n",
    "    # x -> x_hat\n",
    "    def reconstructor(self, x):\n",
    "        # TODOs\n",
    "        #after sess run \n",
    "        #first param : return fron sess.run\n",
    "        #second param: feed_dict\n",
    "        x_hat=self.sess.run(self.x_hat,feed_dict={self.x:x})\n",
    "        \n",
    "        return x_hat\n",
    "    \n",
    "    # x -> z\n",
    "    def transformer(self, x):\n",
    "        # TODOs\n",
    "        z=self.sess.run(self.z,feed_dict={self.x:x})\n",
    "        return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainer(data, model_class, learning_rate=1e-4, batch_size=64, num_epoch=3, n_z=16, log_step=1):\n",
    "    # Create a model    \n",
    "    model= model_class(learning_rate=learning_rate,batch_size=batch_size,n_z=n_z)\n",
    "\n",
    "    # Training loop    \n",
    "    for epoch in range(num_epoch):\n",
    "        start_time=time.time()\n",
    "        \n",
    "        #iterate over all the data\n",
    "        for imgs in data:\n",
    "            #get a img from tuple\n",
    "            #run a forward pass\n",
    "            #batch is image and label and we only need image so we index by zero\n",
    "            losses= model.run_single_step(imgs)\n",
    "        print(losses)\n",
    "        end_time=time.time()\n",
    "        print('Epoch '+str(epoch)+' '+\"Training Time: \"+str(end_time-start_time))\n",
    "    print(\"DONE TRAINING\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = full_data[:1]\n",
    "data = np.asarray(data)\n",
    "data = data[:,[0,1]]\n",
    "# stacking father and mother images for encoder\n",
    "for row in data:\n",
    "    row = np.concatenate((row[0],row[1]),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Passed in object of type <class 'str'>, not tf.Tensor",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-4d08f3303a3e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# with tf.device('/device:GPU:0'):\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mencode_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mAutoencoder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-17-98df4c60f90e>\u001b[0m in \u001b[0;36mtrainer\u001b[1;34m(data, model_class, learning_rate, batch_size, num_epoch, n_z, log_step)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_class\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1e-4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_z\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m16\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlog_step\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[1;31m# Create a model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mmodel_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mn_z\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_z\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;31m# Training loop\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-16-846496948fdf>\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, learning_rate, batch_size, n_z)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[1;31m# Build the graph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[1;31m# Initialize paramters\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-16-846496948fdf>\u001b[0m in \u001b[0;36mbuild\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     90\u001b[0m         \u001b[1;31m#define adam optimizer and minimize over self.recon_loss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m         \u001b[0mrmsprop\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mRMSprop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlearning_rate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 92\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_op\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrmsprop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mminimize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecon_loss\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGraphKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAINABLE_VARIABLES\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     93\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m         \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\gpu-3.7\\lib\\site-packages\\tensorflow_core\\python\\keras\\optimizer_v2\\optimizer_v2.py\u001b[0m in \u001b[0;36mminimize\u001b[1;34m(self, loss, var_list, grad_loss, name)\u001b[0m\n\u001b[0;32m    315\u001b[0m     \"\"\"\n\u001b[0;32m    316\u001b[0m     grads_and_vars = self._compute_gradients(\n\u001b[1;32m--> 317\u001b[1;33m         loss, var_list=var_list, grad_loss=grad_loss)\n\u001b[0m\u001b[0;32m    318\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    319\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrads_and_vars\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\gpu-3.7\\lib\\site-packages\\tensorflow_core\\python\\keras\\optimizer_v2\\optimizer_v2.py\u001b[0m in \u001b[0;36m_compute_gradients\u001b[1;34m(self, loss, var_list, grad_loss)\u001b[0m\n\u001b[0;32m    348\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mbackprop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGradientTape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtape\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    349\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvar_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 350\u001b[1;33m         \u001b[0mtape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvar_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    351\u001b[0m       \u001b[0mloss_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    352\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvar_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\gpu-3.7\\lib\\site-packages\\tensorflow_core\\python\\eager\\backprop.py\u001b[0m in \u001b[0;36mwatch\u001b[1;34m(self, tensor)\u001b[0m\n\u001b[0;32m    848\u001b[0m               pywrap_tensorflow.IsVariable(t)):\n\u001b[0;32m    849\u001b[0m         raise ValueError(\"Passed in object of type {}, not tf.Tensor\".format(\n\u001b[1;32m--> 850\u001b[1;33m             type(t)))\n\u001b[0m\u001b[0;32m    851\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_floating\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    852\u001b[0m         logging.log_first_n(\n",
      "\u001b[1;31mValueError\u001b[0m: Passed in object of type <class 'str'>, not tf.Tensor"
     ]
    }
   ],
   "source": [
    "# with tf.device('/device:GPU:0'):\n",
    "encode_model = trainer(data,Autoencoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu-3.7",
   "language": "python",
   "name": "gpu-3.7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
